---
title: "Redis面经"
description: "redis面经"
keywords: "redis面经"

date: 2024-03-04T12:57:25+08:00
lastmod: 2024-03-04T12:57:25+08:00

categories:
  - 面试
tags:
  - redis
  - 面经

# 原文作者
# Post's origin author name
author: zzzi
# 开启数学公式渲染，可选值： mathjax, katex
# Support Math Formulas render, options: mathjax, katex
math: mathjax
# 原文链接
# Post's origin link URL
#link:
# 图片链接，用在open graph和twitter卡片上
# Image source link that will use in open graph and twitter card
#imgs:
# 在首页展开内容
# Expand content on the home page
#expand: true
# 外部链接地址，访问时直接跳转
# It's means that will redirecting to external links
#extlink:
# 在当前页面关闭评论功能
# Disabled comment plugins in this post
#comment:
#  enable: false
# 关闭文章目录功能
# Disable table of content
toc: false
# 绝对访问路径
# Absolute link for visit
#url: "redis面经.html"
# 开启文章置顶，数字越小越靠前
# Sticky post set-top in home page and the smaller nubmer will more forward.
#weight: 1

# 开启各种图渲染，如流程图、时序图、类图等
# Enable chart render, such as: flow, sequence, classes etc
#mermaid: true
---

> 🛅 redis面经

本文主要介绍一些redis的常见面试题，文章长期更新，面试答案参考小林coding的[图解系列](https://xiaolincoding.com/)，**第一章**面试篇就是整体的面试题，后面几章是对面试篇中一些重点问题的补充

<!--more-->

#### redis定义

redis是一种基于内存的数据库，数据读写都在内存中完成，因此读写速度很快，常用于缓存，消息队列，分布式锁等场景

#### redis和Memcached的区别

1. 都是基于内存的数据库，常用来作缓存
2. 都有**过期策略**，性能都很高

> 区别

1. redis支持的数据类型更丰富，Memcached只支持key-value
2. redis支持数据持久化，可以将内存中的数据同步到磁盘中
3. redis数据过期策略更加高级
4. redis功能更强大，生态系统更加完善

#### 为什么使用redis做mysql的缓存

1. redis具备高性能：数据经过redis缓存在内存中，访问速度会大大加快
2. redis具备高并发：针对请求量来说，redis每秒能够处理的请求量是mysql的十倍以上
3. 缓存之后可以缓解mysql的大部分压力

所以我们使用redis作缓存，这样mysql中的一部分数据缓存在了redis中，可以减小数据访问的时间，提高系统的运行效率

#### redis的数据类型

> 这里指的主要是redis中key-value中value的数据类型，key的数据类型始终是string

1. String：可存储字符串，整数，浮点数，<u>常用来缓存对象（json，按字段分别缓存），计数（因为可存储整数），和一些共享信息（分布式锁）</u>
2. Hash：键值对形式的散列表，<u>常用来缓存对象，一个哈希表就是一个对象的所有字段</u>
3. List：链表，每个节点都是一个字符串，<u>常用来做消息队列，要自己实现**全局唯一**消息id，判断消息是否被处理过</u>，后期出现的stream专门用来做消息队列
4. Set：字符串的无序集合：<u>常用来做集合之间的聚合计算（交并差）</u>
5. Zset：字符串的不允许重复的集合，每个元素带一个分数，<u>常用来进行排序</u>

> 随着版本更新，后面又新增了一些数据类型

1. BitMap：二进制状态的场景，签到，判断是否登录，**底层使用String**，布隆过滤器
2. HyperLoglog：统计基数（不重复元素的个数），但是不太精确，因为是基于概率的
3. GEO：存储地理位置信息，滴滴叫车
4. Stream：为消息队列而生，相比于List实现的消息队列，Stream**可以自动生成**全局唯一消息id，并且有**消费组**（多个消费者消费同一条消息）

#### redis中的消息队列

1. 使用List保证消息的有序性
2. 使用阻塞式读取的方式防止没有消息时消费者不停地询问
3. List给消息手动生成全局唯一ID或者使用Stream来自动给消息打上全局唯一标识

#### redis中数据类型的实现原理

<img src="https://cdn.xiaolincoding.com//mysql/other/9fa26a74965efbf0f56b707a03bb9b7f.png" alt="img" style="zoom: 43%;" />

1. String：SDS(简单动态字符串)，不仅可以保存文本数据，还可以保存二进制数据，内部提供很多方便且安全的api(获取字符串长度，拼接字符串)
2. List：当元素个数小于512个且每个元素值都小于64字节时使用压缩列表，否则使用双向链表，**新版本**中使用quickList代替压缩列表（节点是压缩列表，并将链表分段，段间使用双向链表）
3. Hash：当元素个数小于512个且每个元素值都小于64字节时使用压缩列表，否则使用哈希表，新版本中使用listpack（紧凑列表）**代替**压缩列表
4. Set：元素个数小于512使用整数集合（不重复且有序），否则使用哈希表
5. ZSet：元素个数小于128且元素大小小于64字节使用压缩列表，否则使用跳表（给有序链表的节点加上索引，使得有序链表可以随机访问），新版本使用listpack代替压缩列表

#### redis中的SDS(简单动态字符串)实现原理

> redis是C语言实现的，但是并没有用char数组存储字符串，这是因为char数组存在下面的问题

1. char获取字符串长度需要遍历一遍
2. 字符串中间不能有结尾标志'\0'
3. 字符串操作可能造成缓冲区溢出
4. SDS中的api是安全的，拼接不会造成溢出

SDS在字符数组的基础上增加了几个字段：

- len：记录字符串长度，获取长度的操作时间复杂度为o(1)
- alloc：分配给字符数组的长度
- flag：不同类型的SDS，可以灵活使用节省内存不至于浪费
- buf[]：字符数组保存实际数据，字符串或者二进制数据都可以保存

#### redis中的压缩列表

> 是由连续内存块组成的顺序性数据结构，每个元素都分配刚好大小的内存，对于需要连续存储的数据比较友好，但是也存在问题：
>
> 1. 不能保存过多元素，否则查询效率低
> 2. 新增或者修改数据时，数据占用的内存空间会重新分配，可能引发**连锁更新**，这是因为压缩列表的数据结构导致的

压缩列表的数据结构：

<img src="https://zzzi-img-1313100942.cos.ap-beijing.myqcloud.com/img/202403070953793.png" alt="image-20240306105909862" style="zoom:50%;" />

**用多大分配多大，后一个节点记录当前节点的长度从而可以向前遍历**

#### 压缩列表连锁更新的问题

> 由于压缩链表中某个节点的数据更新，可能导致占用内存大小变化，从而导致后一个节点的prevlen发生变化，然后一级一级向后，都出现更新，这就是连锁更新
>
> 主要是**因为**节点保存了前一个节点的长度prevlen才可能导致连锁更新

为了解决连锁更新：

1. 节点数要尽可能少，这样访问效率也高，连锁更新也能接受
1. 将压缩列表换成listpack，每个节点**不记录**前一个节点的长度，节点更新互不影响

> 压缩列表记录前一个节点的长度是为了根据偏移量计算前一个节点的位置

#### 哈希表实现原理

将key通过**哈希函数**映射到一个数组中，数组中的每个桶都可以存放多个key

多个key被分配到同一个桶中就成为哈希冲突，结局办法有：

1. 开放定址法：
   1. 线性探测：从当前冲突位置逐步向后找到一个一个空闲单元插入
   2. 平方探测：分别向左向右1,4,9的步长移动查找空闲单元
   3. 双散列函数
2. 链地址法：冲突的元素使用链表连接
3. 公共溢出区：冲突的元素统一放到溢出区中

> 哈希表扩容与负载因子（哈希表实际存储元素/哈希表大小）有关

#### 整数集合实现原理

> 适合存储不重复且有序的数据，新数据过大可以升级（加大每个元素的存储空间）

<img src="https://zzzi-img-1313100942.cos.ap-beijing.myqcloud.com/img/202403070953795.png" alt="image-20240307092053947" style="zoom:80%;" />

底层使用一个**数组**存储这些有序元素，当新加入的元素超过当前数据范围，就会触发整数集合的**升级**操作，使得每个元素存储的空间变大，**升级之后不能降级**

#### 跳表实现原理

> 相当于给链表中的节点加了二分查找的索引，使得链表的查询速度与数组类似

![image-20240307094957516](https://zzzi-img-1313100942.cos.ap-beijing.myqcloud.com/img/202403070953796.png)

每个节点的数据结构都标识了当前节点是一个几层的节点，从第一层出发相当于顺序访问，从第二层出发每次跳开一个元素，从第三层出发每次更少

最好层与层之间指针数量2:1

> 为了维护跳表的层级关系，会给每一个节点**初始化一个较大的层数**，这样避免了后期层数不够扩充带来的效率问题

#### 跳表查找过程

> 从最高层开始逐步向下

1. 目标元素的权重和数值任有一个大于当前节点就直接向后，向后不了就向下
2. 目标元素的权重和数值都小于当前节点，那么就往回找，因为每个节点都有一个pre指针
3. 由于层级关系高，每一次向后都会跳过多个节点，此时就几乎达到了数组一样的查询效率

#### 为什么用跳表而不是平衡树

1. ZSet经常使用Zrange，也就是遍历整个链表，使用跳表更方便
2. 跳表实现更简单，初始化时给每一个节点分配一个初始的层级
3. 跳表占用的内存更小一些，节点层数越小，使用的指针数越小，但是树不管怎样都是两个指针

#### quicklist实现原理

> 双向链表+压缩列表组合

主要是减小压缩列表的长度，一串数字中，将其分段，段内使用压缩列表，段间使用双向链表，这样操作有两点好处：

1. 节省了内存，因为段内使用了压缩链表，内存空间不浪费
2. **减小**压缩链表带来的连锁更新的影响，因为压缩链表的长度被控制在了一段内，长度很小，所以连锁更新也**可以忍受**

插入元素时先判断段内是否可以插入，不可以插入就新建一个压缩列表当成quicklist的节点

#### listpack实现原理

> 为了彻底解决压缩列表带来的连锁更新问题，引入listpack

压缩列表之所以会出现连锁更新，是因为当前节点保存了前一个节点的长度，一旦前一个节点更新，导致当前节点保存的长度字段更新，就会一步一步地向后都更新

**而listpack不再保存前一个节点的长度**，从而当前节点更新不会影响后面

#### redis是单线程吗

> 不是

在外部来看，客户端发送请求到请求解析并执行最后返回结果的这一个**过程是由单线程**处理的，但是实际上内部还有**后台线程**，用来关闭文件，异步删除，持久化 AOF日志等操作

一般比较耗时的任务都会交给这些后台线程，这样就不会出现主线程阻塞的问题

#### 为什么redis单线程这么快

1. 操作都在内存中，限制性能的其实不是cpu，而是存储设备和网络的读写性能
2. 单线程可以避免多线程之间的竞争导致的进程切换所消耗的时间
3. 使用I/O多路复用处理大量的客户端请求，将这些请求都交给redis线程快速处理

#### redis之后为什么采用多线程

1. 提高响应速度
2. 文件关闭，AOF重写等操作交给后台线程，不影响前台线程从而影响用户体验
3. 多线程可以加快网络I/O的性能

这是因为网络i/o存在瓶颈，引入多线程只是去加快网络I/O的处理速度，执行客户端命令时还是使用单线程（主线程）

如果想要执行客户端命令的时候使用多线程，可以开启一个开关进行**配置**

#### redis中的线程有哪些

> 除开主线程，还有**几个额外**的线程

1. 主线程：执行客户端的命令
2. 异步关闭文件的线程
3. 持久化AOF文件的线程
4. 释放内存的线程
5. **三个**处理网络I/O的线程

#### redis如何利用多个cpu或者多核cpu

> cpu并不是限制redis性能的原因，真正原因是因为存储设备和网络
>
> 如果想要使用多个cpu或者多核cpu，可以启动多个redis节点或者使用分片集群（数据分成多份，每一个节点持有一份）

#### redis持久化

> redis持久化有两种方式

1. AOF日志：**写后日志**，先写数据，再写日志，日志中记录的是redis**命令**，<u>mysql是写前日志</u>，redis使用写后日志的目的是为了提高性能（不用记录错误的命令，只记录正确的），但是可能丢失数据

   出现日志时，**先**记录在aof的缓冲区，**后续**有三种将缓冲区的日志写入aof文件的策略：

   - Always：每次写日志都同步到aof文件中

   - Everysec：每秒同步一次

   - No：由os控制日志的持久化，频率低

     <img src="https://cdn.xiaolincoding.com//mysql/other/98987d9417b2bab43087f45fc959d32a-20230309232253633.png" alt="img" style="zoom:33%;" />

2. RDB快照：给内存拍照，将此时刻的所有文件记录到磁盘中持久化（**二进制方式**），可以手动也可以自动。由于AOF文件的记录频率比RDB快照高，所以redis会默认先使用AOF文件来恢复

3. 混合方式：AOF+RDB快照，恢复较快，记录也较快，结合二者优点，父子进程共享的未修改数据以RDB方式持久化，在持久化期间执行的修改命令由AOF方式持久化，这样可以保证记录的是最新的数据并且恢复时相对于AOF也较快

#### redis持久化方式的优缺点

1. AOF记录命令，记录较快，恢复较慢，恢复时需要重新执行命令，由于其记录较快，所以一旦发生故障，丢失的数据较少
2. RDB记录数据，恢复较快，但是记录较慢，由于其记录较慢，所以一旦发生故障，丢失的数据就会较多，频繁地快照又会影响性能

#### AOF重写

> 为了给AOF文件瘦身

在redis的运行过程中，产生的日志越来越多，此时AOF文件就会越来越大，于是redis会将这个AOF文件进行重写，**去掉冗余文件**，这个操作是由后台线程完成的

当前数据被更新，<u>之前记录的redis操作命令就是冗余的</u>，也就是历史命令冗余

触发方式可以手动也可以自动，什么时候自动可以通过参数配置

#### AOF重写过程中发生了数据修改

> 设置一个AOF重写缓冲区，重写完成之后再将重写过程中发生的修改操作追加到新的AOF文件中

当AOF重写过程中发生了数据修改，**主线程**会做下面几步：

1. 执行修改命令
2. 将命令保存到AOF缓冲区等待持久化（*这个缓冲区有什么用*）
3. 将命令保存到AOF重写缓冲区中（<u>只有发生AOF重写时才有这一步</u>）

当子进程重写工作完成之后，主进程会将重写缓冲区中的命令**追加**到新的AOF文件中（保存了最新的操作命令），并改名**覆盖**旧的AOF文件，此时就完成了AOF重写，并且数据保持一致

#### redis中的RDB快照

> 快照是写时复制，当写操作发生时才真正复制内存中的内容，平时快照和主进程访问的都是同一块内存，因为他共享了页表

1. fork一个子进程进行RDB快照时，父子进程之间共享的是页表，这样减少了复制的时间
2. 然后RDB快照正常复制
3. 写操作发生，会创建**副本**，父进程操作这个数据副本，子进程复制原来的旧数据
4. RDB快照保存完毕之后，里面的部分数据**不是最新**的
5. 因为在RDB快照保存时，父进程在副本上进行了修改
6. 这些修改只能在下次RDB中保存
7. **极端情况**所有内存中的数据都在RDB期间被修改，此时**都**需要创建副本，内存占用量是原来的两倍（RDB文件一份，被复制一份）
8. 两种创建RDB快照的方式（save和bgsave）

#### redis处理大key

> 大key一般指的是key对应的value很大，而不是key本身很大，一般有两种情况：
>
> - String 类型的值大于 10 KB；
> - Hash、List、Set、ZSet 类型的元素的个数超过 5000个；

带来的影响：

1. 客户端超时：因为单线程操作key比较耗时，客户端看来就会超时
2. 网络阻塞：传输大key时会消耗更多的网络资源
3. 工作线程阻塞：操作大key消耗时间过多，导致其他命令会阻塞
4. 内存分布不均：存储有大key的redis节点占用内存会相对较多

#### 大key对于持久化的影响

> 大key占用内存过多，导致消耗更多的性能

1. 对AOF的影响：
   - always持久化时会造成主线程阻塞
   - everySec不会对主线程造成影响，因为是异步的
   - no更没有影响
   - ~~AOF**重写**时会fork()一个子进程复制页表等数据，大key使得**页表很大**，复制起来很慢~~
   - 重写过程中出现了大key的修改，此时重写缓冲区占用的内存就会过大且时间花费变大
2. 对RDB的影响：
   - 保存RDB快照时会fork()一个子进程复制页表等数据，大key使得页表很大，复制起来很慢
   - 保存过程中修改了大key复制就会创建一个数据副本，大key使得数据副本占用内存太大且创建数据副本的时间也会变长

#### redis查找大key

> 只有找到大key才能进一步进行处理，下面介绍几种常见的查找大key的方法

1. redis-cli --bigkeys ：最好在从节点上执行，在主节点上会阻塞主节点，并且只能找到每个类型中最大的key，针对集合来说，只能统计元素数最多的那个集合，而不是占用内存最大的那个
2. SCAN命令：先对所有的数据扫描，之后获取每一个大key的类型
3. 使用第三方工具：例如Rdb Tools，他可以解析redis的RDB快照文件，从而得到大key

#### redis治理大key

1. 可删除：不是热key，此时这些数据可以删除
   - 渐进式删除：每次使用SCAN命令获取一批大key删除，然后继续扫描删除
   - 惰性删除：调用另外一个线程进行非阻塞式的删除
2. 不可删除
   - value压缩：难以拆分的string就应该使用序列化技术来进行压缩，但是压缩也会消耗时间
   - value拆分：类似于Set中的元素就可以分片，分成一组一组的放到不同的地方，**分布式缓存**

#### redis集群的几种方式

1. 主从复制：多个节点之间数据一致，读写分离
2. 哨兵：可以监控主从节点，并且发生故障时可以进行主从节点自动故障转移
3. 分片集群：数据切分，每个节点保存一部分，数据和节点之间的映射关系使用哈希槽表示，从而可以快速定位数据所在节点，每个节点保存了多个哈希槽，从而根据哈希槽就可以知道数据所在位置

#### redis主从复制

> 读写分离，写操作只在主节点，然后同时同步给从节点，同步的操作如下：分为三种：
>
> 1. 首次全量复制
> 2. 之后长连接复制写命令
> 3. 断开之后恢复使用增量复制

1. 首次需要建立连接，这种连接长期建立，主要是便于主从节点之间通信，之后数据同步时采用**全量复制**的方式
2. 主节点将数据同步给从节点（RDB文件）
3. 同步期间主节点可能发生写操作造成数据更新，此时需要将这期间的写命令同步给从节点防止**数据不一致**
4. 在这期间发生的写命令保存在复制缓冲区中，RDB文件加载完毕之后，还需要接受这些命令并执行，从而实现主从节点一致性
5. **后续**主节点发生写操作只需要将写命令同步过去即可（基于长连接的命令传播）

#### 什么时候全量复制，什么时候增量复制

> 根据自己的**偏移**判断当前自己复制到了**环形**缓冲区的哪里

- 全量同步：master将完整内存**数据**生成RDB，发送RDB到slave。后续命令则记录在repl_baklog，逐个发送给slave。
- 增量同步：slave提交自己的offset到master，master获取repl_baklog中从offset之后的**命令**给slave

> 什么时候执行全量同步？

- slave节点**第一次**连接master节点时
- slave节点断开时间太久，repl_baklog中的**offset已经被覆盖时**

> 什么时候执行增量同步？

- slave节点断开又恢复，并且在repl_baklog中能找到offset时

#### 主从复制过程中断网

> 旧版本是在断网恢复之后进行全量复制，新版本是增量恢复

增量恢复实现原理是因为**环形缓冲区**中记录了两个值：

1. 主节点写入的新数据在哪个位置
2. 从节点同步的数据在哪个位置

这样中间的**差值**就是需要增量复制的部分

当网络频繁断开，此时就会出现环形缓冲区中**没有同步的数据被覆盖**，此时就只能全量复制

#### 主从不一致解决办法

1. 保持网络通畅：减小因为网络问题导致的数据同步不一致问题
2. 主动检测数据不一致问题：出现数据不一致就立马进行数据同步（增量，全量）

#### redis集群检测节点是否在线

使用ping机制，一半以上的节点ping另外一个节点都没有反应就认为这个节点不在线

1. 主节点每10s对从节点发送ping命令确认是否在线
2. 从节点每1s对主节点发送消息，有两个作用：
   - 判断主从节点间的网络状态
   - 看自身数据与主节点的数据是否一致

#### redis集群脑裂是什么

**主从节点**之间连接断开，但是主节点A和客户端连接没有断开

此时客户端还向主节点A发送请求，主节点A中的数据更新，哨兵发现主从节点连接断开，选举新的主节点B，此时有两个主节点：**脑裂**

之后哨兵将主节点A降级为从节点A，从节点A同步主节点B的数据，会覆盖这些未同步的数据，覆盖之后**数据丢失**

#### 脑裂解决方法

1. 主节点发现从节点下线超过阈值就**禁止写**并报错

2. 通信超时的数量超过阈值后就禁止写操作并向客户端报错
3. 超过半数以上的节点同意才能将重新选取该主节点

> 这个下线数量和通信超时时间可以设置

#### 哨兵监控节点状态

> 哨兵可以使用Sentinel，用来监控集群的信息

1. 向主从节点发送ping命令，节点回应，从而判断当前节点在线

2. 如果规定时间内没有回应，此时认为节点**主观**下线，从节点没有后续了

3. 对于主节点来说，一旦有**主观**下线，哨兵就会与其他哨兵一起判断主节点的状态

   <img src="https://cdn.xiaolincoding.com//picgo/13e4361407ba46979e802eaa654dcf67.png" alt="img" style="zoom:23%;" />

4. 如果**多数**（参数可配置）哨兵节点都赞同当前主节点主观下线，此时主节点变为**客观**下线

5. 之后哨兵重新选举主节点，需要选择一个哨兵负责这个事

#### 哪个哨兵负责主从切换

> 哨兵集群中至少需要3个节点

1. 需要从哨兵集群中选取一个leader来进行主从切换
2. 谁**先发现**了**主节点主观下线**谁就是候选者
3. 其余哨兵给候选者投票，每人只有一票
4. 候选者拥有一半以上的票数时，就可以负责主从切换

> 有多个候选者（多个哨兵都发现主节点下线）时，其余哨兵只能投票给其中的一个，此时总有一个满足条件

#### 主从切换过程

1. 从客观下线主节点下面的从节点中**挑选**一个成为主节点
   - 去掉网络状态不好的
   - 选择**优先级**高的从节点（优先级可以配置）
   - 优先级相同，选择**同步**旧主节点的数据多的
   - 优先级和同步进度都相同，选择**节点编号**小的优先
2. 所有其余从节点指向新的主节点，以后直接复制这个主节点的数据
   - 向所有的从节点发送slaveof命令，附带上新主节点的ip和信息
3. 将新主节点的ip和其他信息发送给客户端，告知这是新的主节点
   - 通过事件机制监听主从切换的过程，一旦有某个事件发生，客户端都能收到
4. 监视客观下线的旧主节点，一旦其上线，将其设置为从节点
   - 旧主节点上线，哨兵对其发送slaveof命令使其变成新主节点的从节点

#### 哨兵集群间的通信方式

> 通过**发布者/订阅者**来通信，有一个发送消息的频道

1. 哨兵A发送一条消息到频道中，比如自己的ip和端口号
2. 其余哨兵订阅了这个频道，所以能收到哨兵A发送的消息，比如ip端口号，这样就可以建立连接
3. 哨兵节点之间收到各自的ip和端口之后，就建立了哨兵集群

#### redis过期删除策略

> redis采用：惰性删除+定期删除，下面介绍这几种删除策略

当key设置了过期时间，将key和过期时间保存到字典中，每次查询判断key是否在字典中：

1. 在字典中，判断过期时间**与系统时间的关系**从而判断是否要删除
2. 不在字典中，说明不过期

- 定时删除：创建定时时间，时间到达自动删除过期的key

- 惰性删除：不主动删除key，只有判断当前key过期才删除，删除之后给客户端返回null

- 定期删除：每一段时间检查一部分key是否过期，过期就删除，当这部分key过期的数量太多（<u>过期的怎么这么多？再看看其他的</u>），那么就继续检查下一部分

#### redis持久化时，过期键处理方式

1. RDB文件生成阶段：生成时对key进行过期判断，所以RDB生成的文件中没有过期的key
2. RDB文件加载阶段：
   - RDB文件加载到主库，先判断，过期的key不加载
   - RDB文件加载到从库，不判断，过期的key也加载
3. AOF文件写入阶段：没删除的过期keyAOF文件直接保留，被删除的过期keyAOF文件中追加一个DEL命令显式标记
4. AOF重写阶段：已过期的key相当于冗余，并且此时有一个DEL标记，不保存到新的AOF文件中

#### redis主从模式中，过期键处理方式

1. 主库：key到期，会在AOF文件中使用一个DEL命令标记，从库同步数据时会删除
2. 从库：除了同步时遇到DEL就删除过期的key，平时不管

#### redis内存满了之后的内存淘汰机制

1. 不数据淘汰：内存满了直接报错（**默认**）
2. 进行数据淘汰（分为局部淘汰和全局淘汰）：
   - 在**过期数据**中淘汰（局部）
     - 随机淘汰
     - 淘汰最早过期的
     - 淘汰所有
     - 淘汰最少使用的
   - 在**所有数据**中淘汰（全局）
     - 随机淘汰
     - 淘汰最久未使用的
     - 淘汰使用最少的

#### redis中的LRU（最近最少使用）：时间

> **传统**的LRU是使用链表组织数据，最新访问的数据在链表头，淘汰时优先淘汰链表尾

redis中给数据的结构中添加一个**最后一次访问时间**字段，然后淘汰时随机选5个值，淘汰最久没有使用的那个数据

如果某一次读取大量数据，这些数据的最后一次访问时间就会更新，后续不再使用的话，会在内存中保留很长一段时间：**缓存污染**

#### redis中的LFU（最近最不常用）：次数

> 相比于LRU中根据时间判断，LFU根据访问次数判断，这根据程序的时间局部性原理

redis给数据的结构中添加一个**最后一次访问时间**和**访问频次**（初始化为5）的字段

当数据被访问时，**先**按照访问时间间隔来减小访问频次，减小之后**再**增加，访问频次越大的数据增加的幅度越小

删除时访问频次低的优先删除，访问频次相同时，最后一次访问时间久的优先删除

可以改善缓存污染

#### redis缓存雪崩定义和解决办法

> 当缓存中大量时间在同一时间失效，此时客户端请求就无法在redis中处理，进而全部转到数据库中，请求量过大可能造成数据库**宕机**，从而导致依赖数据库的服务失效，这种**一系列连锁反应**就叫做缓存雪崩
>
> 或者说redis故障，所有的请求都到了数据库，也可能造成缓存雪崩
>
> 这种针对大量数据缓存失效造成的一系列连锁反应称为缓存雪崩

1. 不让大量数据在同一时间失效：将数据的过期时间**打散**，使数据不集中过期
2. 设置缓存不过期：让后台定期更新缓存，使得缓存和数据库中的数据保持一致，从而避免因为缓存失效导致缓存雪崩
3. 大量请求到达，可以执行限流
4. 构建redis高可用集群

#### redis缓存击穿定义和解决办法

> 当某些数据被频繁访问，这种数据称为热点数据
>
> 热点数据失效就会导致该热点数据的很多请求最终到达数据库，请求量过大就可能造成数据库**故障**
>
> 这种针对部分数据失效造成的现象称为缓存击穿

1. 设置**互斥锁**(NX 命令)：保证同一时间只有一个线程请求缓存
2. 热点数据设置为不过期：后台异步更新热点数据，从而不会出现请求访问热点数据过期的问题发生
3. 预热：提前将热点数据载入缓存

#### redis缓存穿透定义和解决办法

> 用户访问的数据**既不在**缓存中，**也不在**数据库中，大量的这种请求到达数据库，这种现象称为缓存穿透，**出现原因**一般有几种：
>
> 1. 业务误操作：缓存和数据库中的数据被误删除
> 2. 黑客攻击：黑客故意删除缓存和数据库中的数据，或者故意访问缓存和数据库中都不存在的数据

1. 非法**请求限制**：当存在恶意请求时，我们直接拦截，不让其访问缓存和数据库
2. 设置**空值**或者**默认**值：缓存和数据库中都没有想要的数据时，此时设置一个空值或者默认值给客户端
3. 设置**布隆过滤器**：快速判断数据库中是否存在目标数据，这样缓存中的数据失效后，根据布隆过滤器也得到数据库中没有，请求就直接不会到达数据库从而引发缓存穿透

**布隆过滤器**：通过散列函数将元素进行映射，并且将对应位置为1，判断元素存在时就根据散列函数映射到对应位置看这个位置是否为1即可

#### 布隆过滤器

> 由初始化都为0的位图数组和N个哈希函数组成，可以快速判断数据是否不存在

1. 使用N个哈希函数对数据做哈希运算，尽可能减小哈希碰撞的概率
2. 将得到的N个哈希值对位图数组长度取模，得到哈希值在数组中的位置
3. 将**每个**对应位置都设置为1
4. 后续查找时也使用N个哈希函数计算再取模来看这些位置是不是1来快速判断是否存在这个数据

> 由于存在哈希冲突，可能两个数据映射到位图数组中的同一位置，例如都映射到了1,3,5，所以：
>
> 1. 布隆过滤器说数据存在，可能是假的
> 2. 布隆过滤器说数据不存在，一定是真的
>
> 所以可以用来快速判断数据是不是**不存在**

#### redis如何缓存热点数据

> 思路：通过数据访问时间排序，留下经常访问的数据

1. LRU算法：根据数据的访问时间排序，定期删除访问时间太久远的数据，并且更新一部分新的数据到缓存中
2. LFU算法：根据数据的访问时间更新数据的访问频次，先衰减再更新，按照更新后的访问频次决定数据的去留

#### 缓存更新策略

1. 旁路缓存(Cache Aside)：应用程序**直接与数据库和缓存**打交道（适合读多写少的情况，此时才不会造成缓存的频繁更新，降低缓存命中率）
   - 写策略：出现写数据的请求时，先写入数据库，然后删除缓存
   - 读策略：缓存中命中直接返回，没命中先查数据库并存入缓存，最后返回给用户
2. Read/Write Through（读穿 / 写穿）策略：应用**只与缓存**交互，数据同步由缓存自己控制
   - Read Through：先读缓存，存在就返回，不存在**由缓存**从数据库中读取并写入缓存，最后返回给客户端
   - Write Through：如果缓存中有数据则更新，之后**由缓存**更新数据库，缓存中没有则直接更新数据库
3. Write Back（写回）策略：只更新缓存并将其设置为**脏数据**，后期**异步**更新数据库

#### 数据库和缓存保持一致性

1. 先更新数据库还是先更新缓存都可能造成数据不一致问题

2. 先**删除**缓存再更新数据库可能造成数据不一致问题

   > 这两种情况可以加上分布式锁

3. 先更新数据库再**删除**缓存数据不一致的概率很低，因为缓存更新的速度快，但是由于删除了缓存，所以造成缓存命中率低

   > 删除缓存而不是更新缓存是因为删除缓存带来的代价更小，更新数据库又更新缓存，在同一时间内造成的压力太大

#### redis延迟队列实现

> 把当前要做的事情，往后推迟一段时间再做

可以用ZSet实现延迟队列，因为他有一个score属性记录延迟执行的时间，之后轮询其中的所有消息，判断是否达到执行时间：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97.png" alt="img" style="zoom:53%;" />

#### redis管道

> 正常的redis由于是单线程执行命令，所以每条命令执行后都要等待
>
> 管道技术可以一次性发送多条命令，减小命令执行的等待时间

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%85%AB%E8%82%A1%E6%96%87/%E7%AE%A1%E9%81%93%E6%A8%A1%E5%BC%8F.jpg" alt="img" style="zoom:33%;" />

#### redis事务

> 主要是为了**防止别的命令插队**
>
> 1. 开启事务
> 2. 命令入队
> 3. 收到exec之后开始执行命令，然后返回所有命令的执行结果

redis中事务运行出现错误时，并**不会回滚**，并且错误发生之前的操作依然有效，也就是**不保证原子性**

1. redis生产环境中很少产生事务的报错
2. 支持事务回滚与redis简单高效的设计理念不符

#### redis分布式锁

> 在**分布式**情况下，控制资源在同一时刻只能被一个应用访问，可解决分布式下的并发问题

```java
SET lock_key unique_value NX PX 10000 
```

上面的命令就是加锁操作，一共有四个主要部分，分析几个参数的意义：

1. lock_key：设置一个锁变量lock_key，加锁时插入，解锁时删除
2. NX：利用Redis中的NX参数属性（存在插入失败，不存在插入成功）来进行加锁解锁，一旦存在lock_key，此时说明被加了锁，客户端需要等待
3. PX：给锁变量设置过期时间，防止客户端出现错误阻塞，其余客户端也无法使用当前资源
4. unique_value：解锁时需要判断当前客户端是否是加锁的客户端，是的话才解锁，也就是判断unique_value
5. 原子性：利用Lua脚本（redis内部保证lua脚本执行的原子性）保证加锁解锁的**原子性**

#### 分布式锁的优缺点

1. 性能高效：redis本身是共享存储系统，可以存储分布式锁，并且基于内存，性能高效
2. 实现方便，利用NX（插入失败代表存在锁，插入成功代表加锁成功）的特点就可以实现分布式锁
3. 避免单点故障：redis是集群化的

---

1. 超时时间不好设置：短了可能没用完资源就被抢了，设置长了可能阻塞的客户端较多
2. redis的**异步复制**导致分布式锁不可靠：在主节点加了锁（利用NX插入变量），其余节点没有同步，其余节点中还是可以加锁（利用NX插入变量成功）

#### redis解决分布式锁的不可靠 

> 分布式锁的不可靠主要是因为redis的**异步复制**，在一个节点加了锁（利用NX插入变量），其余节点还没有复制，但是此时在剩下的节点又加锁（利用NX插入变量又成功）

1. 设计了RedLock，**依次**对每个节点加锁，超过一半的节点加锁都成功才可以获得分布式锁
2. 给大多数节点加锁成功，此时锁的过期时间需要重新计算（加锁耗费了时间）
3. 如果剩下的过期时间内不足以完成对共享资源的操作，那么就释放锁，防止还没操作完锁就过期了

#### redis中的Lua脚本

主要是为了保证redis中的一些命令操作的**原子性**，因为redis中的事务无法保证原子性
