---
title: "系统面经"
description: "系统面经"
keywords: "系统面经"

date: 2024-03-19T08:47:11+08:00
lastmod: 2024-03-19T08:47:11+08:00

categories:
  - 面试
tags:
  - 面经
  - 操作系统
# 原文作者
# Post's origin author name
author: zzzi
# 开启数学公式渲染，可选值： mathjax, katex
# Support Math Formulas render, options: mathjax, katex
math: mathjax
# 原文链接
# Post's origin link URL
#link:
# 图片链接，用在open graph和twitter卡片上
# Image source link that will use in open graph and twitter card
#imgs:
# 在首页展开内容
# Expand content on the home page
#expand: true
# 外部链接地址，访问时直接跳转
# It's means that will redirecting to external links
#extlink:
# 在当前页面关闭评论功能
# Disabled comment plugins in this post
#comment:
#  enable: false
# 关闭文章目录功能
# Disable table of content
#toc: false
# 绝对访问路径
# Absolute link for visit
#url: "系统面经.html"
# 开启文章置顶，数字越小越靠前
# Sticky post set-top in home page and the smaller nubmer will more forward.
#weight: 1

# 开启各种图渲染，如流程图、时序图、类图等
# Enable chart render, such as: flow, sequence, classes etc
#mermaid: true

---

> 🥽 系统面经

本文中主要介绍一些操作系统相关的面试题，资料来源于[小林coding](https://xiaolincoding.com/)，文章长期更新，先介绍了CPU和内存的相关知识，在这个基础上引入了运行在cpu和内存中的进程的相关知识，之后针对页面，进程，磁盘的调度算法做了研究，最后就是一些文件系统，输入输出设备的相关知识，相当于围绕了一个计算机来介绍内部的相关知识

<!--more-->

#### 冯诺依曼模型

> 运算器，控制器，存储器，输入输出设备

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C/%E5%86%AF%E8%AF%BA%E4%BE%9D%E6%9B%BC%E6%A8%A1%E5%9E%8B.png" alt="img" style="zoom:53%;" />

#### 内存

1. 基本存储单位为字节，1字节等于8位
2. 内存地址从0开始编号，类似于**数组**，读写任何一个数据速度一样

#### 中央处理器CPU

1. 32位cpu一次最多可以处理四个字节（32位），能计算的最大整数就是`2^32=4,294,967,296-1`，算上0
2. 64位cpu一次最多可以处理8个字节（64位），因为每个字节8位，
3. 一个地址单元就有8bit，所以64位一次只能处理一个地址单元，32位两次才能处理一个
4. 32位cpu能表示的最大值为2^32，也就是超过4GB的数据就无法表示了，64位机器只用了**48位**来表示虚拟内存的大小，也就是258T
5. cpu内部的控制单元：负责控制cpu工作
6. 逻辑运算单元负责运算
7. 寄存器分为几种：
   - 通用寄存器：存放需要运算的**数据**
   - 程序计数器：存储下一条**指令**的地址
   - 指令寄存器：保存**正在执行的指令**

#### 总线

> 用于CPU和其他设备之间的通信

1. 地址总线：指定CPU要操作的内存地址
2. 数据总线：读写内存中的数据
3. 控制总线：发送和接受各种信号，cpu收到信号之后进行响应，例如中断，设备复位
4. 系统总线：CPU向内存中读数据时，地址先放到系统中线上
5. 存储总线：I/O Bridge将系统总线上的数据放到存储总线上，便于向内存中读数据

#### 线路位宽和CPU位宽

> 一个地址单元大小为8bit，也就是1Byte
>
> 电压高表示1，电压低表示0，所以可以通过**操作电压**传输数据

1. 线路位宽表示地址总线**能访问的内存地址范围**大小，1条总线能表示0,1，两条总线能表示00,01,10,11个地址,32条总线能标识2^32=4G大小范围，一个地址单元大小为8bit（1字节），也就是能访问4GB数据

   > 这里只是说能访问的范围是4GB，但是32位机器每次只能处理4B四字节，64位机器每次只能处理8B八字节

2. CPU位宽表示能**处理的数据范围大小**，CPU位宽最好不要小于线路位宽，否则读取到了这么大的数据cpu也无法一次处理，并且32位CPU只能处理4GB范围内的数据，超过范围的**无法表示**这么大的地址

#### 程序执行的基本过程

> 程序执行时需要翻译成汇编代码，最后变成机器码
>
> 数据和指令分开存放，数据存放到**数据段**，指令存放到**正文段**

1. 程序被翻译成汇编代码，最终变成机器码，也就是要执行的指令
2. CPU根据程序计数器的内存地址拿到将要执行的指令放到寄存器中
3. 将拿到的指令放入指令寄存器中
4. 根据指令类型将指令交给不同的单元执行，例如计算指令交给运算器
5. 程序计数器根据指令的长度自增，便于拿到后面的指令
6. 上面的过程会不断循环，不停地读指令，这个过程称为CPU的指令周期

#### 指令

> 指令在执行时需要先成为汇编代码，然后翻译成机器码
>
> 不同的指令集有不同的编译方式

1. 不同的CPU有不同的指令集，也就是不同的汇编语言和机器码
2. 不同的汇编代码被指令集**映射**成对应的0,1形式的机器码
3. 指令执行时最终被加载到控制器中，然后进行**解析**执行
4. 解析就是将机器码进行分解，得到地址和操作数
5. 最终将得到的结果写回

#### 指令的类型

1. 数据传输：store，load，mov
2. 运算：加减乘除，位运算，比较大小
3. 跳转：if-else，switch-case
4. 信号类型：发生中断的trap
5. 闲置：nop

#### 时钟周期与cpu主频

**时钟周期是主频的倒数**，主频表示一秒钟**产生多少次数的脉冲信号**，产生的脉冲信号越多，代表运算速度越快，一次信号就是一个周期，相当于表示一秒钟产生多少个时钟周期，**倒数**就可以计算一个时钟周期的时间

#### 指令的执行速度

> 与时钟频率有关，一个时钟周期内只能完成一个动作，一条指令需要若干时钟周期

<img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240506153214159.png" alt="image-20240506153214159" style="zoom:50%;" />

1. CPU的时钟频率越快，指令执行越快
2. 同一条指令，涉及到的操作越少执行越快，因为经历的时钟周期少

#### 存储设备的速度

> 从高到低，存储设备只与相邻的打交道，**一级一级**的传递数据

1. 寄存器：cpu正在处理的数据放在寄存器中，肯定最快，一般半个时钟周期就能读取数据
2. **cpu三级缓存**，越小越快：这里成为数据和指令缓存，离CPU也比较近，使用的是**SRAM**的芯片，静态是因为他是晶体管，有电数据就在，不像电容会漏电，数据会慢慢丢失
   - 一级缓存：指令和数据**分开存放**，一般2-4个时钟周期就能读取数据，几十KB-几百KB
   - 二级缓存：读数据的速度一般在20-20个时钟周期，大小一般为几百KB-几MB
   - 三级缓存：读数据的速度一般在20-60个时钟周期，大小一般为几MB-几十MB
   - 其中L1和L2是每个cpu核心独享的，L3是多个核心共享的
3. 内存：使用**DRAM**的芯片，数据存储依靠会**漏电的电容**，所以需要动态刷新内存保证数据不丢失，一般读取速度在200-300个时钟周期，晶体管当开关，用来控制给电容充电
4. 硬盘：速度最慢，但是数据可以**持久化**存储
5. 数据访问时是**一级一级的访问**，并不会越过某一个设备直接访问内存或者硬盘

#### 计算密集型和I/O密集型任务

1. 计算密集型：系统大部分时间是在利用CPU进行计算，I/O的事件可以忽略不计、
2. I/O密集型：系统大部分时间消耗在I/O数据上，CPU利用率并不高

#### CPU cache的结构：

> 由多个**cache line**组成，是CPU从内存中读取数据的基本单位，太大可能出现**伪共享**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/Cache%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="img" style="zoom: 33%;" />

每一个cpu line分为**头标志和数据块**

#### CPU怎么知道要访问的数据在缓存中

> 要访问的内存地址与缓存之间有**映射关系**，直接根据映射关系判断是否存在

1. CPU读取数据到缓存中的单位是cache line，多个cache line组成一个cache

2. 当cpu想要访问某一个内存块时，内存块与缓存之间有一定的连接映射关系：

   1. **直接映射**（一对一）：一个内存块只与一个缓存块对应，内部使用**哈希函数**做映射

   2. **全相连**（一对ALL）：一个内存块可以与缓存中的所有块建立连接，更加灵活，成本更高

   3. **组相连**（一对N）：前两种的折中，cache分为很多组，每一个内存块可以映射到组内的任意缓存块，相对灵活且成本较低

      > ==对比虚拟内存和物理内存的映射==

3. 根据不同的链接映射关系先去缓存中找，找到了就直接用，没找到就向下访问

#### 如何让代码跑得更快

> 代码存储到缓存中才能使其跑得更快，而代码又分为指令和数据
>
> 数据顺序访问，指令提前缓存，一个线程不要访问多个核心，因为L1和L2是核心内独享的

1. 提高**数据**的缓存命中率：例如访问数组这种连续存储的数据时，尽可能按照顺序访问，不要跳跃式的访问
2. 提高**指令**的缓存命中率：利用CPU的**分支预测器**，如果可以预测到接下来应该执行代码的哪个分支，提前将这些代码缓存，就可以加快执行速度
3. 防止因线程切换导致缓存命中率降低：多核cpu中，一个线程的执行涉及到多个核心。而一二级缓存是核心内独有的，这样切换会降低缓存的命中率，**可以将线程绑定到某一个核心中，不让其切换核心**

#### 缓存和内存一致性

> 当cpu操作产生新数据后，需要**写**入cache，然后从cache写入内存，这其中涉及到缓存和内存的**一致性**

1. **写直达**：把数据**同时**写入内存和cache中，这种每次都写入内存的方法花费的时间更多
2. **写回**：需要写数据时，判断当前数据将要存入的缓存内的数据是什么状态
   - 如果当前数据是脏数据，也就是缓存和内存中不一致的数据，此时触发写内存操作
   - 如果当前数据是旧数据，那么直接覆盖，并且将当前数据标记为**脏数据**
   - 后期仅当当前被覆盖的数据是**脏数据要被覆盖时才写入内存**，减少内存的写入次数
   - 根据时间局部性原理，当前缓存的数据命中率大大提高
3. 主要是确定什么时候写入内存

#### 缓存之间的一致性

> cpu多核之间只共享第三级缓存，前两级缓存是核心内独有的，所以存在缓存不一致问题，指的是多核心的L1和L2的缓存一致性
>
> 基于总线嗅探的MESI协议

1. 第一个核心操作数据x，将其+1，之后利用写回的策略，只会更新第一二级缓存
2. 第二个核心也操作数据x，此时从内存中读取到的数据是旧的，因为第一个核心已经修改过了
3. 有两种策略：
   1. **写传播**：核心内的cache更新时，必须**传播**到其他核心的cache中
   2. **串行化**：核心对数据的操作不管哪个核心看都是**顺序一致**的，也就是数据先+100，后*200，顺序要一样才能保证缓存同步
4. 基于**总线嗅探**的**MESI协议**就可以实现缓存一致性

#### 总线嗅探

> 数据发生变化就**广播**，可以实现写传播

1. 一个核心修改了数据之后，通过总线进行广播
2. 其余核心收到广播之后，判断自己的缓存中是否有这个数据，有的话就更新

#### MESI协议

> 给缓存中的数据增加状态，每种状态访问权限是不同的

- *Modified*，已修改：数据被修改过，还没有同步到内存
- *Exclusive*，独占：数据没被修改，但是独占
- *Shared*，共享：数据没被修改，且共享
- *Invalidated*，已失效：数据是无效的，不能读取该数据

1. 独占数据直接读写，一旦有多个内核读取独占数据，独占将变成共享
2. 一旦当前共享数据要被修改，其余核心中的数据就变成无效，当前核心内的数据变成已修改
3. 当前已修改数据要被替换时，要先写入内存，可以立即为脏数据
4. 后续要访问的数据是已修改状态时，要先写入内存再访问

#### CPU伪共享

> 不同的核心读取的是**同一个内存块**的**不同数据**，基于**MESI**协议就会造成伪共享

1. 核心1读取数据A，核心2读取数据B
2. 由于A,B在同一个内存块中，所以这个内存块被标记为共享
3. 核心1修改数据A，会将核心2的内存块标记为已失效并将自己标记为已修改
4. 但是核心2想操作的数据B并没有变化，这种共享了还是没用的情况称为**伪共享**
5. 核心2要想操作B，需要先将已修改的A的内存块写入内存，然后从内存读取
6. 但是实际是二者之间没有影响，操作的是不同的数据，只是操作的不同数据在同一个cache line，**修改状态的范围太大了**

**解决办法**

1. 热点数据**避免**放到同一个内存块中
1. 配置内核参数，使得A和B不放在同一个内存中

#### 中断

> 在CPU执行期间，由于内外部或者程序预定的事件导致CPU暂停正在执行的事情
>
> 分为硬中断和软中断是为了防止**中断执行时间太长**或者**丢失中断**

1. 中断分为硬中断和软中断，也就是上半部分和下半部分
   - 硬中断：直接处理前期**硬件请求**等需要快速响应的事件，耗时较短，后半部分的工作交给软中断
   - 软中断：硬中断后续的工作就由软中断完成，耗时较长
2. 软中断的情况：
   - 网络收发
   - 定时
   - 调度

#### 浮点数存储方式

**符号位+指数位+尾数**

1. 十进制浮点数转化成二进制，整数除2取余，小数乘2取整

2. 浮点数在计算机内存储是按照**二进制**，所以有的浮点数并不精确

3. 因为转二进制时就**无法精确转换**

4. 针对1001.1101，**规格化**为1.0011101*2^3，其中符号位为0，指数位为3，尾数为0011101，不存储整数位的1，这样多一位，精度更高

5. 单精度float和双精度double的区别就在于这三个位置所占位数

   - float占4字节，32位

   - double占8字节，64位

     ![image-20240319160459912](C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240319160459912.png)

将小数转换成二进制小数之后，进一步规格化，然后确定符号位，指数位以及尾数位

1. 符号位，正数为0，负数为1

2. 指数位：为了防止出现负数造成麻烦，所以float加上127的**偏移量**，要计算十进制数时再减去127，double加上2055 

   > 例如当前指数位是-8，加上127变成119，转换十进制时119-127还原成`-8`即可

3. 尾数位：小数点后的就是尾数位，由于是小数，所以不够的在**后面**补零，不存1，这样尾数位可以多一位，存储的精度更高

#### 负数为什么要用补码

> 除符号位外，剩下所有位取反+1

为了**统一操作**，这样就和正数的操作方法一样了，最终的得到的结果按照补码转换即可

#### 内核

> 运行在应用程序和硬件之间的一层结构，可以隔离硬件的差异，提供统一的接口，所有app共享

1. 内核存在的意义是为了**统一硬件设备的操作**，应用程序与内核交互即可，不用关心如何操作硬件设备
2. 并且还可以隔离应用程序，防止出现一些高危操作
3. 相当于内核的执行权限更大，操作的空间也更大，应用程序要越权操作时，需要进入内核态
4. linux内核设计的核心理念：
   - 多任务：多个任务可以并行（单核）或者并发（多核）执行
   - 对称多处理：每个CPU低位相同，都可以访问完整的内存和硬件资源
   - ELF：可执行文件链接格式，代码编译成汇编代码，会变成目标代码，链接上需要使用的函数库，形成可执行文件
   - 宏内核：系统功能都运行在内核中，对应的微内核就是只保留核心功能在内核中，剩下的功能下放到用户空间中
5. windows和linux内核类型不一样，windows是**混合**内核，

#### 虚拟内存

> 应用程序使用的内存就是虚拟内存

##### 优点

1. 为了将程序使用的地址**隔离**起来，这样程序之间的地址就不会互相冲突
2. 应用程序只操作自己的虚拟内存，具体到哪一块物理内存由内核映射，对应用程序更加友好
3. 可以使得进程需要的运行内存**超过**物理的内存大小，因为是用时才**换入**，利用请求式的分段或者分页
4. 用于映射的段表或者页表标记了物理地址的操作权限，更加**安全**
5. 降低程序员开发负担，不用关心操作的内存会冲突，因为操作的是虚拟内存

##### 其他

1. 程序使用的虚拟地址与物理地址之间需要操作系统的**MMU**（内存管理单元）来**映射**
2. 有几种管理映射的方式：
   - 分段式存储管理
   - 分页式存储管理
   - 段页式存储管理
3. 表示进程的结构体中存在一个虚拟内存的**结构体属性**，父子进程之间**拷贝共享**的就是这个结构体属性
4. 不同进程之间的结构体不一样，也就是虚拟地址是隔离的

#### 进程打开的过程

1. 分配进程id，创建PCB
2. 给进程分配资源，主要是提供进程运行所必要的数据
3. 如果是子进程的话，还需要**拷贝父进程**结构体中关于虚拟内存和页表的相关内容
4. 如果与父进程之间共享了地址空间，那么此时子进程就会变成线程

#### 虚拟内存的划分

> 进程表示虚拟内存的结构体中有一个属性标识内核虚拟空间和用户虚拟空间的**分界线**

<img src="https://cdn.xiaolincoding.com//mysql/other/3a6cb4e3f27241d3b09b4766bb0b1124-20230309234553726.png" alt="img" style="zoom:33%;" />

1. 32位（4G全部用完）：
   - 用户虚拟空间：00,01,10开头的2^30，刚好3G
   - 内核虚拟空间：11开头的2^30，刚好1G
2. 64位（只利用了**48位**，共256T）：
   - 用户虚拟空间：低位0开头的2^47，刚好128T
   - 内核虚拟空间：高位1开头的2^47，刚好128T
   - 剩下的部分没有分配，称为**空洞**

#### 分段式内存管理

> **段表**来建立桥梁，根据段表找到物理内存分段的起始位置，根据偏移量找到具体的数据所在位置
>
> 按逻辑划分

1. 认为程序由逻辑上的一段一段组成，代码分段，数据分段，栈段等
2. 分段机制下，虚拟地址由**段选择因子**和**段内偏移量**组成：
3. 段选择因子：内部的段号最重要，指向了段表中的某一个段的描述信息，主要包含段的起始位置
4. 段内偏移量：根据段选择因子找到的段的起始位置来进行偏移，最终确定数据的真实位置
5. 需要访问两次内存：一次找到段表，一次找到段内数据
6. 内存分段会造成**外部碎片**，因为段与段之间是分开的，导致一个段的内存空间被释放，可能与空闲内存之间不连续，两个128MB的不连续空间无法当成256MB用
7. 不会造成内部碎片，因为**想要**使用多大的内存就分配多大
8. 为了解决外部碎片，引入了**内存交换**，先将导致不连续内存之间的数据交换到硬盘上，这样就会空出一大部分空闲内存，然后再重新分配交换出去的数据所占的内存

<img src="https://cdn.xiaolincoding.com//mysql/other/6142bc3c917e4a6298bdb62936e0d332.png" alt="img" style="zoom: 25%;" />

> 上图来说，两个空闲的128MB无法当做256MB使用，出现外部内存碎片，可以将中间音乐占用的256MB数据交换到磁盘，之后得到512MB的空闲内存，最后再将音乐的数据交换回来，紧挨着游戏的内存后面放，最终就得到了256MB的空暇内存
>
> 可以理解为音乐向前移动，

#### 分页式内存管理

> 数据存储的基本单位变成了更小的页，使用**页表**来进行映射
>
> 按照固定大小分配，不再按照程序的不同逻辑分配

1. 一个程序可能使用很多页，虚拟页和物理页之间的映射关系保存在页表中
2. 虚拟页想要访问物理页失败时，产生**缺页异常**，此时操作系统会分配一个物理页进行映射，更新页表
3. 内存空间不够，会将最近没使用的页中的数据**写入磁盘**，然后这些页的映射关系重新分配，写入磁盘的过程叫做**换出**
4. 需要的数据不在内存中，就需要**换入**
5. 每次只**加载需要的数据页**，通过**页号+偏移量**确定数据的存放位置
6. 每个进程都有自己的页表，导致页表很大，所以引出**多级页表**
7. **多级页表**：一级页表中存放的时二级页表的地址，一层一层向下
8. **TLB**（页表缓存，快表，**旁路缓存**）：根据程序的局部性原理，存在一些经常被访问的页面，CPU中有一个**页表缓存**专门存储**经常访问**的页面，缓解了多级页表转换速度慢的问题
9. 由于内存分配的最小单位就是页，所以页内可能出现无法使用的**内部碎片**
10. 需要访问两次内存：一次找到页表，第二次找到页内数据

#### 段页式内存管理

1. 先进行分段，段内进行分页
2. 先找到段表中对应的页表位置，然后在页表中找到页面所在位置
3. 需要访问三次内存：第一次找到段表，第二次找到页表，第三次找到数据
4. **优点**：利用分段信息共享（一段数据有实际意义，一页数据没有意义），动态链接等特点，结合分页没有外部碎片，提出段页式内存管理

#### 缺页中断的过程

1. 当前进程发现自己需要的虚拟页对应的物理页**不在**内存中，此时产生缺页中断（先在快表中找，然后再去页表中找，找不到才会缺页中断）
2. 操作系统找到发生缺页中断的虚拟页面，判断其访问的物理内存**是不是合法**的
3. 找到一个空闲的物理页框准备存放当前进程需要的数据，如果没有空闲的物理页，此时会发**生页面置换**，也就是内存满了就触发页面置换
4. 如果页面置换算法选择的页面**被修改**，还需要将这个页面被修改的部分进行**持久化**
5. 尽量选择先置换文件页，后置换匿名页
6. 根据页表中保存的数据在**磁盘中的地址**获取到需要的数据内容，这个磁盘地址是进程加载到内存中时保存的，也就是**进程创建时保存**的，之后将数据加载到物理页中
7. 发生一个中断，**更新页表**中关于虚拟页和物理页中的关系
8. **恢复**缺页中断前的的状态，从发生缺页中断的地方开始执行指令

#### linux缓解预读失效

> 与mysql差不多，改进LRU算法，使用**两个链表**存数据
>
> mysql：young+old
>
> linux：active+inactive

1. 设计一个**活跃**链表和一个**非活跃**链表，两个链表都在page cache中
2. **预读数据**先放入非活跃链表头部，预读失效的数据会先被淘汰，减小影响
3. 数据被使用时，将其拿到活跃链表头部
4. 活跃链表尾部**降级**的数据被放入非活跃链表的头部，并不是真正淘汰
5. 当新数据读入时，最终被淘汰的是非活跃链表的尾部
6. 相当于将数据**分级**，这样就不会影响经常被访问的数据，因为他会被经常拿到链表头部
7. mysql是类似的，只是链表名称叫做young和old。young在前，old**链接**在后
8. redis是使用LFU算法，除了计算数据的使用时间还计算数据的使用频率，根据这两个值淘汰数据

#### 缓存污染相关知识

> 缓存污染是访问了大量的数据，预读失效是预读的数据从来没访问过

1. 缓存污染：短时间内**大量数据**只被访问一次，由于LRU算法的特性，这些只被访问一次的数据很久才会被淘汰，占用缓存空间，被污染了
2. 导致大量热点数据被淘汰，降低缓存命中率
3. 解决办法（提高进入链表头部的**门槛**）：
   - linux：**不是第一次**访问就将其放到LRU链表头部，而是第二次才加入活跃链表头部
   - mysql：根据数据停留在old中的时间判断，**前后两次**访问时间**超过1s**才将数据拿到young链表头部，否则被认为是短时间访问的数据，先不放入young头部

#### 用户虚拟空间格式

> 分为**六个部分**，这些格式之间都有指针作为**分界线**，防止出现**越界**的情况，并且不管32还是64位，用户虚拟空间都是下面的格式，只是大小不同

<img src="https://cdn.xiaolincoding.com//mysql/other/b1402bf81de260b86ce0cb4c19cd4330-20230309233758868.png" alt="image.png" style="zoom:33%;" />

1. 代码段：存放编译好的机器码形式的代码
2. 数据段：存储指定了初值的数据全局变量和静态变量
3. BSS段：包括**未初始化**的静态变量和全局变量
4. 堆段：程序运行期间动态申请的内存
5. 文件映射段：存储程序运行调用的其他库的代码段
6. 栈段：存储运行时调用函数使用的局部变量和参数

#### 内核如何管理用户虚拟空间

> 结构体+链表+红黑树

1. 每个进程设置一个**结构体**，内部划分了用户虚拟内存和内核虚拟内存

2. 用户虚拟内存中的**六个部分**都有自己的结构体，指示了自己的大小，相当于分界

3. 不同部分之间使用双向链表连接，便于遍历

4. 为了便于**查找指定虚拟内存**，还建立了红黑树的结构

   <img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240322100005966.png" alt="image-20240322100005966" style="zoom:70%;" />

5. 虚拟内存和物理内存之间的关系由**页表**映射

6. 页面的访问权限由一个**参数**的不同值决定（可读，可写，可执行。。。）

#### 32位内核虚拟空间格式

<img src="https://cdn.xiaolincoding.com//mysql/other/68763fe509b7adf5987a3ce96c9d12ee.png" alt="image.png" style="zoom:23%;" />

> 32位系统只有1G内核虚拟空间，需要**精细划分**，且所有进程共享内核空间，与64位内核虚拟空间格式不太一样

1. 直接（连续）映射区：这块连续区域映射到的物理内存也是**连续**的，大约896MB
   - 内部存放内核代码和数据
   - 进程创建之后的数据结构也会存放到这里
   - 存放进程调用链的内核栈也存放到这里
2. 内存空洞：大约8M大小的内存空洞
3. 动态映射区：逻辑连续，物理不连续，通过页表映射
4. 永久映射区：可以与物理内存建立永久的映射关系
5. 固定映射区：这个区域中的**虚拟地址不变**，对应的物理地址可以变，这些固定的虚拟地址有固定的用途
6. 临时映射区：存储一些临时的数据

#### 64位内核虚拟空间格式

> 64位虚拟内核空间128T，基本可以**随意挥霍**，所有进程共享，与32位内核虚拟空间格式不太一样，因为他空间足够，**不用精细划分**

<img src="https://cdn.xiaolincoding.com//mysql/other/84eb41fc42b790865eb8bc15d3a2892a.png" alt="image.png" style="zoom:20%;" />

#### cpu从内存中读数据的过程

> 数据传输通过**总线**，IO bridge负责中间的联系

1. 通过总线发起**读事务**
2. 将虚拟地址转换成内存的物理地址，页表起作用
3. 将内存物理地址A放到系统总线上，然后**IO bridge**传输到存储总线
4. 存储总线上一旦有地址信号，存储控制器将物理地址转换成DRAM芯片中的二维地址
5. 二维地址指示了一个**超单元**的地址，内部保存了数据，大小为1字节
6. 根据这个二维地址读取到对应的数据，一次操作的单位是8字节，也就是8个**超单元**
7. 根据这个将数据放到存储总线，IO Bridge将其转换之后放到系统总线上
8. CPU接收到系统总线上的数据，将其接收到之后存入三级缓存或者寄存器中

<img src="https://cdn.xiaolincoding.com//mysql/other/b4c3dc16dbfab2682d46772b787ae962.png" alt="CPU读取内存.png" style="zoom:50%;" />

#### cpu向内存中写数据的过程

> 主要是总线和IO bridge加上存储控制器在工作

> 第一步：定位要写入的物理内存

1. 通过总线发起**写事务**
2. 将虚拟地址转换成内存物理地址，页表就起作用了
3. 将内存物理地址传递到系统总线上
4. 然后IO bridge将系统总线上的内存地址转换到存储总线上
5. 之后存储控制器定位到对应的内存地址

> 第二步：传递要写入的数据

1. cpu将数据放到系统总线上，再次经过IO bridge转换到存储总线上
2. 存储控制器读取到存储总线上的数据，写入刚才指定的内存中

#### 物理内存模型

1. 内核中以struct page来对基本单位页来进行管理，每一个struct page都有一个索引编号PFN。struct page和PFN之间的转换由内核中的两个宏完成

1. **管理**这些struct page的方式称为**物理内存模型**

   - flatMEM **平坦**内存模型：物理内存连续，分配的页面也连续。所以struct page和PFN之间的映射关系可以保存到一个**数组**中，通过偏移量找到下一个struct page

     <img src="https://cdn.xiaolincoding.com//mysql/other/89fe28d0feb1cd31cbaad5352e1f43d9.png" alt="image.png" style="zoom:20%;" />

   - discontingMEM **非连续**内存模型：由于flatMEM按照数组进行管理，一旦物理地址不连续，数组中就会出现很多空洞，于是使用节点node管理每一个断开的连续段，每一个node**内部都是一个数组**，可以类比段页式内存管理：

     <img src="https://cdn.xiaolincoding.com//mysql/other/ae106d5d780328aae34d40560dc0442f.png" alt="image.png" style="zoom:15%;" />

   - sparseMEM**稀疏**内存模型：为了对更小的连续内存小块进行精细管理，相当于node划分的更小，变成了section（128M），并且每个section还带上了在不在线的状态以**支持热插拔**

#### 内存热插拔实现原理

> 主要是要**优雅的拔下**，插上直接等待映射即可，拔下需要保证内部数据还是可用
>
> 可以**迁移**的物理页才能保存到热插拔内存中

1. 分为物理热插拔和逻辑热插拔，**稀疏内存模型**就能支持热插拔
2. 支持热插拔的内存内部存储的全是**可以迁移的物理页**，例如用户空间使用的物理地址，迁移只需要改变虚拟地址和物理地址之间的映射即可
3. 不可迁移的物理页不能保存到热插拔内存中，例如内核空间中的直接映射区，由于是虚拟地址减去偏移计算得到物理地址，所以物理地址不能变，所以不能迁移
4. 一旦内存物理拔掉，此时稀疏物理模型的中被拔掉的section标记为下线
5. 之后完成物理页的迁移
6. 内存插上之后，等待虚拟地址的映射即可

#### 物理内存架构

> CPU访问内存需要经过总线

1. 一致性访问UMA架构：CPU和内存被总线隔开，并且每个CPU到每个内存的距离是一样的（**访问速度一样**，所以称为一致性访问架构），CPU个数增多导致总线压力变大：

   <img src="https://cdn.xiaolincoding.com//mysql/other/79170f0256ed383e3934b99a156911fd.png" alt="image.png" style="zoom: 23%;" />

   优缺点：

   - 每个CPU平等，访问速度一样，且结构简单
   - CPU个数增加，每个CPU的带宽会减小
   - 总线的长度也会边长，因为要连接更多的CPU

2. 非一致性访问NUMA架构：分为本地内存和远程内存，每个**cpu都有自己的本地内存**，访问速度快，内存不够时才访问远程内存，由于是这种**不连续**的内存，所以前面提到的平坦内存模型就**无法使用**：

   > 内存之间使用**QPI点对点内存互联**通信

   <img src="https://cdn.xiaolincoding.com//mysql/other/672a905532a801f8811040265cae2d0f-20230310000450243.png" alt="image.png" style="zoom:23%;" />

   - NUMA中CPU的内存分配策略（先分配本地内存还是远程内存）：
     - 本地和远程都可以
     - 优先在指定节点分配，不够时在距离最近的节点分配
     - 优先在本地，本地不够再远程

#### 内核如何管理NUMA节点

1. UMA架构看做只有一个NUMA节点的伪NUMA架构，相当于**全是本地内存**

2. 针对每一个NUMA节点都建立一个**结构体**

3. 定义一个全局数组node_date，每个数组中的元素都指向一个NUMA节点的结构体

4. 每一个NUMA结构体中都有以下的内容：

   - 节点id

   - 物理模型中管理**一段**连续内存使用到的mem-map数组

   - 节点内第一个物理页的索引编号PFN

   - 节点内可用物理页个数

   - 所有的物理页个数（可用+空洞）

     ![image-20240323102303344](C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240323102303344.png)

5. 每个NUMA节点的物理内存主要划分为：
   - zone_DMA：用于寻址范围有要求的设备，例如ISA设备只能对内存前16MB寻址
   - zone_DMA32：专门提供给64位系统的DMA设备
   - 高端内存：32位系统中使用的非线性映射区
   - zone_DEVICE：支持热插拔的非易失性内存，或者用于内核崩溃保存调试信息
   - zone_movable：保存可迁移数据，为了支持热插拔
6. 针对不经常使用的页面，内核还会定期规整回收
7. 每个节点有一个状态，这个状态在热插拔时变化，在线还是离线

#### 二进制文件如何映射到用户虚拟内存中

> 先放入物理内存，然后调用映射函数做映射，之后CPU就可以调度

1. 根据性质放入不同的区域：二进制文件中的只读内容会放入内存中的只读权限的区域，可读写的数据会被放到可读写权限的区域，要执行的文件会被放到可执行区域
2. 之后内核调用一个**映射函数**完成物理内存到虚拟内存的映射
3. 初始化结构体中的信息，包括进程id，六大部分的起始位置等等
4. 将不同类型的数据映射到虚拟内存中的不同区域
5. 映射建立好之后，用户想要访问时，会根据虚拟地址访问物理地址，可能当前物理地址还没有数据，此时发生缺页
6. 每个应用要访问的数据都有对应的虚拟地址，相当于中间用虚拟地址联系起来

#### malloc分配内存的方式

> 从**用户空间**中分配，也就是分配的是虚拟内存，使用时才会去映射物理内存

1. 使用brk()系统调用从**堆段**中分配，需要的内存大小**小于** 128kb时使用
2. 使用mmap()系统调用从**文件映射区**分配，需要的内存大小**超过**128kb时使用
3. 分配时并不是指定多少分配多少，而是预分配**更大**的空间
4. 分配的空间是虚拟的，只有被访问时才会映射到物理内存中，此时出发**缺页中断**
5. 使用brk()分配的内存free()释放后会放到内存池中，便于后面直接复用，所以使用brk分配内存，有时不需要系统调用，但是缺点是brk分配的内存太小
6. 使用mmap()分配的内存空间free()释放后，会归还给OS，所以如果只用mmap分配内存，每次都需要系统调用
7. 使用brk()和mmap()配合可以提高内存的使用效率
8. free()释放时，内存块有自己的**描述信息**，每次分配内存时会多分配一点存储这个描述信息，从而使得free()可以知道释放多大的内存

#### 分配物理内存的过程

> 根据malloc分配的虚拟内存访问物理内存时，才会触发缺页中断，开始分配

1. 虚拟内存没有分配内存时，会触发缺页中断，此时进行内存分配
2. 有空闲内存直接分配
3. 没有空闲内存就进行内存回收
   1. 后台内存回收：异步进行内存回收，可以**早点触发**后台回收
   2. 直接内存回收：后台内存回收的速度赶不上需要的速度就会**同步**进行内存回收，此时前台的进程会被阻塞
   3. 内存回收后还不够，此时触发**OOM**(Out Of Memory内存溢出)机制，不停地选择内存占用多的进程杀死，回收他们的内存，直到内存够用
4. 回收内存时可以回收**文件页**（干净页直接释放，脏页先写入磁盘再释放）或者**匿名页**（写入磁盘再释放）
   - **文件页**：在**磁盘中有载体**的数据，比如某一个txt文件，这种数据干净页直接释放，脏页写回磁盘再释放
   - **匿名页**：在**磁盘中没有载体**的数据，比如程序运行过程中产生的堆栈数据，先swap到磁盘中，后期要使用再swap回来

#### 页面置换

> 当需要的页面不在内存中，并且此时内存中没有空闲的页面时，就会发生页面置换，这涉及到swap机制
>
> 页面置换算法是为了选择一个页面换出，并且该页面尽可能不在后面被使用，这样会减小换入换出的次数

1. 最佳页面置换：选择**未来**最久不访问的页面换出，但是未来的访问次序并不知道，所以算法**无法实现**，可以作为一个标准衡量其余算法的效率
2. 先进先出置换：选择在内存中停留时间最长的，也就是最先进来的
3. 最近最久未使用：选择最近最久未使用的页面，代价很高，需要维护一个LRU链表，将访问过的页面放到链表头
4. 时钟页面置换：有一个环形链表和一个指针，当前页面被访问，标志位记为1，当前页面没访问，标志位记为0，页面置换时选择一个标志位为0的页面，如果当前位置为1，则现将其置为0，然后找下一个，直到找到0
5. 最不常用置换：选择访问**次数**最少的

#### 如何减小回收内存带来的影响

> 主要是说文件页和匿名页的区别，从而降低影响

1. 尽量**先回收文件页**，因为大部分文件页可以直接释放（不是脏页），不用写入内存，少回收**匿名页**，也就是程序运行过程总动态产生的页面
2. 匿名页回收必须保存到磁盘，因为数据不可复制性太大，磁盘换入换出涉及swap机制
3. 争取**早点进行异步回收**，这样空闲空间就会变大，可以调整**内存的水位线**
4. **重要的进程不杀死**：调整他的一个参数（用来计算被杀死的概率），使其不会因为内存不够而被杀死，也就是手动让其被杀死的概率**降低**，或者直接升级内存

#### 物理内存的水位线

> 当物理内存超过水位线时，开始进行内存回收，阈值规定的是空闲空间的多少

1. 页**最小**阈值：剩余内存在页低阈值到页最小阈值之间时。给当前进程分配完内存**后**，就会**触发内存回收**，一旦超过这个阈值，就会立马触发内存回收
2. 页**低**阈值：剩余内存在页高阈值和页低阈值之间时，说明内存有一定消耗，但是可以接受
3. 页**高**阈值：剩余容量高于这个时，说明内存充足 

#### 物理内存水位线的计算

> 依赖于一个内核参数min_free_kbytes 计算得来

1. 根据内核参数计算出页最小阈值
2. 页低阈值一般为页最小阈值的**1.25**倍
3. 页高阈值一般为页低阈值的**1.5**倍
4. 水位线之间的**间距可调**，根据一个内核参数，根据系统运行情况动态调整水位线，这样可以避免内存回收带来的影响

#### 4G机器申请8G内存

> 分为只分配和分配之后访问，而且分配的还是虚拟内存
>
> 分配之后没开启swap还是不行
>
> 相当于成功只有**64位系统+开启swap**才可以

1. 针对只分配不访问：由于分配的是虚拟内存，只要不访问就不会分配物理内存，所以：
   - 32位机器：用户空间可分配的大小为3GB，也就是虚拟内存最多申请3GB，申请8G会失败，因为其最多表示4GB的内存大小
   - 64位机器：用户空间可分配的大小为128T，也就是虚拟内存最多申请128T，申请8G会成功
2. 分配成功之后（**64位机器才能分配成功**）需要访问：
   - 没开启swap：此时只有4G物理内存，分配8G虚拟内存之后进行访问会出现**内存溢出**的情况，此时进程会被杀掉
   - 开启swap：此时虽然只有4G物理内存，但是由于可以进行换入换出，所以长时间不用的数据会被**换出**，腾出内存空间，从而8G内存空间可以不停地**换入换出**满足需求，效率很低（页面抖动）

#### 进程结构 

1. 进程：正在内存中运行的程序
2. 进程结构：使用**进程控制块PCB**来描述，是进程存在的唯一标识，通过**链表**组织：
   - 进程标识符：进程的唯一id
   - 用户标识符：标识当前进程属于哪个用户
   - 进程状态：运行，就绪，阻塞等
   - 进程优先级：根据这个判断谁先用cpu
   - 资源分配清单：当前进程正在使用哪些资源
   - cpu相关信息：进程切换时保存的cpu状态信息，便于后期进程恢复

#### 创建进程的步骤

> 创建PCB->分配资源->进入就绪队列

1. 申请**空白PCB**，填入控制和管理进程的信息，例如进程的唯一标识
2. 为进程分配运行所需资源
3. 进入就绪队列等待调度执行

#### 终止进程的步骤

> 查找->释放资源->子进程处理->删除PCB

1. 找到进程对应的pcb
2. 如果处于执行状态，直接停止执行，将资源还给cpu
3. 如果进程有子进程，这个子进程变成孤儿进程，将子进程交给1号进程
4. 将pcb从对应的队列中删除

#### 进程的状态

> 进程按照链表组织，例如所有就绪的进程链接起来组成了就绪队列

1. 运行：正在运行
2. 就绪：可运行，但是需要等待cpu
3. 阻塞：不可运行，需要等待某些资源，这些进程通常会被换出到磁盘，等待的资源出现时才会被换入到内存中成为就绪态
6. 可运行，需要等待某些资源，这些进程通常会被换出到磁盘，等待的资源出现时才会被换入到内存中成为就绪态
7. 挂起：进程被换出到磁盘中的状态，分为阻塞挂起和就绪挂起
8. 创建：正在被创建
9. 结束：正在从系统中消失

#### 进程上下文切换

> 从一个进程切换到另外一个进程

1. 进程运行所需的信息保存在PCB中，包括虚拟内存，栈，全局变量，寄存器等内容
2. 进程上下文切换相当于将一个进程的这些信息保存起来。然后将另外一个进程的这些信息加载到内存中运行
3. 一般来说进程执行的时间片到了，资源不足或者程序主动暂停都会引起进程的上下文切换

#### 线程上下文切换

> 引入线程其实是为了共享进程中的数据

1. 当两个线程**不属于同一个进程**，此时上下文切换就和进程上下文切换一样
2. 当两个线程属于同一个进程，此时只需要切换线程**独有**的寄存器和栈的信息即可，其余共享的信息不变

#### 线程实现

> linux中主要分两种线程，第三种轻量级线程也称为

1. 内核线程：在内核中实现的线程，由内核管理
2. 用户线程：在用户空间中实现的线程，在用户态进行管理
3. 轻量级线程（LWP）：在内核中来支持用户线程，用户线程就可以使用内核的功能

#### ！！进程和线程的比较

1. 进程是正在运行的程序，而线程是进程**内部的一条执行流程**
2. 进程是分配资源的单位，线程是cpu调度的单位
3. 进程拥有完整的资源，线程只**独有很少的资源**，例如寄存器和栈，其余的内容都是和进程共享的
4. 线程创建时间快，运行开销小

#### 进程调度原则

> 进程**状态转换**的过程称为进程调度
>
> 调度分为抢占式和非抢占式

1. cpu利用率：保证cpu始终忙碌
2. 系统吞吐量：保证同样时间内运行完成的进程更多
3. 周转时间：进程运行+阻塞+等待的时间尽可能小
4. 等待时间：在就绪队列中等待的时间尽可能小
5. 响应时间：用户请求到得到响应的时间尽可能小

#### 进程调度算法

1. 先来先服务FCFS：当长进程先来时，对后面的短进程不太友好

2. 最短作业优先SJF：长作业很可能长时间得不到响应

3. 高响应比优先：计算进程的响应比，高的先执行：、

   等待时间相同，短作业优先，等待时间过长的长作业也能得到运行机会（由于预先得不到进程的要求服务时间，所以这个算法是**无法实现**的）：

   <img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240324220038192.png" alt="image-20240324220038192" style="zoom:25%;" />

4. 时间片轮转：每个进程都执行一段时间，时间片一般被设置为20-50ms，时间太长会**退化**成先来先服务
5. 最高优先级调度：根据进程的优先级调度：
   - 静态优先级：创建进程时就确定的优先级
   - 动态优先级：进程运行过程中动态变化
6. 多级反馈队列：
   - 多个队列，队列优先级**从高到低**，时间片**从短到长**
   - 新来的进程现在高优先级的队列末尾按照FCFS执行一个时间片
   - 一个时间片没执行完当前进程转到下一队列的末尾
   - 当前队列没有进程，才调度下一队列中的进程
   - 大多数进程在高优先级队列就可以执行完
   - 长进程虽然等待了一段时间，但是轮到自己之后，时间片也会变长

#### 进程通信方式

> 由于进程间的用户空间隔离，内核空间共享，所以通信要通过**内核空间**

1. 管道：**单向**传递数据，需要双向时要创建两个管道
   - 管道中的数据实际上保存在**内核的缓存**中
   - **匿名**管道只能实现父子进程之间的通信：grep前面的 `|`，底层其实创建了多个子进程
   - **命名**管道可以在不相关的进程间通信，相当于创建了一个共享的文件
   - 传输的数据是无格式的流，大小受到限制
   
2. 消息队列：一个保存在内核中的消息链表，每个消息是一个存储块，不是流式的
   - 双方需要协商好通信的**数据格式**
   - 只要消息队列没释放或者操作系统没关闭，此时消息队列就一直在
   - 不适合传输大文件，有**大小限制**
   - 消息队列在内核中：发送消息需要将数据从用户态拷贝到内核态，接收消息需要从内核态拷贝到用户态，存在**拷贝开销**

3. 共享内存：拿出一块虚拟地址，映射到一块共享的物理内存中
   - **避免数据拷贝**，直接开辟一块共享的物理内存，这边写入，那一边就能读到

4. 信号量：是一个整型的计数器用于进程间的**同步和互斥**，保护共享资源，**用户自定义**的
   - 防止共享的内存由于多个进程修改出现版本不一致的问题
   - P操作：将信号量-1，相减之后信号量<0说明此资源不能再被访问
   - V操作：将信号量+1，相加之后信号量>0说明此资源可以被访问
   - P，V操作需要**成对**出现
   - 信号量为1说明是**互斥**信号量，我访问（-1）你就不能访问
   - 信号量为0说明是**同步**信号量，我生产了（+1）你才能访问

5. 信号：**异常**情况下，使用信号来进行通信，系统中定义的
   - 例如ctrl+c强行停止进程就会发送一个SIGINT信号
   - 使用kill -9杀死进程此时会发送一个SIGKILL信号
   - 应用收到信号之后，可以执行系统默认提供的信号处理函数，也可以自定义信号处理函数，JVM就自定义了信号处理函数
6. socket：跨网络通信时使用socket
   - 指定好通信的协议，通信双方的地址，经过bind，llisten，connect，accept或者recvfrom和sendto就可以开始通信
   - 建立连接的socket与真正传输数据的socket不一样,有两个cosket
   - 使用socket本地传输时，直接**绑定到一个本地文件**，不需要绑定ip和端口

#### 临界区和临界资源

1. 临界区：操作共享数据的一段代码，可能出现竞争状态，最多只允许一个线程同时运行
2. 临界资源：一次只允许一个进程访问的资源

#### 进程同步互斥

> 进程通信的一种方式

1. 同步：进程间在一些关键点上需要互通等待与互通消息，这种**互相制约**的等待称为同步，例如必须先吃饭后洗碗，这种制约关系就是同步
2. 互斥：针对某一资源来说，**同·一时间只允许一个**进程操作
3. 锁：加锁可以实现进程互斥：
   1. 访问临界区的线程必须加锁，加锁完成···之后再解锁
   2. 忙等待锁：也就是CAS算法，只要原值不是我们知道的原值，说明当前数据被修改过，就不能进行操作，拿着**新的原值**又去判断
     - 会出现**自旋**情况，也就是不是期待的原值时一直循环判断
     - 出现**ABA**问题，期待的原值是A，拿到的也是A，但是版本不一样，可以加上版本号，挪用公款后面补上，但是也违法了
     - 只能保证**一个变量**的原子操作，因为只能比较一个变量是否改变
   3. 无等待锁：发现期待的值与当前值不符，不进行自旋，而是直接将当前进程放入等待队列，等待后面cpu的调度

4. 信号量：为1代表互斥信号量，为0代表同步信号量

#### 生产者消费者问题

1. 生产者生产数据放到缓冲区，消费者消费缓冲区中的数据

2. 缓冲区互斥访问

3. 生产者消费者之间同步，有了数据才能消费<img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240326101129225.png" alt="image-20240326101129225" style="zoom: 50%;" />

   <img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240326101030782.png" alt="image-20240326101030782" style="zoom: 50%;" /><img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240326101050346.png" alt="image-20240326101050346" style="zoom: 50%;" />

4. 生产者拿到缓冲区的互斥锁之后，开始生产数据
5. 消费者拿到缓冲区的互斥锁之后，开始消费数据

#### 哲学家就餐问题

> 哲学家围一圈，中间有叉子，有两个叉子才能就餐，可能存在死锁，同时先拿左边再去拿右边拿不到

1. 增加互斥量，一次只能一个哲学家就餐，其余哲学家需要阻塞
2. 分奇偶：奇数先拿左再拿右，偶数先拿右再拿左
3. 记录状态：两个邻居都没有进餐时，自己才能进餐，这需要一个状态数组记录哲学家的状态

#### 读者写者问题

> 同一时间允许多个读。读写，写写同一时间互斥

1. 读者优先：有写者直接阻塞，优先读，可能造成写者一直阻塞
   - 只要有读者（数量大于0），后续读者直接进入临界区
   - 针对读者数量的变化操作要**互斥**防止出错
   - 第一个读者进入临界区读数据时，将写者阻塞，后面的**读者直接进来**读
   - 最后一个读者离开临界区后，释放临界区资源，后续读者写者竞争临界区
2. 写者优先：有读者会阻塞，优先写，
   - 只要有写者（数量大于0），后续写者可以直接竞争临界区进行写操作，相当于插队
   - 操作写者数量的变化操作要互斥防止出错，并且**写者之间**竞争临界区也需要互斥
   - 第一个写者拿到临界区之后，直接写，后续的写者只要当前写者写完就可以直接写，读者获取不到临界区可能一直阻塞
   - 最后一个写者写完释放临界区，之后读者写者竞争
3. 公平方式：
   1. 一旦有写者，后面的读者就不能插队，可以设置一个flag，写者到达就p(falg)，读者p(falg)时会被阻塞，相当于不能插队
   2. 没有写者的时候，多个读者可以同时读
   3. 当读者数量为0时释放缓冲区，此时如果有写者就可以获得缓冲区
   4. 相当于等先来的读者读完之后，写者就可以写

#### 避免死锁

> 由于保护共享资源加了互斥锁，加锁不当会产生进程互相死等的情况，同时满足四个条件才会产生死锁：
>
> 1. 互斥条件：多个进程不能同时使用一个资源
> 2. 持有并等待：等待新资源的时候，已经拿到的资源不会释放
> 3. 不可剥夺：自己使用完之前，别的进程无法使用
> 4. 环路等待：两个进程的资源获取顺序形成了环，出现了互相等待的情况

只要破坏四个条件的任何一个就可以打破死锁

1. 互斥条件**无法破坏**，这是由资源的性质决定的，为了安全不能破坏
2. 破坏持有并等待（不等）：进程运行前**一次性分配**所有资源，没分配够就直接等待。
3. 破坏不可剥夺（可剥夺）：申请其他资源失败时，现有的资源会被**释放**
4. 破坏环路等待（不环路）：给所有的资源**编号**，必须按照资源号递增的顺序申请资源
5. **银行家**算法：保证分配资源后不会进入不安全状态（可能死锁），也就是避免死锁
   - 进程需要预先提出自己的最大资源请求
   - 分为最大需求矩阵，已分配矩阵，可用矩阵
   - 给某一个进程分配之后，按照某一种顺序，所有的进程是不是都可以正常运行结束
   - 如果可以说明当前时刻是安全的，可以继续
   - 如果不可以说明当前时刻不安全，不能继续

#### 互斥锁和自旋锁

> 是一种独占锁，mysql中写锁

1. 互斥锁：加锁成功正常执行，加锁失败将线程置为睡眠状态，锁被释放，当前线程被唤醒
2. 第一次上下文切换：加锁失败，会将线程设置为**睡眠**状态
3. 第二次上下文切换：锁被释放，当前线程变成**就绪**状态
4. 自旋锁：加锁不成功一直询问
5. 互斥锁加锁失败会**线程切换**，自旋锁加锁失败会**忙等待**
6. 加锁时间很短时，互斥锁的**线程切换时间比加锁时间消耗更多**，此时应该尽可能选择自旋锁

#### 读写锁

> 类似于读者优先

1. 当前没有写锁，多个线程能并发的持有读锁，当前有写锁，其余线程无法加锁，所以写锁是一个**独占锁**。读锁是一个**共享锁**
2. 读写锁就像读者写者问题一样，分为读者优先，写者优先，公平竞争（使用队列）
   1. 读优先：此时读者进程可以正常加多个锁，但是写者会阻塞
   2. 写优先：读锁加完之后写锁到来，后续的读锁无法加上
   3. 公平读写锁：读锁写锁使用队列，按时间排队

3. 如果可以区分读写场景，读写锁更加合适

#### 乐观锁和悲观锁

1. 悲观锁：认为多线程修改共享资源概率很高，容易出现并发读写问题，所以操作之前必须上锁
2. 乐观锁：认为多线程修改共享资源概率较低，不容易出现并发读写问题，每次先修改，修改之后判断当前数据在修改过程中是不是被其他人修改从而判断是否需要放弃本次操作
   - 记录当前操作前的原值
   - 进行修改
   - 修改之后判断原值是否变化，变化说明修改的过程中被别人修改过了，此时放弃本次修改
   - 修改过后原值没有变化，此时提交修改
   - 像多人编辑文档，git都使用了乐观锁，真的发生冲突让用户自己解决，然后再提交

#### 进程最多可创建多少线程

> 跟多少位的系统以及**每个线程初始分配多少内存**有关
>
> 这个问题域mysql不能超过2000W行差不多

1. 主要取决于进程的虚拟空间多大以及每个线程占用多大
2. 32位系统，进程最多可以占满3GB的用户空间
3. 进程创建线程时，**假如**每个线程默认分配10MB的栈空间，这个大小可以改
4. 当系统中**只有一个进程**时：大约最多可以创建==**300**==个线程，如果将默认分配的栈空间改小，创建的线程数还能变多
5. 另外系统支持的最大线程数，线程ID的最大范围都会限制线程的数量，超过这些范围，线程会创建失败

#### 线程崩溃，进程怎么办

> 普通进程会崩溃，Java中的JVM不会崩溃，因为内部定义了信号处理函数，内部线程出现异常之后，系统发出**信号**尝试中断进程，JVM的**信号处理函数**会将出现错误的线程资源回收，自己正常运行

1. 线程因为访问非法内存崩溃，此时进程也崩溃，因为系统认为这种非法操作可能影响别人，所以干脆让整个进程崩溃

2. 想要进程崩溃，此时就发送一个信号，例如kill -9会发送一个SIGKILL信号，进程收到信号之后，调用信号处理函数（如果有的话）完成最后的处理，最后进程退出

3. JVM就有自己的**信号处理函数**，不使用系统默认的处理函数，一旦出现异常，JVM会完成对应的资源回收后选择继续运行或者退出，更加优雅

4. 相当于进程如果觉得自己“罪不至死”，此时就要**自定义信号处理函数**伸冤，保证自己的正常运行

#### 磁盘调度算法

> 为了提高磁盘的访问性能，使磁头的寻道时间变短，调度的是**访问哪个磁道**

1. 先来先服务：对哪个磁道的访问请求先来，就先访问哪个磁道，磁道的访问可能很分散，导致性能不高
2. 最短寻道时间：优先选择离当前磁头近的磁道访问，但是可能导致某些请求饥饿，因为刺头可能很长时间内都在同一片范围内活动
3. 扫描SCAN（电梯调度）：在一个方向上移动（例如从内向外），移动的过程中响应访问磁道的请求，然后这个方向上没有了就掉头（例如从外向内），中间的磁道请求的响应率高
4. 循环扫描C-SCAN：不掉头，而是只在一个方向上扫描，到头之后又回到开始
5. 优化扫描（LOOK）：到达最远的请求之后直接**掉头**，而不是走到磁道的尽头，这样可以减小磁头移动时间，扫描算法的优化版本
6. 优化循环扫描（C-LOOK）：不是到达尽头才**回到开始**，而是到了最远的请求之后就认为到达了尽头

#### 文件的结构

1. 索引节点（inode）：记录文件的元信息，主要是文件大小，访问权限，创建时间，在磁盘中的位置等信息，是文件的**唯一标识**，存储在磁盘中

   > 需要区分索引节点和文件描述符，索引节点用来描述问加你，文件描述符用来操作文件

2. 目录项：记录文件的名字，索引节点指针以及目录项的层级关系（父子关系）,缓存在内存，相当于一把钥匙

3. 目录项中保存了索引节点的指针，而索引节点又指向了真正的物理地址，从而可以找到数据的存储位置

#### 目录和目录项

> 目录是个**文件**，目录项是表示文件的**数据结构**

1. 目录项表示一个文件的基础信息，包括文件名，索引节点指针以及目录项的层级关系
2. 目录是所有目录项的集合，是一个文件，本身也有目录项
3. 内核会将进程访问的目录对应的目录项保存到内存中加快访问速度

#### 文件的使用过程

> 主要就是根据各种系统调用的函数

1. 通过open函数打开文件，得到文件的文件描述符
2. 调用read或者write来操作文件中的数据
3. 之后调用close来关闭文件
4. **每个进程**打开的所有文件会被维护在一个**文件打开表**中，主要有以下内容：
   - 文件指针，当前进程读写到了当前文件的什么位置
   - 文件打开计数器，当前文件被多少文件打开了
   - 文件磁盘位置
   - 文件访问权限
5. 文件系统操作的基本单位是**数据块**，一个数据块4k，相当于8个磁盘扇区（512B）

#### 文件在磁盘中的存储

> 文件的索引节点也要存储到磁盘中，目录项缓存到内存中，文件系统将磁盘的多个扇区（512B）组成一个逻辑块（4K）

1. 磁盘分为三块区域：
   - 超级块：存储当前文件系统的数据块的个数
   - 索引节点区：存储文件对应的索引节点
   - 数据块区：这里存储的就是真实的文件或者目录了
2. 目录项缓存在内存中，然后指向索引块
3. 索引块又指向具体的数据块
4. 文件数据需要访问时，会载入内存

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/%E7%9B%AE%E5%BD%95%E9%A1%B9%E5%92%8C%E7%B4%A2%E5%BC%95%E5%85%B3%E7%B3%BB%E5%9B%BE.png" alt="img" style="zoom: 33%;" />

#### 文件在数据块中的存储

> 这是文件在磁盘中的**数据块**的组织形式

1. 连续空间存放：文件存放在磁盘中的连续空间中
   - 需要在文件头中指定文件的大小和起始块的位置才能知道分配多大的连续空间
   - 有**磁盘碎片**：文件间存在无法利用的小碎片，此时需要挪动文件的位置从而将小碎片进行整合，但是这样消耗过大
   - 文件大小不易扩展，可能文件后面紧挨着另外的文件，没地方扩展，此时需要新申请更大的连续空间
2. 非连续空间存放：
   - 链表：文件被分成一个一个的链表块，分为两种
     - **隐式**链表：链表块之间用指针连接，**只能顺序访问**找到某一个链表块
     - **显示**链表：针对每一个链表块的指针，单独将其保存到一张**内存分配表FAT**中，这样要找某一个链表块，直接从表中读取到指针即可
   - 索引：每个文件都有一个**索引数据块**，内部存放文件数据块的指针
     - 存储这个索引有单独的开销，即使文件很小也需要索引
     - 文件过大一个索引存不下
       - 链式索引：一个索引数据块指向一部分文件数据块，然后还有一个指针指向下一个索引数据块（索引数据块间使用链表连接）
       - 多级索引：索引块中存放的还是索引

3. Unix中采用**上面几种方式的融合**：
   1. 文件所需数据块小于10块，直接查找，每个数据块一个指针
   2. 超过10块，使用一级索引，索引块中存放数据块的指针，需要访问磁盘两次
   3. 还存不下使用二级索引，索引中存放的是索引，二级索引中才存放数据块的指针，需要访问磁盘三次
   4. 还存不下使用三级索引，第三级索引中才存放数据块指针，需要访问磁盘四次
   5. 一共需要13个指针，直接索引10+一级1+二级1+三级1

#### 空闲空间管理

> 管理磁盘中的空闲区域，后期分配磁盘空间时更加方便

**空闲表法：**

1. 所有的空闲块维护在一张表中，包含第一个块号和这个空闲区域包含几个数据块
2. 分配空间时顺序查找到一个**合适**的空闲区域，既不能大也不能小
3. 释放空间时，按顺序找到一个表中的条目，将释放空间的第一个块号和释放的块数填到表中
4. 只适合管理少量空闲区，适用于建立连续文件

**空闲链表法 ：**

1. 空闲数据块之间使用链表维护
2. 创建文件需要几个数据块就从链表头取下几个
3. 释放空间时将数据块依次加入链表头即可
4. 不适合大型文件系统，因为这使得链表太长，占用空间太多

**位图法：**

1. 磁盘每一个盘块都有一个二进制位与之对应
2. 值为0代表盘块空闲，值为1代表盘块已分配
3. linux采用位图管理空闲空间

#### 文件系统结构

> 由**引导块和块组**组成

1. 引导块：用于系统启动时引导，引导操作系统来读取文件系统中的块组
2. 块组包含的内容如下：
   - 超级块：包含inode个数，磁盘块个数，每个块组中空闲块和inoide的数目
   - 数据位图和inode位图：记录哪些数据块和inode块还是空闲的 
   - inode列表：包含块组中所有的inode
   - 数据块：包含文件中的数据

#### 目录的存储

> 目录中存储的是每个文件的基本信息

1. 正常来说采用**列表存储：**
   - 第一项为当前目录`‘.’`
   - 第二项为上级目录`'..'`
   - 后面都是一个一个的文件名和其对应的inode
2. 由于文件太多，都采用列表存储不太好，除了当前目录和上级目录，其余的文件目录项可以采用**哈希**存储，对文件名进行哈希，需要防止碰撞

#### 软链接和硬链接

> 看保存的是文件的inode还是路径，保存inode相当于直接指向文件，是硬链接，保存的是路径相当于需要拿到路径再去访问，是软链接
>
> 删除的时候也有区别，硬链接文件需要等所有的硬链接删除才能删除源文件，软链接不用，因为他都无感知，保存的是路径

1. 硬链接：直接创建一个目录项，其中的inode指向同一个文件，硬指的是直接链接到文件上，所有的硬链接删除才能删除原始文件
2. 软链接：重新创建一个文件，不过文件中保存的是想要链接的文件的**路径**，软指的是不直接链接到文件上，文件被删除这个链接还是在，只是找不到链接的文件而已

#### 文件I/O

> 看是直接与文件交互还是有中间商（缓存），交互时进程是不是阻塞，得到数据是否需要等待

- 缓冲与非缓冲 I/O
  1. 缓冲：利用**标准库的缓存**实现文件的加速访问，然后标准库再通过系统调用访问文件
  2. 非缓冲：直接通过系统调用访问文件，没有标准库的缓存做中间商，中间会经过虚拟文件系统VFS，VFS的作用是为了统一各种文件系统的操作，有点类似于虚拟内存和设备控制器的作用，都是为了**隔离**统一
  
- 直接与非直接 I/O
  1. 直接：直接通过虚拟文件系统操作真正的文件系统，与磁盘中的文件交互
  2. 非直接：引入os的内核缓存，读文件时先从内核读，写文件时先写入内核，由内核与文件交互
  
- 阻塞与非阻塞 I/O
  1. 阻塞：用户访问数据先阻塞，直到内核与文件交互，读取到文件之后从缓冲区传递给用户，用户才开始操作数据
  
  2. 非阻塞：用户发起请求之后就返回，之后一直向内核**轮询**，看数据是否准备好，为了减小轮询的代价，引入了I/O多路复用，数据准备好的事件发生才开始读取数据，分为select，poll，epoll，逐步改进
  
     > I/O多路复用最大的优点就是一个线程可以处理多个I/O请求，其次才是这种时间通知防止轮询的优点
  
- 同步与异步 I/O
  1. 同步：需要等待数据从内核态拷贝到用户态，最终交给用户
  2. 非同步：数据从文件中读取并从内核态拷贝到用户态之后。通知用户，此时用户才读取数据，不会出现等待的情况

#### Page Cache 与 buffer cache

> 在后期的版本中，其实二者已经混在一起了，因为二者**都在内存中**，有了page cache，buffer cache只需要维护一个指向page cache的指针即可

1. page cache :**页**缓存,负责缓存**逻辑**数据。相当于页是逻辑单位

2. buffer cache : **块**缓存,负责缓存**物理**数据。相当于块是物理单位

   > 页是内存中管理数据的**逻辑**单位，块是文件系统中管理数据的**物理**单位，大小都是4KB

3. **通过**文件系统操作数据，操作的是逻辑数据，真正映射到物理磁盘中需要通过文件系统，此时逻辑数据缓存到page cache中，刷新数据需要交给buffer cache完成

4. **越过**文件系统直接操作数据，会被缓存到buffer cache中，例如文件系统的一些元数据就会缓存到这里

5. 引入cache可以加快数据点额读取速度，但是具体如何缓存对应用程序透明，不太好优化，所以部分应用程序自定义缓存机制，例如mysql中的innodb

#### 设备控制器

> 设备提供的可以访问控制自己的工具，工具有一些不同，于是进一步引入了设备驱动程序来屏蔽控制器的差异

1. 每个外设都有自己的设备控制器，描述如何控制自己，例如硬盘有硬盘控制器，显示器有视频控制器
2. CPU通过设备控制器与设备打交道，可以控制对应的设备
3. 设备控制器内部有寄存器保存设备的状态，以及和CPU进行通信
   - 状态寄存器：保存自己的当前的状态，完成工作，正在工作等，便于CPU知晓
   - 命令寄存器：保存CPU传递来的指令
   - 数据寄存器：设备运行所需要的数据
4. CPU为了与这些寄存器通信，有两种方法：
   - 端口I/O：每个寄存器被分配一个I/O端口，通过指令操作寄存器
   - 内存映射I/O：每个寄存器被映射到内存中，CPU像操作内存一样操作寄存器
5. 当设备工作完成后，可能需要通知CPU，此时需要**中断**机制

#### 设备驱动程序

> 为了进一步屏蔽不同设备控制器之间的差异，引入了统一的设备驱动程序，对外暴露的接口是统一的

1. 不同的设备有不同的设备控制器，为了屏蔽设备控制器的区别，此时引入设备驱动程序
2. 不同设别的设备驱动有统一的接口暴露给操作系统，可以用统一的方式接入OS
3. 设备一旦完成了工作，产生中断给CPU，此时CPU在设备驱动程序中响应这个中断

#### 中断

> 计算机运行过程中，发生某个事件后通知CPU来进行处理，CPU不用轮询等待某个事件的发生，化主动为被动，提高CPU利用率
>
> 中断分为两个阶段，第一阶段处理一些必要紧急的事情（硬中断），第二阶段处理一些耗时的工作（软中断），防止中断阻塞或者丢失

1. 硬中断：由外部设备产生（磁盘，网卡等），用来通知操作系统外部设备发生变化
   - 外设将中断请求发给**中断控制器**
   - 中断控制器根据优先级将中断传递给cpu
   - CPU暂停当前程序流，将当前程序的寄存器中的值保存到栈中，转去执行中断处理程序
   - 执行完毕之后恢复没执行完的程序流
2. 软中断 ：可以理解为一条**CPU指令**，由进程产生
   - 进程一旦发出软中断，CPU就转去处理这个软中断处理程序，也会保存寄存器的值到栈中便于后期恢复
   - 执行完毕之后，恢复寄存器中的值，继续执行
3. 不同的设备和进程有不同的中断处理程序
4. 设备初始化时，要将自己的中断处理程序注册进行注册

#### DMA直接内存访问

> 可以使得CPU不用全程参与数据读写的操作，相比中断，cpu的利用率更高，因为他都不需要CPU的参与，CPU可以尽情做自己的事情

1. CPU告诉DMA控制器，自己**需要多少数据，你给我放到哪**，然后就干自己的事情

   > 可以理解为CPU的秘书，有一定的CPU权限，读取数据的全过程不需要CPU参与，只有开始和结束需要CPU的参与

2. DMA控制器给对应的设备发送指令，转告CPU的指令

3. 设备收到命令之后，将数据传递到自己的缓冲区中，然后发送一个成功的信号到DMA控制器

4. DMA控制器收到信号之后，将数据拷贝到内核缓冲区中。发**中断**告诉CPU已经完成

5. 整个过程不需要CPU的参与，CPU只需要去拿到指定位置的数据即可，在DMA控制器传输文件的时候，CPU可以做其他的事情，提高了CPU的吞吐量

#### 输入输出设备

1. 块设备：数据存储在固定的块中，例如硬盘或者USB，数据读写时都会先放入缓冲区，缓冲区中的数据足够才会发给CPU或者设备
2. 字符设备：以字符为单位发送数据，例如鼠标，不可以寻址

#### 通用块层

> 为了减小**块设备带来的差异**，引入通用块层来管理不同的块设备
>
> 相当于在块设备上又封装了一层

1. 给文件系统和应用程序提供统一的访问结构，将不同的块设备抽象成统一的
2. 将文件系统和应用程序发给块设备的请求进行排序，之后进行调度，提高磁盘的读写速度，一共有**五种调度算法**：
   - 不调度：对请求不做处理，一般出现在虚拟机系统中，虚拟机系统的通用块层不做处理，将请求交给外部宿主机的通用块层处理
   - 先入先出：先来的请求先调度
   - 完全公平：按照时间片均匀分配
   - 优先级调度：优先级高的先调度，适用于进程很多的系统，此时请求也会很多
   - 最终期限调度：分别处理读和写请求，保证到达最终期限的请求被优先处理，适用于I/O压力很大的场景

#### 键盘输入A，发生了什么

> 从敲击到显示到屏幕中的过程
>
> 初始化->扫描数据->发中断->中断处理程序将数据转成ACSII码->保存到读缓冲区->显示器驱动程序定期从读缓冲区拿数据，最终可以拿到敲击的字母A

1. 键盘驱动程序初始化时会**注册中断处理程序**，其功能就是从对应的寄存器中读取一个数据，键盘敲击时会**保存到寄存器**中，后续调用中断处理程序就会读取
2. **键盘控制器**将A保存到自己的数据寄存器中
3. 之后发出一个中断，告诉CPU输入了一个A
4. CPU将正在执行的程序的寄存器值保存到栈中便于后期恢复，然后转去执行中断
5. 调用初始化时注册的中断处理程序，读取到A字符，转换成ASCII码
6. 将读取到的数据放入读缓冲区
7. 显示设备的驱动程序定期从缓冲区中读取数据，能拿到这个A，显示到屏幕上
8. CPU恢复之前中断的上下文，相当于每次敲击都会中断

#### 传统文件传输过程

> 需要经过四次文件拷贝和上下文切换

1. 磁盘将数据放到自己的缓冲区中
2. 第一次拷贝：DMA控制器将数据拷贝到内核缓冲区中
3. 第二次拷贝：之后CPU产生中断，从用户态切换到内核态，系统调用**read**，CPU将内核缓冲区中的数据拷贝到用户缓冲区，然后切换回用户态
4. 第三次拷贝：之后再从用户态切换到内核态，系统调用**write**，CPU将用户缓冲区中的数据拷贝到socket缓冲区中，然后切换回用户态
5. 第四次拷贝：之后DMA控制器将其拷贝到网卡的缓冲区中，等待文件传输
6. 这一过程中一共经历了四次数据拷贝和CPU的上下文切换
7. 为了减小上下文切换和系统调用的次数，引入了**零拷贝技术**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/%E4%BC%A0%E7%BB%9F%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93.png" alt="img" style="zoom:50%;" />

#### 零拷贝技术

> 零拷贝代表没有CPU拷贝。以**网络传输文件**为例。有三种实现方式：
>
> 1. mmap+write
> 2. sendfile
> 3. SG-DMA+sendfile：真正的零拷贝，没有CPU拷贝

1. mmap+write：可以减少**一次**系统调用和**两次**上下文切换

   - 用mmap代替上面的read系统调用，减少这次的数据拷贝过程

   - mmap直接将内核缓冲区里的数据**映射**到用户空间，这样就不用拷贝了

   - 之后调用write，进行上下文切换，将内核缓冲区中的数据拷贝到socket缓冲区

   - DMA控制器将其拷贝到网卡中，等待发送

   - 有**四次**上下文切换和三次拷贝。还**不是真正的零拷贝**

     <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/mmap%20%2B%20write%20%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" alt="img" style="zoom: 50%;" />

2. sendfile：

   - 调用内核中专门发送文件的函数sendfile

   - 调用sendfile函数进行上下文切换，然后将用户缓冲区中的数据直接拷贝到socket缓冲区中

   - 之后DMA控制器将socket缓冲区中的数据转到网卡中等待发送

   - 只有**两次**上下文切换和**三次**CPU拷贝，这还**不是真正的零拷贝**

     <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-3%E6%AC%A1%E6%8B%B7%E8%B4%9D.png" alt="img" style="zoom: 50%;" />

3. SG-DMA+sendfile：

   - DMA控制器直接将数据拷贝到内核缓冲区中，数据的长度和描述符会传递到socket缓冲区，代表当前发了什么数据，这里没有CPU拷贝

   - SG-DMA控制器直接将内核缓冲区中的数据拷贝到网卡中，没有CPU拷贝

   - **需要判断自己的网卡是否支持SG-DMA技术**

   - 只有**两次**上下文切换，没有CPU拷贝，这**是真正的零拷贝技术**

     <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" alt="img" style="zoom:25%;" />

4. 大文件传输不应该使用零拷贝技术：
   1. 因为这样会迅速将内核缓冲区占满，导致其余请求无法利用这个缓冲区
   2. 此时应该使用**异步I/O+直接I/O**的形式
      - **异步I/O**指用户发出请求之后，不阻塞等待请求结果，而是请求结果出现后由中断通知
      - **直接I/O**代表用户请求的数据**不经过缓冲区**，直接传输，**防止将缓冲区占满**

#### I/O多路复用

> 为了同时响应更多的请求，同时消耗变小一些，多个请求复用一个进/线程

1. 正常的socket通信模型是阻塞模型，只能一对一通信
2. 进一步引出了多进程/线程通信，可以使得能够通信的数量变多，但是每个线程或者进程会占用内存空间，且上下文切换有负担，还是会有瓶颈
3. 针对上面的问题引出I/O多路复用技术
4. 在**一个**进程里头就可以处理多个I/O通信，每个请求的处理时间很短，可以理解为时分复用
5. 有select，poll，epoll三种I/O通信技术
6. 已连接的socket会交给内核，内核将已发生网络事件的socket交给用户去处理即可
7. select（使用bitsmap存储socket）：将已建立连接的socket集合交给内核，内核检测到内部有网络事件发生，将集合返回给用户，然后用户遍历找到具体发生时间的socket来处理
8. poll（使用链表存储socket）：将已建立连接的socket交给内核，内核检测到有网络事件发生，将socket集合返回给用户，用户再去遍历找到具体发生网络事件的socket
9. epoll(使用红黑树+链表存储socket)：内核使用红黑树存储所有已建立连接的socket，某一个socket发生网络事件，将其加入链表，用户拿到链表不需要遍历，因为全是发生了网络事件的socket

#### Reactor和Proactor

> reactor（同步）

1. 所谓的reactor就是在I/O多路复用基础上做了一层封装，一旦有事件发生，reactor就会做出相对应的反应

2. 相当于I/O多路复用可以接受多个请求，reactor是拿到发生事件的请求之后怎么做

3. 内部使用I/O多路复用监听事件，事件发生交给dispatch分发，建立连接的事件分发给acceptor处理，实际业务事件交给handler处理

4. reactor的进程可以有多个，同时一个reactor可以处理的线程也可以有多个，所以就有四种组合

5. 其实就是看**有几个reactor**，可以**同时处理几个请求**，多个请求来了使用多个handler处理即可

6. 每种组合就是线程多了而已，核心还是上面的**三个部分**，dispatch，acceptor，handler

   <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Reactor/%E4%B8%BB%E4%BB%8EReactor%E5%A4%9A%E7%BA%BF%E7%A8%8B.png" alt="img" style="zoom: 25%;" />

> proactor（异步）

1. proactor相比于reactor来说，处理的事件不一样，reactor监听处理的是**就绪**的事件，proactor监听的是**已完成**读写的事件，但是二者都是将事件进行分发

#### 一致性哈希

>数据或者请求路由的一种策略，如何分发数据或请求到指定的节点

1. 为了解决分布式集群经常**扩容，节点数变化**的问题
2. 正常的负载均衡哈希是按照节点数进行哈希，然后将请求路由到不同的服务器
3. 但是服务器数量一旦变化，相同的请求就会出现被负载均衡到不同的服务器中，如果之前的服务器中存储了请求必要的数据，那么就需要数据迁移
4. 防止这种情况引入了一致性哈希
5. 极端情况下所有的服务器都需要数据迁移
6. 为了解决这种问题引入新的一致性哈希，不对节点数哈希，而是对`2^32`做哈希
7. 先对集群中的服务器哈希，使其映射到`2^32`中的一个位置
8. 后期到来一个请求之后，继续对2^32做哈希，映射到`2^32`中的一个位置，之后向后顺时针找到的第一个节点就是自己需要访问的服务器

<img src="https://cdn.xiaolincoding.com//mysql/other/30c2c70721c12f9c140358fbdc5f2282.png" alt="img" style="zoom:33%;" />

8. 但是节点分布不均匀的话，就会出现大量请求路由到同一个服务器中

9. 此时给这些节点生成**副本**，也就是**虚拟节点**，然后均匀的哈希到`2^32`中的位置上，类似于几个节点**均分**了`2^32`个位置，这样就可以解决不均匀的问题

   <img src="https://cdn.xiaolincoding.com//mysql/other/dbb57b8d6071d011d05eeadd93269e13.png" alt="img" style="zoom:33%;" />
