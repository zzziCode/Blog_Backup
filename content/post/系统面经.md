---
title: "系统面经"
description: "系统面经"
keywords: "系统面经"

date: 2024-03-19T08:47:11+08:00
lastmod: 2024-03-19T08:47:11+08:00

categories:
  - 面试
tags:
  - 面经
  - 操作系统
# 原文作者
# Post's origin author name
author: zzzi
# 开启数学公式渲染，可选值： mathjax, katex
# Support Math Formulas render, options: mathjax, katex
math: mathjax
# 原文链接
# Post's origin link URL
#link:
# 图片链接，用在open graph和twitter卡片上
# Image source link that will use in open graph and twitter card
#imgs:
# 在首页展开内容
# Expand content on the home page
#expand: true
# 外部链接地址，访问时直接跳转
# It's means that will redirecting to external links
#extlink:
# 在当前页面关闭评论功能
# Disabled comment plugins in this post
#comment:
#  enable: false
# 关闭文章目录功能
# Disable table of content
#toc: false
# 绝对访问路径
# Absolute link for visit
#url: "系统面经.html"
# 开启文章置顶，数字越小越靠前
# Sticky post set-top in home page and the smaller nubmer will more forward.
#weight: 1

# 开启各种图渲染，如流程图、时序图、类图等
# Enable chart render, such as: flow, sequence, classes etc
#mermaid: true

---

> 🥽 系统面经

本文中主要介绍一些操作系统相关的面试题，资料来源于[小林coding](https://xiaolincoding.com/)，文章长期更新

<!--more-->

#### 冯诺依曼模型

> 运算器，控制器，存储器，输入输出设备

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C/%E5%86%AF%E8%AF%BA%E4%BE%9D%E6%9B%BC%E6%A8%A1%E5%9E%8B.png" alt="img" style="zoom:33%;" />

#### 内存

1. 基本存储单位为字节，1字节等于8位
2. 内存地址从0开始编号，类似于**数组**，读写任何一个数据速度一样

#### 中央处理器CPU

1. 32位cpu一次最多可以处理四个字节（32位），能计算的最大整数就是`2^32=4,294,967,296`
2. 64位cpu一次最多可以处理8个字节（64位）
3. 一个地址单元就有8bit，所以64位一次只能处理一个地址单元，32位两次才能处理一个
4. 32位cpu能表示的最大值为2^32，也就是超过4GB的数据就无法表示了，64位机器只用了48位来表示虚拟内存的大小，也就是258T
5. cpu内部的控制单元：负责控制cpu工作
6. 逻辑运算单元负责运算
7. 寄存器分为几种：
   - 通用寄存器：存放需要运算的数据
   - 程序计数器：存储下一条指令的地址
   - 指令寄存器：保存正在执行的指令

#### 总线

> 用于CPU和其他设备之间的通信

1. 地址总线：指定CPU要操作的内存地址
2. 数据总线：读写内存中的数据
3. 控制总线：发送和接受各种信号，cpu收到信号之后进行响应，例如中断，设备复位

#### 线路位宽和CPU位宽

> 一个地址单元大小为8bit，也就是1Byte
>
> 电压高表示1，电压低表示0，所以可以通过**操作电压**传输数据

1. 线路位宽表示地址总线能访问的内存地址**范围**大小，1条总线能表示0,1，两条总线能表示00,01,10,11个地址,32条总线能标识2^32=4G大小范围，一个地址单元大小为8bit，也就是能访问4GB数据

   > 这里只是说能访问的范围是4GB，但是32位机器每次只能处理4B，64位机器每次只能处理8B

2. CPU位宽表示能处理的数据范围大小，CPU位宽最好不要小于线路位宽，否则读取到了这么大的数据cpu也无法一次处理，并且32位CPU只能处理4GB范围内的数据，超过范围的**无法表示**这么大的地址

#### 程序执行的基本过程

> 程序执行时需要翻译成汇编代码，最后变成机器码
>
> 数据和指令分开存放，数据存放到**数据段**，指令存放到**正文段**

1. 程序被翻译成汇编代码，最终变成机器码变成指令
2. CPU根据程序计数器的内存地址拿到将要执行的指令
3. 将拿到的指令放入指令寄存器中
4. 根据指令类型将指令交给不同的单元执行，例如计算指令交给运算器
5. 程序计数器根据指令的长度自增，便于拿到后面的指令
6. 上面的过程会不断循环，这个过程称为CPU的指令周期
7. 程序执行时需要翻译成汇编代码，最后变成机器码

#### 指令

> 指令在执行时需要先成为汇编代码，然后翻译成机器码

1. 不同的CPU有不同的指令集，也就是不同的汇编语言和机器码
2. 不同的汇编代码被指令集**映射**成对应的0,1形式的机器码
3. 指令执行时最终被加载到控制器中，然后进行**解析**执行
4. 解析就是将机器码进行分解，得到地址和操作数
5. 最终将得到的结果写回

#### 指令的类型

1. 数据传输：store，load，mov
2. 运算：加减乘除，位运算，比较大小
3. 跳转：if-else，switch-case
4. 信号类型：发生中断的trap
5. 闲置：nop

#### 时钟周期与cpu主频

时钟周期是主频的倒数，主频表示一秒钟产生多少次数的脉冲信号，一次信号就是一个周期，相当于表示一秒钟产生多少个时钟周期，**倒数**就可以计算一个时钟周期的时间

#### 指令的执行速度

> 与时钟频率有关，一个时钟周期内只能完成一个动作，一条指令需要若干时钟周期

1. CPU的时钟频率越快，指令执行越快
2. 同一条指令，涉及到的操作越少执行越快

#### 存储设备的速度

> 从高到低，存储设备只与相邻的打交道，**一级一级**的传递数据

1. 寄存器：cpu正在处理的数据放在寄存器中，肯定最快，一般半个时钟周期就能读取数据
2. cpu三级缓存，越小越快：这里成为数据和指令缓存，离CPU也比较近，使用的是**SRAM**的芯片
   - 一级缓存：指令和数据分开存放，一般2-4个时钟周期就能读取数据，几十KB-几百KB
   - 二级缓存：读数据的速度一般在20-20个时钟周期，大小一般为几百KB-几MB
   - 三级缓存：读数据的速度一般在20-60个时钟周期，大小一般为几MB-几十MB
3. 内存：使用**DRAM**的芯片，数据存储依靠会**漏电的电容**，所以需要动态刷新内存保证数据不丢失，一般读取速度在200-300个时钟周期
4. 硬盘：速度最慢，但是数据可以**持久化**存储
5. 数据访问时是**一级一级的访问**，并不会越过某一个设备直接访问内存或者硬盘

#### 计算密集型和I/O密集型任务

1. 计算密集型：系统大部分时间是在利用CPU进行计算，I/O的事件可以忽略不计、
2. I/O密集型：系统大部分时间消耗在I/O数据上，CPU利用率并不高

#### 如何让代码跑得更快

> 代码存储到缓存中才能使其跑得更快，而代码又分为指令和数据

1. 提高数据的缓存命中率：例如访问数组这种连续存储的数据时，尽可能按照顺序访问，不要跳跃式的访问
2. 提高指令的缓存命中率：利用CPU的分支预测器，如果可以预测到接下来应该执行代码的哪个分支，提前将这些代码缓存，就可以加快执行速度
3. 防止因线程切换导致缓存命中率降低：多核cpu中，一个线程的执行可能在多个核心中。而一二级缓存是核心内独有的，这样切换会降低缓存的命中率

#### 缓存和内存一致性

> 当cpu操作产生新数据后，需要**写**入cache，然后从cache写入内存，这其中涉及到缓存和内存的**一致性**

1. 写直达：把数据**同时**写入内存和cache中，这种每次都写入内存的方法花费的时间更多
2. 写回：需要写数据时，判断当前数据将要存入的地址内的数据是什么状态
   - 如果当前数据是脏数据，也就是缓存和内存中不一致的数据，此时出发写内存的操作
   - 如果当前数据是旧数据，那么直接覆盖，并且将当前数据标记为**脏数据**
   - 后期仅当当前脏数据要被覆盖时才写入内存，减少内存的写入次数
   - 根据时间局部性原理，当前缓存的数据命中率大大提高
3. 主要是确定什么时候写入内存

#### 缓存之间的一致性

> cpu多核之间只共享第三级缓存，前两级缓存是核心内独有的，所以存在缓存不一致问题

1. 第一个核心操作数据x，将其+1，之后利用写回的策略，只会更新第一二级缓存
2. 第二个核心也操作数据x，此时从内存中读取到的数据是错的，因为第一个核心已经修改过了
3. 有两种策略：
   1. 写传播：核心内的cache更新时，必须**传播**到其他核心的cache中
   2. 串行化：核心对数据的操作不管哪个核心看都是**顺序一致**的，也就是数据先+100，后*200，顺序要一样才能保证缓存同步
4. 基于**总线嗅探**的**MESI协议**就可以实现缓存一致性

#### 总线嗅探

> 数据发生变化就**广播**

1. 一个核心修改了数据之后，通过总线进行广播
2. 其余核心收到广播之后，判断自己的缓存中是否有这个数据，有的话就更新

#### MESI协议

- *Modified*，已修改：数据被修改过，还没有同步到内存
- *Exclusive*，独占：数据没被修改，但是独占
- *Shared*，共享：数据没被修改，且共享
- *Invalidated*，已失效：数据是无效的，不能读取该数据

1. 独占数据直接读取，一旦有多个内核读取独占数据，独占将变成共享
2. 一旦当前共享数据要被修改，其余核心中的数据就变成无效，当前核心内的数据变成已修改
3. 当前已修改数据要被替换时，要先写入内存
4. 后续要访问的数据是已修改状态时，要先写入内存再访问

#### CPU伪共享

> 不同的核心读取的是**同一个内存块**的**不同数据**就会造成伪共享

1. 核心1读取数据A，核心2读取数据B
2. 由于A,B在同一个内存块中，所以这个内存块被标记为共享
3. 核心1修改数据A，会将核心2的内存块标记为已失效并将自己标记为已修改
4. 但是核心2想操作的数据B并没有变化，这种共享了还是没用的情况称为**伪共享**
5. 核心2要想操作B，需要先将已修改的A的内存块写入内存，然后从内存读取

**解决办法**

1. 热点数据**避免**放到同一个内存块中

#### 中断

> os接收到**硬件**的中断请求，就会**打断**在执行的进程，响应硬件的请求，所以针对的是硬件

1. 中断分为硬中断和软中断
   - 硬中断：直接处理硬件请求，耗时较短
   - 软中断：硬中断后续的工作就由软中断完成，耗时较长
2. 软中断的情况：
   - 网络收发
   - 定时
   - 调度

#### 浮点数存储方式

**符号位+指数位+尾数**

1. 浮点数在计算机内存储是按照二进制，所以有的浮点数并不精确

2. 因为转二进制时就**无法精确转换**

3. 针对1001.1101，**规格化**为1.0011101*2^3，其中符号位为0，指数位为3，尾数为0011101

4. 单精度float和双精度double的区别就在于这三个位置所占位数

   - float占4字节，32位

   - double占8字节，64位

     ![image-20240319160459912](C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240319160459912.png)

将小数转换成二进制小数之后，进一步规格化，然后确定符号位，指数位以及尾数位

1. 符号位，正数为0，负数为1

2. 指数位：为了防止出现负数造成麻烦，所以float加上127的**偏移量**，要计算十进制数时再减去127，double加上2055 

   > 例如当前指数位是-8，加上127变成119，转换十进制时119-127还原成`-8`即可

3. 尾数位：小数点后的就是尾数位，由于是小数，所以不够的在**后面**补零

#### 负数为什么要用补码

> 除符号位外，剩下所有位取反+1

为了统一操作，这样就和正数的操作方法一样了，最终的得到的结果按照补码转换即可

#### 虚拟内存

1. 为了将程序使用的地址**隔离**起来，这样程序之间的地址就不会互相冲突
2. 可以使得进程需要的运行内存**超过**物理的内存大小，因为是用时才**换入**
3. 用于映射的段表或者页表标记了物理地址的操作权限，更加安全
4. 降低程序员开发负担，不用关心操作的内存会冲突，因为操作的是虚拟内存
5. 程序使用的虚拟地址与物理地址之间需要操作系统的**MMU**（内存管理单元）来**映射**
6. 有几种管理映射的方式：
   - 分段式存储管理
   - 分页式存储管理
   - 段页式存储管理
7. 表示进程的结构体中存在一个虚拟内存的**结构体属性**，父子进程之间**拷贝共享**的就是这个结构体属性
8. 不同进程之间的结构体不一样，也就是虚拟地址是隔离的

#### 进程打开的过程

1. 分配进程id
2. 给进程分配资源，主要是提供进程运行所必要的数据
3. 如果是子进程的话，还需要**拷贝父进程**结构体中关于虚拟内存和页表的相关内容
4. 如果与父进程之间共享了地址空间，那么此时子进程就会变成线程

#### 虚拟内存的划分

> 进程表示虚拟内存的结构体中有一个属性标识内核虚拟空间和用户虚拟空间的**分界线**

1. 32位：
   - 用户虚拟空间：00,01,10开头的2^30，刚好3G
   - 内核虚拟空间：11开头的2^30，刚好1G
2. 64位（只利用了48位）：
   - 用户虚拟空间：低位0开头的2^47，刚好128T
   - 内核虚拟空间：高位1开头的2^47，刚好128T
   - 剩下的部分没有分配，称为**空洞**

#### 分段式内存管理

> **段表**来建立桥梁，根据段表找到物理内存分段的起始位置，根据偏移量找到具体的数据所在位置

1. 认为程序由逻辑上的一段一段组成，代码分段，数据分段，栈段等
2. 分段机制下，虚拟地址由**段选择因子**和**段内偏移量**组成：
3. 段选择因子：内部的段号最重要，指向了段表中的某一个段的描述信息，主要包含段的起始位置
4. 段内偏移量：根据段选择因子找到的段的起始位置来进行偏移，最终确定数据的真实位置
5. 需要访问两次内存：一次找到段表，一次找到段内数据
6. 内存分段会造成**外部碎片**，因为段与段之间是分开的，导致一个段的内存空间被释放，可能与空闲内存之间不连续，两个128MB的不连续空间无法当成256MB用
7. 不会造成内部碎片，因为**想要**使用多大的内存就分配多大
8. 为了解决外部碎片，引入了**内存交换**，先将导致不连续内存之间的数据交换到硬盘上，这样就会空出一大部分空闲内存，然后再重新分配交换出去的数据所占的内存

<img src="https://cdn.xiaolincoding.com//mysql/other/6142bc3c917e4a6298bdb62936e0d332.png" alt="img" style="zoom: 25%;" />

> 上图来说，两个空闲的128MB无法当做256MB使用，出现外部内存碎片，可以将中间音乐占用的256MB数据交换到磁盘，之后得到512MB的空闲内存，最后再将音乐的数据交换回来，紧挨着游戏的内存后面放，最终就得到了256MB的空暇内存
>
> 可以理解为音乐向前移动，

#### 分页式内存管理

> 数据存储的基本单位变成了更小的页，使用**页表**来进行映射

1. 一个程序可能使用很多页，虚拟页和物理页之间的映射关系保存在页表中
2. 虚拟页想要访问物理页失败时，产生缺页异常，此时操作系统会分配一个物理页进行映射
3. 内存空间不够，会将最近没使用的页中的数据**写入磁盘**，然后这些页的映射关系重新分配，写入磁盘的过程叫做**换出**
4. 需要的数据不在内存中，就需要**换入**
5. 每次只加载需要的数据页，通过**页号+偏移量**确定数据的存放位置
6. 每个进程都有自己的页表，导致页表很大，所以引出**多级页表**
7. **多级页表**：一级页表中存放的时二级页表的地址，一层一层向下
8. TLB（页表缓存，快表，旁路缓存）：根据程序的局部性原理，存在一些经常被访问的页面，CPU中有一个**页表缓存**专门存储**经常访问**的页面
9. 由于内存分配的最小单位就是页，所以页内可能出现无法使用的**内部碎片**
10. 需要访问两次内存：一次找到页表，第二次找到页内数据

#### 段页式内存管理

1. 先进行分段，段内进行分页
2. 先找到段表中对应的页表位置，然后在页表中找到页面所在位置
3. 需要访问三次内存：第一次找到段表，第二次找到页表，第三次找到数据
4. 利用分段信息共享（一段数据有实际意义，一页数据没有意义），动态链接等特点，结合分页没有外部碎片，提出段页式内存管理

#### 缺页中断的过程

1. 当前进程发现自己需要的虚拟页对应的物理页**不在**内存中，此时产生缺页中断（先在快表中找，然后再去页表中找，找不到才会缺页中断）
2. 操作系统找到发生缺页中断的虚拟页面，判断其访问的物理内存**是不是合法**的
3. 找到一个空闲的物理页框准备存放当前进程需要的数据，如果没有空闲的物理页，此时会发**生页面置换**
4. 如果页面置换算法选择的页面**被修改**，还需要将这个页面被修改的部分进行**持久化**
5. 根据页表中保存的数据在**磁盘中的地址**获取到需要的数据内容，这个磁盘地址是进程加载到内存中时保存的，也就是**进程创建时保存**的，之后将数据加载到物理页中
6. 发生一个中断，**更新页表**中关于虚拟页和物理页中的关系
7. **恢复**缺页中断前的的状态，从发生缺页中断的地方开始执行指令

#### 用户虚拟空间格式

> 分为六个部分，这些格式之间都有指针作为**分界线**，防止出现**越界**的情况

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/32%E4%BD%8D%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80.png" alt="虚拟内存空间划分" style="zoom:25%;" />

1. 代码段：存放编译好的机器码形式的代码
2. 数据段：存储指定了初值的数据全局变量和静态变量
3. BSS段：包括未初始化的静态变量和全局变量
4. 堆段：程序运行期间动态申请的内存
5. 文件映射段：存储程序运行调用的其他库的代码段
6. 栈段：存储运行时调用函数使用的局部变量和参数

#### 32位内核虚拟空间格式

> 32位系统只有1G内核虚拟空间，需要**精细划分**

1. 直接（连续）映射区：这块连续区域映射到的物理内存也是连续的，大约896MB
   - 内部存放内核代码和数据
   - 进程创建之后的数据结构也会存放到这里
   - 存放进程调用链的内核栈也存放到这里
2. 内存空洞：大约8M大小的内存空洞
3. 动态映射区：逻辑连续，物理不连续，通过页表映射
4. 永久映射区：可以与物理内存建立永久的映射关系
5. 固定映射区：这个区域中的**虚拟地址不变**，对应的物理地址可以变，这些固定的虚拟地址有固定的用途
6. 临时映射区：存储一些临时的数据

#### 64位内核虚拟空间格式

> 64位虚拟内核空间128T，基本可以**随意挥霍**

<img src="https://cdn.xiaolincoding.com//mysql/other/84eb41fc42b790865eb8bc15d3a2892a.png" alt="image.png" style="zoom:20%;" />

#### 虚拟内存整体布局

> 这里介绍的是**32位**的系统，64的系统如上图所示

<img src="https://cdn.xiaolincoding.com//mysql/other/68763fe509b7adf5987a3ce96c9d12ee.png" alt="image.png" style="zoom:23%;" />

#### 内核如何管理用户虚拟内存

1. 设置一个结构体，内部划分了用户虚拟内存和内核虚拟内存

2. 还划分了用户空间内的六个部分之间的**边界**

3. 结构体内部保存了表示每一个部分的结构体，之间使用双向链表连接便于遍历，为了便于查找，还建立了红黑树的结构

   <img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240322100005966.png" alt="image-20240322100005966" style="zoom:50%;" />

4. 虚拟内存和物理内存之间的关系由页表映射

5. 页面的访问权限由一个**参数**的不同值决定（可读，可写，可执行。。。）

#### cpu从内存中读数据的过程

> 数据传输通过**总线**，IO bridge负责中间的联系

1. 通过总线发起读事务
2. 将虚拟地址转换成内存地址
3. 将内存地址A放到系统总线上，然后**IO bridge**传输到存储总线
4. 存储总线上一旦有地址信号，存储控制器就**根据这个内存地址从内存中读取数据**
5. 将读取到的数据放到存储总线上，然后IO bridge将数据转换到系统总线上
6. CPU接收到系统总线上的数据，将其接收到之后存入三级缓存或者寄存器中

#### 如何根据内存地址读取数据

> 主要是存储控制器的功劳

1. 存储控制器将内存地址转换成内存DRAM芯片中的二维地址，因为数据在内存中存储之后，靠这个二维地址定位
2. 根据二维地址读取到对应的数据
3. 存储控制器将读取到的数据放到存储总线上

#### cpu向内存中写数据的过程

> 主要是总线和IO bridge加上存储控制器在工作

1. 通过总线发起写事务
2. 将虚拟地址转换成内存地址
3. 将内存地址传递到系统总线上
4. 然后IO bridge将系统总线上的内存地址转换到存储总线上
5. 之后存储控制器定位到对应的内存地址
6. cpu将数据放到系统总线上，再次经过IO bridge转换到存储总线上
7. 存储控制器读取到存储总线上的数据，写入刚才指定的内存中

#### 物理内存模型

1. 内核中以struct page来对基本单位页来进行管理，每一个struct page都有一个索引编号PFN。而**管理**这些struct page的方式称为物理内存模型

   - flatMEM平坦内存模型：物理内存连续，分配的页面也连续。所以struct page和PFN之间的映射关系可以保存到一个**数组**中，通过偏移量找到下一个struct page

     <img src="https://cdn.xiaolincoding.com//mysql/other/89fe28d0feb1cd31cbaad5352e1f43d9.png" alt="image.png" style="zoom:20%;" />

   - discontingMEM非连续·内存模型：由于flatMEM按照数组进行管理，一旦物理地址不连续，数组中就会出现很多空洞，于是使用节点node管理每一个断开的连续段，每一个node**内部都是一个数组**：

     <img src="https://cdn.xiaolincoding.com//mysql/other/ae106d5d780328aae34d40560dc0442f.png" alt="image.png" style="zoom:15%;" />

   - sparseMEM稀疏内存模型：为了对更小的连续内存小块进行精细管理，相当于node划分的更小，变成了section，并且每个section还带上了在不在线的状态以支持热插拔

#### 内存热插拔实现原理

> 主要是要优雅的拔下，插上直接等待映射即可，拔下需要保证内部数据还是可用

1. 分为物理热插拔和逻辑热插拔，稀疏内存模型就能支持热插拔
2. 支持热插拔的内存内部存储的全是可以迁移的物理页，例如用户空间使用的物理地址，迁移只需要改变虚拟地址和物理地址之间的映射即可
3. 不可迁移的物理页不能保存到热插拔内存中，例如内核空间中的直接映射区，由于是虚拟地址减去偏移计算得到物理地址，所以物理地址不能变，所以不能迁移
4. 一旦内存物理拔掉，此时稀疏物理模型的中被拔掉的section标记为下线
5. 之后完成物理页的迁移
6. 内存插上之后，等待虚拟地址的映射即可

#### 物理内存架构

> CPU访问内存需要经过总线

1. 一致性访问UMA架构：CPU和内存被总线隔开，并且每个CPU到每个内存的距离是一样的（访问速度一样，所以称为一致性访问架构），CPU个数增多导致总线压力变大：

   <img src="https://cdn.xiaolincoding.com//mysql/other/79170f0256ed383e3934b99a156911fd.png" alt="image.png" style="zoom:10%;" />

2. 非一致性访问NUMA架构：分为本地内存和远程内存，每个cpu都有自己的本地内存，访问速度快，内存不够时才访问远程内存，由于是这种**不连续**的内存，所以前面提到的平坦内存模型就**无法使用**：

   <img src="https://cdn.xiaolincoding.com//mysql/other/672a905532a801f8811040265cae2d0f-20230310000450243.png" alt="image.png" style="zoom:14%;" />

   - NUMA的内存分配策略（先分配本地内存还是远程内存）：
     - 本地和远程都可以
     - 优先在指定节点分配，不够时在距离最近的节点分配
     - 优先在本地，本地不够在远程

#### 内核如何管理NUMA节点

1. UMA架构看做只有一个NUMA节点的伪NUMA架构

2. 针对每一个NUMA节点都建立一个结构体

3. 定义一个全局数组node_date，每个数组中的元素都指向一个NUMA节点的结构体

4. 每一个NUMA结构体中都有以下的内容：

   - 节点id

   - 物理模型中管理**一段**连续内存使用到的mem-map数组

   - 节点内第一个物理页的索引编号PFN

   - 节点内可用物理页个数

   - 所有的物理页个数（可用+空洞）

     ![image-20240323102303344](C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240323102303344.png)

5. 每个NUMA节点的物理内存主要划分为：
   - zone_DMA：用于寻址范围有要求的设备，例如ISA设备只能对内存前16MB寻址
   - zone_DMA32：专门提供给64位系统的DMA设备
   - 高端内存：32位系统中使用的非线性映射区
   - zone_DEVICE：支持热插拔的非易失性内存，或者用于内核崩溃保存调试信息
   - zone_movable：保存可迁移数据，为了支持热插拔
6. 针对不经常使用的页面，内核还会定期规整回收
7. 每个节点有一个状态，这个状态在热插拔时变化，在线还是离线

#### 二进制文件如何映射到用户虚拟内存中

> 先放入物理内存，然后调用映射函数做映射

1. 二进制文件中的只读内容会放入内存中的只读权限的区域，可读写的数据会被放到可读写权限的区域，要执行的文件会被放到可执行区域
2. 之后内核调用一个映射函数完成物理内存到虚拟内存的映射
3. 初始化结构体中的信息，包括进程id，六大部分的起始位置等等
4. 将不同类型的数据映射到虚拟内存中的不同区域

#### malloc分配内存的方式

> 从**用户空间**中分配

1. 使用brk()系统调用从**堆段**中分配，需要的内存大小**小于** 128kb时使用
2. 使用mmap()系统调用从**文件映射区**分配，需要的内存大小**超过**128kb时使用
3. 分配时并不是指定多少分配多少，而是预分配**更大**的空间
4. 分配的空间是虚拟的，只有被访问时才会映射到物理内存中，此时出发**缺页中断**
5. 使用brk()分配的内存free()释放后会放到内存池中，便于后面直接复用
6. 使用mmap()分配的内存空间free()释放后，会归还给OS
7. 使用brk()和mmap()配合可以提高内存的使用效率
8. free()释放时，内存块有自己的描述信息，从而使得free()可以知道释放多大的内存

#### 分配内存的过程

1. 虚拟内存没有分配内存时，会触发缺页中断，此时进行内存分配
2. 有空闲内存直接分配
3. 没有空闲内存就进行内存回收
   1. 后台内存回收：异步进行内存回收，可以**早点触发**后台回收
   2. 直接内存回收：后台内存回收的速度赶不上需要的速度就会同步进行内存回收，此时前台的进程会被阻塞
   3. 内存回收后还不够，此时触发OOM(Out Of Memory内存溢出)机制，不停地选择内存占用多的进程杀死，直到内存够用
4. 回收内存时可以回收文件页（干净页直接释放，脏页先写入磁盘再释放）或者匿名页（写入磁盘再释放）

#### 如何减小回收内存带来的影响

1. 尽量先回收文件页，因为大部分文件页可以直接释放（不是脏页），不用写入内存，少回收**匿名页**，也就是程序运行过程总动态产生的页面
2. 匿名页回收必须保存到磁盘，因为数据不可复制性太大，磁盘换入换出涉及swap机制
3. 争取早点进行异步回收，这样空闲空间就会变大
4. 重要的进程就调整他的一个参数（用来计算被杀死的概率），使其不会因为内存不够而被杀死，也就是手动让其被杀死的概率**降低**

#### 物理内存的水位线

> 当物理内存超过水位线时，开始进行内存回收

1. 页最小阈值：剩余内存在页低阈值到页最小阈值之间时。给当前进程分配完内存**后**，就会**触发内存回收**，一旦超过这个阈值，就会立马触发内存回收
2. 页低阈值：剩余内存在页高阈值和页低阈值之间时，说明内存有一定消耗，但是可以接受
3. 页高阈值：剩余容量高于这个时，说明内存充足

#### 物理内存水位线的计算

> 依赖于一个内核参数min_free_kbytes 计算得来

1. 根据内核参数计算出页最小阈值
2. 页低阈值一般为页最小阈值的1.25倍
3. 页高阈值一般为页低阈值的1.5倍
4. 水位线之间的**间距可调**，根据一个内核参数，根据系统运行情况动态调整水位线，这样可以避免内存回收带来的影响

#### 物理内存页的格式



#### 4G机器申请8G内存

> 分为只分配和分配之后访问

1. 针对只分配不访问：由于分配的是虚拟内存，只要不访问就不会分配物理内存，所以：
   - 32位机器：用户空间可分配的大小为3GB，也就是虚拟内存最多申请3GB，申请8G会失败，因为其最多表示4GB的内存大小
   - 64位机器：用户空间可分配的大小为128T，也就是虚拟内存最多申请128T，申请8G会成功
2. 分配成功之后需要访问：
   - 没开启swap：此时只有4G物理内存，分配8G虚拟内存之后进行访问会出现内存溢出的情况，此时进程会被杀掉
   - 开启swap：此时虽然只有4G物理内存，但是由于可以进行换入换出，所以长时间不用的数据会被**换出**，腾出内存空间，从而8G内存空间可以不停地**换入换出**满足需求

#### linux缓解预读失效

> 与mysql差不多，改进LRU算法，使用两个链表存数据

1. 设计一个**活跃**链表和一个**非活跃**链表
2. 预读数据先放入非活跃链表头部
3. 数据被使用时，将其拿到活跃链表头部
4. 活跃链表尾部**降级**的数据被放入非活跃链表的头部，并不是真正淘汰
5. 当新数据读入时，最终被淘汰的是非活跃链表的尾部
6. 相当于将数据**分级**，这样就不会影响经常被访问的数据
7. mysql是类似的，只是链表名称叫做young和old。young在前，old**链接**在后
8. redis是使用LFU算法，除了计算数据的使用时间还计算数据的使用频率，根据这两个值淘汰数据

#### 缓存污染相关知识

1. 缓存污染：短时间内大量数据只被访问一次，由于LRU算法的特性，这些只被访问一次的数据很久才会被淘汰，占用缓存空间，被污染了
2. 导致大量热点数据被淘汰，降低缓存命中率
3. 解决办法（提高进入链表头部的**门槛**）：
   - linux：**不是第一次**访问就将其放到LRU链表头部，而是第二次
   - mysql：根据数据停留在old中的时间判断，**前后两次**访问时间**超过1s**才将数据拿到young链表头部

#### 进程结构

1. 进程：正在内存中运行的程序
2. 进程结构：使用进程控制块PCB来描述，是进程存在的唯一标识，通过链表组织：
   - 进程标识符：进程的唯一id
   - 用户标识符：标识当前进程属于哪个用户
   - 进程状态：运行，就绪，阻塞等
   - 进程优先级：根据这个判断谁先用cpu
   - 资源分配清单：当前进程正在使用哪些资源
   - cpu相关信息：进程切换时保存的cpu状态信息，便于后期进程恢复

#### 创建进程的步骤

1. 申请空白PCB，填入控制和管理进程的信息，例如进程的唯一标识
2. 为进程分配运行所需资源
3. 进入就绪队列等待调度执行

#### 终止进程的步骤

1. 找到进程对应的pcb
2. 如果处于执行状态，直接停止执行，将资源还给cpu
3. 如果进程有子进程，这个子进程变成孤儿进程，将子进程交给1号进程
4. 将pcb从对应的队列中删除

#### 进程的状态

> 进程按照链表组织，例如所有就绪的进程链接起来组成了就绪队列

1. 运行：正在运行
2. 就绪：可运行，但是需要等待cpu
3. 阻塞：不可运行，需要等待某些资源，这些进程通常会被换出到磁盘，等待的资源出现时才会被换入到内存中成为就绪态
4. 运行：正在运行
5. 就绪：可运行，需要等待cpu
6. 可运行，需要等待某些资源，这些进程通常会被换出到磁盘，等待的资源出现时才会被换入到内存中成为就绪态
7. 挂起：进程被换出到磁盘中的状态，分为阻塞挂起和就绪挂起
8. 创建：正在被创建
9. 结束：正在从系统中消失

#### 进程上下文切换

> 从一个进程切换到另外一个进程

1. 程序运行依赖cpu中的**寄存器**和**程序计数器**
2. 寄存器中存放的程序运行的数据，程序计数器用来存储指令，这两个合起来称为**上下文**
3. 进程的切换就是切换这两个设备中的内容

#### 线程上下文切换

1. 当两个线程**不属于同一个进程**，此时上下文切换就和进程上下文切换一样
2. 当两个线程属于同一个进程，此时只需要切换线程独有的寄存器和栈的信息即可，其余共享的信息不变

#### 线程实现

1. 用户线程：在用户空间中实现的线程，在用户态进行管理
2. 内核线程：在内核中实现的线程，由内核管理
3. 轻量级线程：在内核中来支持用户线程

#### 进程和线程的比较

1. 进程是正在运行的程序，而线程是进程内部的一条执行流程
2. 进程是分配资源的范围，线程是cpu调度的单位
3. 进程拥有完整的资源，线程只独有很少的资源，例如寄存器和栈
4. 线程可以共享进程的资源空间
5. 线程创建时间快，运行开销小

#### 进程调度原则

> 进程状态转换的过程称为进程调度
>
> 调度分为抢占式和非抢占式

1. cpu利用率：保证cpu始终忙碌
2. 系统吞吐量：保证同样时间内运行完成的进程更多
3. 周转时间：进程运行+阻塞+等待的时间尽可能小
4. 等待时间：在就绪队列中等待的时间尽可能小
5. 响应时间：用户请求到得到响应的时间越小越好

#### 调度算法

1. 先来先服务FCFS：当长进程先来时，对后面的短进程不太友好

2. 最短作业优先SJF：长作业很可能长时间得不到响应

3. 高响应比优先：计算进程的响应比，高的先执行：、

   等待时间相同，短作业优先，等待时间过长的长作业也能得到运行机会（由于预先得不到进程的执行时间，所以这个算法是**无法实现**的）：

   <img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240324220038192.png" alt="image-20240324220038192" style="zoom:25%;" />

4. 时间片轮转：每个进程都执行一段时间，时间片一般被设置为20-50ms，时间太长会**退化**成先来先服务
5. 最高优先级调度：根据进程的优先级调度：
   - 静态优先级：创建进程时就确定的优先级
   - 动态优先级：进程运行过程中动态变化
6. 多级反馈队列：
   - 多个队列，队列优先级从高到低，时间片从短到长
   - 新来的进程现在高优先级的队列末尾按照FCFS执行一个时间片
   - 一个时间片没执行完当前进程转到下一队列的末尾
   - 当前队列没有进程，才调度下一队列中的进程
   - 大多数进程在高优先级队列就可以执行完
   - 长进程虽然等待了一段时间，但是轮到自己之后，时间片也会边长

#### 进程通信方式

> 由于进程间的用户空间隔离，内核空间共享，所以通信要通过**内核空间**

1. 管道：单向传递数据，需要双向时要创建两个管道
   - 管道中的数据实际上保存在内核的缓存中
   - **匿名**管道只能实现父子进程之间的通信：grep前面的 `|`
   - **命名**管道可以在不相关的进程间通信，相当于创建了一个共享的文件

2. 消息队列：一个保存在内核中的消息链表
   - 双方需要协商好通信的**数据格式**
   - 只要消息队列没释放或者操作系统没关闭，此时消息队列就一直在
   - 不适合传输大文件，有**大小限制**
   - 发送消息需要将数据从用户态拷贝到内核态，接收消息需要从内核态拷贝到用户态，存在**拷贝开销**

3. 共享内存：拿出一块虚拟地址，映射到一块共享的物理内存中
   - **避免数据拷贝**，直接开辟一块共享的物理内存，这边写入，那一边就能读到

4. 信号量：是一个整型的计时器用于进程间的**同步和互斥**，保护共享资源
   - 防止共享的内存由于多个进程修改出现版本不一致的问题
   - P操作：将信号量-1，相减之后信号量<0说明此资源不能再被访问
   - V操作：将信号量+1，相加之后信号量>0说明此资源可以被访问
   - P，V操作需要成对出现
   - 信号量为1说明是**互斥**信号量
   - 信号量为0说明是**同步**信号量

5. 信号：异常情况下，使用信号来进行通信
   - 例如ctrl+c强行停止进程就会发送一个SIGINT信号
   - 使用kill -9杀死进程此时会发送一个SIGKILL信号
6. socket：跨网络通信时使用socket
   - 指定好通信的协议，通信双方的地址，经过bind，llisten，connect，accept或者recvfrom和sendto就可以开始通信
   - 建立连接的socket与真正传输数据的socket不一样
   - 使用socket本地传输时，直接绑定到一个本地文件，不需要绑定ip和端口

#### 临界区和临界资源

1. 临界区：每个进程访问临界资源的一段代码
2. 临界资源：一次只允许一个进程访问的资源

#### 进程同步互斥

1. 同步：进程间在一些关键点上需要互通等待与互通消息，这种互相制约的等待称为同步，例如必须先吃饭后洗碗，这种制约关系就是同步
2. 互斥：针对某一资源来说，同一时间只允许一个进程操作
3. 锁：加锁可以实现进程互斥：
   - 忙等待锁：也就是CAS算法，只要原值不是我们知道的原值，说明当前数据被修改过，就不能进行操作，拿着**新的原值**又去判断
     - 会出现**自旋**情况，也就是不是期待的原值时一直循环判断
     - 出现**ABA**问题，期待的原值是A，拿到的也是A，但是版本不一样，可以加上版本号，挪用公款后面补上，但是也违法了
     - 只能保证**一个变量**的原子操作，因为只能比较一个变量是否改变
   - 无等待锁：发现期待的值与当前值不符，不进行自旋，而是直接将当前进程放入等待队列，等待后面cpu的调度
4. 信号量：为1代表互斥信号量，为0代表同步信号量

#### 生产者消费者问题

1. 生产者生产数据放到缓冲区，消费者消费缓冲区中的数据

2. 缓冲区互斥访问

3. 生产者消费者之间同步，有了数据才能消费<img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240326101129225.png" alt="image-20240326101129225" style="zoom: 50%;" />

   <img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240326101030782.png" alt="image-20240326101030782" style="zoom: 33%;" /><img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240326101050346.png" alt="image-20240326101050346" style="zoom:33%;" />

4. 生产者拿到缓冲区的互斥锁之后，开始生产数据
5. 消费者拿到缓冲区的互斥锁之后，开始消费数据

#### 哲学家就餐问题

> 哲学家围一圈，中间有叉子，有两个叉子才能就餐，可能存在死锁，同时先拿左边再去拿右边拿不到

1. 增加互斥量，一次只能一个哲学家就餐，其余哲学家需要阻塞
2. 奇数先拿左再拿右，偶数先拿右再拿左
3. 两个邻居都没有进餐时，自己才能进餐，这需要一个状态数组记录哲学家的状态

#### 读者写者问题

> 同一时间允许多个读。读写，写写同一时间互斥

1. 读者优先：有写者直接阻塞，优先读，可能造成写者一直阻塞
   - 只要有读者（数量大于0），后续读者直接进入临界区
   - 针对读者数量的变化操作要**互斥**防止出错
   - 第一个读者进入临界区读数据时，将写者阻塞，后面的**读者直接进来**读
   - 最后一个读者离开临界区后，释放临界区资源，后续读者写者竞争临界区
2. 写者优先：有读者会阻塞，优先写，
   - 只要有写者（数量大于0），后续写者可以直接竞争临界区进行写操作，相当于插队
   - 操作写者数量的变化操作要互斥防止出错，并且**写者之间**竞争临界区也需要互斥
   - 第一个写者拿到临界区之后，直接写，后续的写者只要当前写者写完就可以直接写，读者获取不到临界区可能一直阻塞
   - 最后一个写者写完释放临界区，之后读者写者竞争
3. 公平方式：
   1. 一旦有写者，后面的读者就不能插队，可以设置一个flag，写者到达就p(falg)，读者p(falg)时会被阻塞，相当于不能插队
   2. 没有写者的时候，多个读者可以同时读
   3. 当读者数量为0时释放缓冲区，此时如果有写者就可以获得缓冲区
   4. 相当于等先来的读者读完之后，写者就可以写

#### 避免死锁

> 由于保护共享资源加了互斥锁，加锁不当会产生进程互相死等的情况，同时满足四个条件才会产生死锁：
>
> 1. 互斥条件：多个进程不能同时使用一个资源
> 2. 持有并等待：等待新资源的时候，已经拿到的资源不会释放
> 3. 不可剥夺：自己使用完之前，别的进程无法使用
> 4. 环路等待：两个进程的资源获取顺序形成了环

只要破坏四个条件的任何一个就可以打破死锁

1. 互斥条件无法破坏，这是由资源的性质决定的，为了安全不能破坏
2. 破坏持有并等待：进程运行前一次性分配所有资源，没分配够就直接等待。
3. 破坏不可剥夺：申请其他资源失败时，现有的资源会被释放
4. 破坏环路等待：给所有的资源编号，必须按照资源号递增的顺序申请资源
5. **银行家**算法：保证分配资源后不会进入不安全状态（可能死锁）
   - 进程需要预先提出自己的最大资源请求
   - 分为最大需求矩阵，已分配矩阵，可用矩阵
   - 给某一个进程分配之后，按照某一种顺序，所有的进程是不是都可以正常运行结束
   - 如果可以说明当前时刻是安全的
   - 如果不可以说明当前时刻不安全

#### 互斥锁和自旋锁

> 是一种独占锁

1. 互斥锁：加锁成功正常执行，加锁失败将线程置为睡眠状态，锁被释放，当前线程被唤醒
2. 第一次上下文切换：加锁失败，会将线程设置为睡眠状态
3. 第二次上下文切换：锁被释放，当前线程变成就绪状态
4. 自旋锁：加锁不成功一直询问
5. 互斥锁加锁失败会**线程切换**，自旋锁加锁失败会**忙等待**
6. 加锁时间很短时，互斥锁的线程切换时间比加锁时间消耗更多，此时应该尽可能选择自旋锁

#### 读写锁

1. 当前没有写锁，多个线程能并发的持有读锁，当前有写锁，其余线程无法加锁，所以写锁是一个**独占锁**。读锁是一个**共享锁**
2. 读写锁就像读者写者问题一样，分为读者优先，写者优先，公平竞争（使用队列）
3. 如果可以区分读写场景，读写锁更加合适

#### 乐观锁和悲观锁

1. 悲观锁：认为多线程修改共享资源概率很高，容易出现并发读写问题，所以操作之前必须上锁
2. 乐观锁：认为多线程修改共享资源概率较低，不容易出现并发读写问题，每次先修改，修改之后判断当前数据在修改过程中是不是被其他人修改从而判断是否需要放弃本次操作
   - 记录当前操作前的原值
   - 进行修改
   - 修改之后判断原值是否变化，变化说明修改的过程中被别人修改过了，此时放弃本次修改
   - 修改过后原值没有变化，此时提交修改
   - 像多人编辑文档，git都使用了乐观锁，真的发生冲突让用户自己解决

#### 进程最多可创建多少线程

1. 主要取决于进程的虚拟空间多大以及每个线程占用多大
2. 32位系统，进程最多可以占满3G的用户空间
3. 进程创建线程时，每个线程默认分配10MB的栈空间，这个大小可以改
4. 所以大约最多可以创建300个线程，如果将默认分配的栈空间改小，创建的线程数还能变多
5. 另外系统支持的最大线程数，线程ID的最大范围都会限制线程的数量，超过这些范围，线程会创建失败

#### 线程崩溃，进程怎么办

> 普通进程会崩溃，Java中的JVM不会崩溃，因为内部定义了信号处理函数，内部线程出现异常之后，系统发出**信号**尝试中断进程，JVM的**信号处理函数**会将出现错误的线程资源回收，自己正常运行

1. 线程因为访问非法内存崩溃，此时进程也崩溃，因为系统认为这种非法操作可能影响别人，所以干脆让整个进程崩溃

2. 想要进程崩溃，此时就发送一个信号，例如kill -9会发送一个SIGKILL信号，进程收到信号之后，调用信号处理函数（如果有的话）完成最后的处理，最后进程退出

3. JVM就有自己的信号处理函数，一旦出现异常，JVM会完成对应的资源回收后选择继续运行或者退出


#### 进程调度/CPU调度

> 这里指的是CPU一旦空闲就会调度一个就绪的进程来运行

1. 先来先服务：先到达的进程先进行服务，当长进程运行过长时间后，后面的短进程等待时间过长，**不利于短进程**

2. 短作业优先：抢占式的调度，到达一个更短的进程就先让他运行，正在运行的进程转换成就绪态，**不利于长进程**

3. 高响应比优先：计算每个进程的响应比：

   <img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240330090044060.png" alt="image-20240330090044060" style="zoom:33%;" />

   由于要事先知道每个进程的运行时间，但是运行时间又不可能预估，所以此算法**无法实现**，一旦实现长短进程都比较公平

4. 时间片轮转：每个进程轮流运行相同大小的时间片，通常设置为20-50ms
5. 高优先级优先：每个进程都有优先级，分为静态优先级（进程创建时确定）和动态优先级（进程运行过程中动态调整）
6. 多级反馈队列：
   - 队列有优先级，高优先级的队列时间片较短，优先级越低，时间片越长
   - 尽可能保证短进程在高优先级队列一次就能运行完成
   - 长进程虽然等待了一定时间，但是轮到自己的时间片也变长，可以忍受
   - 当进程到了更高级别的队列中，当前正在运行的进程会被打断，转去运行高优先级的进程

#### 页面置换

> 当需要的页面不在内存中，并且此时内存中没有空闲的页面时，就会发生页面置换，这涉及到swap机制
>
> 页面置换算法是为了选择一个页面换出，并且该页面尽可能不在后面被使用，这样会减小换入换出的次数

1. 最佳页面置换：选择**未来**最久不访问的页面换出，但是未来的访问次序并不知道，所以算法**无法实现**，可以作为一个标准衡量其余算法的效率
2. 先进先出置换：选择在内存中停留时间最长的，也就是最先进来的
3. 最近最久未使用：选择最近最久未使用的页面，代价很高，需要维护一个LRU链表，将访问过的页面放到链表头
4. 时钟页面置换：有一个环形链表和一个指针，当前页面被访问，标志位记为1，当前页面没访问，标志位记为0，页面置换时选择一个标志位为0的页面，如果当前位置为1，则现将其置为0，然后找下一个，直到找到0
5. 最不常用置换：选择访问次数最少的

#### 磁盘调度算法

> 为了提高磁盘的访问性能，使磁头的寻道时间变短

1. 先来先服务：对哪个磁道的访问请求先来，就先访问哪个磁道，磁道的访问可能很分散，导致性能不高
2. 最短寻道时间：优先选择离当前磁头近的磁道访问，但是可能导致某些请求饥饿，因为刺头可能很长时间内都在同一片范围内活动
3. 扫描（电梯调度）：在一个方向上移动（例如从内向外），移动的过程中响应访问磁道的请求，然后这个方向上没有了就掉头（）例如从外向内，中间的磁道请求的响应率高
4. 循环扫描：不掉头，而是只在一个方向上扫描，到头之后又回到开始
5. 优化扫描（LOOK）：到达最远的请求之后直接掉头，而不是走到磁道的尽头，这样可以减小磁头移动时间
6. 优化循环扫描（C-LOOK）：不是到达尽头才回到开始，而是到了最远的请求之后就认为到达了尽头

#### 文件的结构

1. 索引节点（inode）：记录文件的元信息，主要是文件大小，访问权限，创建时间，在磁盘中的位置等信息，是文件的**唯一标识**，存储在磁盘中
2. 目录项：记录文件的名字，索引节点指针以及目录项的层级关系（父子关系）,缓存在内存
3. 目录项中保存了索引节点的指针，而索引节点又指向了真正的物理地址，从而可以找到数据的存储位置

#### 目录和目录项

1. 目录项表示一个文件的基础信息，包括文件名，索引节点指针以及目录项的层级关系
2. 目录是所有目录项的集合，是一个文件，本身也有目录项
3. 内核会将进场访问的目录对应的目录项保存到内存中加快访问速度

#### 文件的使用过程

1. 通过open函数打开文件，得到文件的文件描述符
2. 调用read或者write来操作文件中的数据
3. 之后调用close来关闭文件
4. 每个进程打开的所有文件会被维护在一个文件打开表中，主要有以下内容：
   - 文件指针，当前进程读写到了当前文件的什么位置
   - 文件打开计数器，当前文件被多少文件打开了
   - 文件磁盘位置
   - 文件访问权限
5. 文件系统操作的基本单位是数据块，一个数据块4k，

#### 文件的存储

1. 连续空间存放：文件存放在磁盘中的连续空间中
   - 需要在文件头中指定文件的大小和起始块的位置才能知道分配多大的连续空间
   - 有磁盘碎片：文件间存在无法利用的小碎片，此时需要挪动文件的位置从而将小碎片进行整合，但是这样消耗过大
   - 文件大小不易扩展，可能文件后面紧挨着另外的文件，没地方扩展，此时需要新申请更大的连续空间
2. 非连续空间存放：
   - 链表：文件被分成一个一个的链表块，分为两种
     - **隐式**链表：链表块之间用指针连接，只能通过顺序访问找到某一个链表块
     - **显示**链表：针对每一个链表块的指针，单独将其保存到一张内存分配表FAT中，这样要找某一个链表块，直接从表中读取到指针即可
   - 索引：每个文件都有一个索引数据块，内部存放文件数据块的指针
     - 存储这个索引有单独的开销，即使文件很小也需要索引
     - 文件过大一个索引存不下
       - 链式索引：一个索引数据块指向一部分文件数据块，然后还有一个指针指向下一个索引数据块（索引数据块间使用链表连接）
       - 多级索引：索引块中存放的还是索引

3. Unix中采用上面几种方式的融合：
   1. 文件所需数据块小于10块，直接查找，每个数据块一个指针
   2. 超过10块，使用一级索引，索引块中存放数据块的指针，需要访问磁盘两次
   3. 还存不下使用二级索引，索引中存放的是索引，二级索引中才存放数据块的指针，需要访问磁盘三次
   4. 还存不下使用三级索引，第三级索引中才存放数据块指针，需要访问磁盘四次
   5. 一共需要13个指针，直接索引10+一级1+二级1+三级1

#### 空闲空间管理

> 管理磁盘中的空闲区域，后期分配磁盘空间时更加方便

**空闲表法：**

1. 所有的空闲块维护在一张表中，包含第一个块号和这个空闲区域包含几个数据块
2. 分配空间时顺序查找到一个**合适**的空闲区域，既不能大也不能小
3. 释放空间时，按顺序找到一个表中的条目，将释放空间的第一个块号和释放的块数填到表中
4. 只适合管理少量空闲区，适用于建立连续文件

**空闲链表法 ：**

1. 空闲数据块之间使用链表维护
2. 创建文件需要几个数据块就从链表头取下几个
3. 释放空间时将数据块依次加入链表头即可
4. 不适合大型文件系统，因为这使得链表太长，占用空间太多

**位图法：**

1. 磁盘每一个盘块都有一个二进制位与之对应
2. 值为0代表盘块空闲，值为1代表盘块已分配
3. linux采用位图管理空闲空间

#### 文件系统结构

> 由**引导块和块组**组成

1. 引导块：用于系统启动时引导，引导操作系统来读取文件系统中的块组
2. 块组包含的内容如下：
   - 超级块：包含inode个数，磁盘块个数，每个块组中空闲块和inoide的数目
   - 数据位图和inode位图：记录哪些数据块和inode块还是空闲的 
   - inode列表：包含块组中所有的inode
   - 数据块：包含文件中的数据

#### 目录的存储

> 目录中存储的是每个文件的基本信息

1. 正常来说采用列表存储：
   - 第一项为当前目录`‘.’`
   - 第二项为上级目录`'.'`
   - 后面都是一个一个的文件名和其对应的inode
2. 由于文件太多，都采用列表存储不太好，除了当前目录和上级目录，其余的文件目录项可以采用**哈希**存储，对文件名进行哈希，需要防止碰撞

#### 软链接和硬链接

1. 硬链接：直接创建一个目录项，其中的inode指向同一个文件，硬指的是直接链接到文件上，所有的硬链接删除才能删除原始文件
2. 软链接：重新创建一个文件，不过文件中保存的是想要链接的文件的**路径**，软指的是不直接链接到文件上，文件被删除这个链接还是在，只是找不到链接的文件而已

#### 文件I/O

> 看是直接与文件交互还是有中间商（缓存），交互时进程是不是阻塞，得到数据是否需要等待

- 缓冲与非缓冲 I/O
  1. 缓冲：利用标准库的缓存实现文件的加速访问，然后标准库再通过系统调用访问文件
  2. 非缓冲：直接通过系统调用访问文件，没有标准库的缓存做中间商，中间会经过虚拟文件系统
- 直接与非直接 I/O
  1. 直接：直接通过虚拟文件系统操作真正的文件系统，与磁盘中的文件交互
  2. 非直接：引入os的内核缓存，读文件时先从内核读，写文件时先写入内核，由内核与文件交互
- 阻塞与非阻塞 I/O
  1. 阻塞：用户访问数据先阻塞，直到内核与文件交互，读取到文件之后从缓冲区传递给用户，用户才开始操作数据
  2. 非阻塞：用户发起请求之后就返回，之后一直向内核轮询，看数据是否准备好，为了减小轮询的代价，引入了I/O多路复用
- 同步与异步 I/O
  1. 同步：需要等待数据从内核态拷贝到用户态，最终交给用户
  2. 非同步：数据从文件中读取并从内核态拷贝到用户态之后。通知用户，此时用户才读取数据，不会出现等待的情况

#### Page Cache 与 buffer cache

1. page cache :页缓存,负责缓存**逻辑**数据。

2. buffer cache : 块缓存,负责缓存**物理**数据。
3. **通过**文件系统操作数据，操作的是逻辑数据，真正映射到物理磁盘中需要通过文件系统，此时逻辑数据缓存到page cache中，刷新数据需要交给buffer cache完成
4. **越过**文件系统直接操作数据，会被缓存到buffer cache中，例如文件系统的一些元数据就会缓存到这里

#### 设备控制器

1. 每个外设都有自己的设备控制器，知道怎么控制对应的设备，例如硬盘有硬盘控制器，显示器有视频控制器
2. CPU通过设备控制器与设备打交道
3. 设备控制器内部有寄存器保存设备的状态，以及和CPU进行通信
   - 状态寄存器：保存自己的当前的状态，完成工作，正在工作等，便于CPU知晓
   - 命令寄存器：保存CPU传递来的指令
   - 数据寄存器：设备运行所需要的数据
4. CPU为了与这些寄存器通信，有两种方法：
   - 端口I/O：每个寄存器被分配一个I/O端口，通过指令操作寄存器
   - 内存映射I/O：每个寄存器被映射到内存中，CPU像操作内存一样操作寄存器
5. 当设备工作完成后，可能需要通知CPU，此时需**要DMA**机制

#### DMA直接内存访问

> 可以使得设备在CPU不参与的情况下，自主将数据放入内存

1. CPU告诉DMA控制器，自己需要多少数据，你给我放到哪，然后就干自己的事情
2. DMA控制器给对应的设备发送指令，转告CPU的指令
3. 设备收到命令之后，将数据传递到自己的缓冲区中，然后发送一个成功的信号到DMA控制器
4. DMA控制器收到信号之后，将数据拷贝到内核缓冲区中。发**中断**告诉CPU已经完成
5. 整个过程不需要CPU的参与，CPU只需要去拿到指定位置的数据即可，在DMA控制器传输文件的时候，CPU可以做其他的事情，提高了CPU的吞吐量

#### 设备驱动程序

1. 不同的设备有不同的设备控制器，为了屏蔽设备控制器的区别，此时引入设备驱动程序
2. 不同设别的设备驱动有统一的接口暴露给操作系统，可以用统一的方式接入OS
3. 设备一旦完成了工作，产生中断给CPU，此时CPU在设备驱动程序中响应这个中断

#### 中断

> 计算机运行过程中，发生某个事件后通知CPU来进行处理，CPU不用轮询等待某个事件的发生，化主动为被动，提高CPU利用率

1. 硬中断：由外部设备产生（磁盘，网卡等），用来通知操作系统外部设备发生变化
   - 外设将中断请求发给**中断控制器**
   - 中断控制器根据优先级将中断传递给cpu
   - CPU暂停当前程序流，将当前程序的寄存器中的值保存到栈中，转去执行中断处理程序
   - 执行完毕之后恢复没执行完的程序流
2. 软中断 ：可以理解为一条**CPU指令**，由进程产生
   - 进程一旦发出软中断，CPU就转去处理这个软中断处理程序，也会保存寄存器的值到栈中便于后期恢复
   - 执行完毕之后，恢复寄存器中的值，继续执行
3. 不同的设备和进程有不同的中断处理程序
4. 设备初始化时，要将自己的中断处理程序注册进行注册

#### 输入输出设备

1. 块设备：数据存储在固定的块中，例如硬盘或者USB，数据读写时都会先放入缓冲区，缓冲区中的数据足够才会发给CPU或者设备
2. 字符设备：以字符为单位发送数据，例如鼠标

#### 通用块层

> 为了减小块设备带来的差异，引入通用块层来管理不同的块设备

1. 给文件系统和应用程序提供统一的访问结构，将不同的块设备抽象成统一的
2. 将文件系统和应用程序发给块设备的请求进行排序，之后进行调度，提高磁盘的读写速度，一共有五种调度算法：
   - 不调度：对请求不做处理，一般出现在虚拟机系统中，虚拟机系统的通用块层不做处理，将请求交给外部宿主机的通用块层处理
   - 先入先出：先来的请求先调度
   - 完全公平：按照时间片均匀分配
   - 优先级调度：优先级高的先调度，适用于进程很多的系统，此时请求也会很多
   - 最终期限调度：分别处理读和写请求，保证到达最终期限的请求被优先处理，适用于I/O压力很大的场景

#### 键盘输入A，发生了什么

> 从敲击到显示到屏幕中的过程

1. 键盘驱动程序注册中断处理程序，其功能就是从对应的寄存器中读取一个数据
2. 键盘控制器将A保存到自己的数据寄存器中
3. 之后发出一个中断，告诉CPU输入了一个A
4. CPU将正在执行的程序的寄存器值保存到栈中便于后期恢复，然后转去执行中断
5. 调用当时注册的中断处理程序，读取到A字符，转换成ASCII码
6. 将读取到的数据放入读缓冲区，显示设备从缓冲区中拿到这个A，显示到屏幕上
7. CPU恢复之前中断的上下文

#### 传统文件传输过程

1. 磁盘将数据放到自己的缓冲区中
2. DMA控制器将数据拷贝到内核缓冲区中
3. 之后CPU产生中断，从用户态切换到内核态，系统调用**read**，CPU将内核缓冲区中的数据拷贝到用户缓冲区，然后切换回用户态
4. 之后再从用户态切换到内核态，系统调用**write**，CPU将用户缓冲区中的数据拷贝到socket缓冲区中，然后切换回用户态
5. 之后DMA控制器将其拷贝到网卡的缓冲区中，等待文件传输
6. 这一过程中一共经历了四次用户态和内核态的上下文切换，还有两次CPU拷贝
7. 为了减小上下文切换和系统调用的次数，引入了**零拷贝技术**

#### 零拷贝技术

> 零拷贝代表没有CPU拷贝。有三种实现方式：
>
> 1. mmap+write
> 2. sendfile
> 3. SG-DMA+sendfile：真正的零拷贝，没有CPU拷贝

1. mmap+write：可以减少**一次**系统调用和**两次**上下文切换

   - 用mmap代替上面的read系统调用，减少这次的数据拷贝过程

   - mmap直接将内核缓冲区里的数据**映射**到用户空间，这样就不用拷贝了

   - 之后调用write，进行上下文切换，将内核缓冲区中的数据拷贝到socket缓冲区

   - DMA控制器将其拷贝到网卡中，等待发送

   - 有**四次**上下文切换和**一次**CPU拷贝。还**不是真正的零拷贝**

     <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/mmap%20%2B%20write%20%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" alt="img" style="zoom:23%;" />

2. sendfile：

   - 调用内核中专门发送文件的函数sendfile

   - 调用sendfile函数进行上下文切换，然后将用户缓冲区中的数据直接拷贝到socket缓冲区中

   - 之后DMA控制器将socket缓冲区中的数据转到网卡中等待发送

   - 只有**两次**上下文切换和**一次**CPU拷贝，这还**不是真正的零拷贝**

     <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-3%E6%AC%A1%E6%8B%B7%E8%B4%9D.png" alt="img" style="zoom:25%;" />

3. SG-DMA+sendfile：

   - DMA控制器直接将数据拷贝到内核缓冲区中，数据的长度和描述符会传递到socket缓冲区，代表当前发了什么数据，这里没有CPU拷贝

   - SG-DMA控制器直接将内核缓冲区中的数据拷贝到网卡中，没有CPU拷贝

   - 只有**两次**上下文切换，没有CPU拷贝，这**是真正的零拷贝技术**

     <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" alt="img" style="zoom:25%;" />

4. 大文件传输不应该使用零拷贝技术：
   1. 因为这样会迅速将内核缓冲区占满，导致其余请求无法利用这个缓冲区
   2. 此时应该使用异步I/O加上直接I/O的形式
   3. 异步I/O指用户发出请求之后，不阻塞等待请求结果，而是请求结果出现后由中断通知
   4. 直接I/O代表用户请求的数据**不经过缓冲区**，直接传输，防止将缓冲区占满

#### I/O多路复用
