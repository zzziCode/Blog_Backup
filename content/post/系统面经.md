---
title: "系统面经"
description: "系统面经"
keywords: "系统面经"

date: 2024-03-19T08:47:11+08:00
lastmod: 2024-03-19T08:47:11+08:00

categories:
  - 面试
tags:
  -	面经
  - 操作系统

# 原文作者
# Post's origin author name
author: zzzi
# 开启数学公式渲染，可选值： mathjax, katex
# Support Math Formulas render, options: mathjax, katex
math: mathjax
# 原文链接
# Post's origin link URL
#link:
# 图片链接，用在open graph和twitter卡片上
# Image source link that will use in open graph and twitter card
#imgs:
# 在首页展开内容
# Expand content on the home page
#expand: true
# 外部链接地址，访问时直接跳转
# It's means that will redirecting to external links
#extlink:
# 在当前页面关闭评论功能
# Disabled comment plugins in this post
#comment:
#  enable: false
# 关闭文章目录功能
# Disable table of content
#toc: false
# 绝对访问路径
# Absolute link for visit
#url: "系统面经.html"
# 开启文章置顶，数字越小越靠前
# Sticky post set-top in home page and the smaller nubmer will more forward.
#weight: 1

# 开启各种图渲染，如流程图、时序图、类图等
# Enable chart render, such as: flow, sequence, classes etc
#mermaid: true

---

> 系统面经

本文中主要介绍一些操作系统相关的面试题，资料来源于[小林coding](https://xiaolincoding.com/)，文章长期更新

<!--more-->

#### 冯诺依曼模型

> 运算器，控制器，存储器，输入输出设备

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C/%E5%86%AF%E8%AF%BA%E4%BE%9D%E6%9B%BC%E6%A8%A1%E5%9E%8B.png" alt="img" style="zoom:33%;" />

#### 内存

1. 基本存储单位为字节，1字节等于8位
2. 内存地址从0开始编号，类似于**数组**，读写任何一个数据速度一样

#### 中央处理器CPU

1. 32位cpu一次最多可以处理四个字节（32位），能计算的最大整数就是`2^32=4,294,967,296`
2. 64位cpu一次最多可以处理8个字节（64位）
3. 一个地址单元就有8bit，所以64位一次只能处理一个地址单元，32位两次才能处理一个
4. 32位cpu能表示的最大值为2^32，也就是超过4GB的数据就无法表示了，64位机器只用了48位来表示虚拟内存的大小，也就是258T
5. cpu内部的控制单元：负责控制cpu工作
6. 逻辑运算单元负责运算
7. 寄存器分为几种：
   - 通用寄存器：存放需要运算的数据
   - 程序计数器：存储下一条指令的地址
   - 指令寄存器：保存正在执行的指令

#### 总线

> 用于CPU和其他设备之间的通信

1. 地址总线：指定CPU要操作的内存地址
2. 数据总线：读写内存中的数据
3. 控制总线：发送和接受各种信号，cpu收到信号之后进行响应，例如中断，设备复位

#### 线路位宽和CPU位宽

> 一个地址单元大小为8bit，也就是1Byte
>
> 电压高表示1，电压低表示0，所以可以通过**操作电压**传输数据

1. 线路位宽表示地址总线能访问的内存地址**范围**大小，1条总线能表示0,1，两条总线能表示00,01,10,11个地址,32条总线能标识2^32=4G大小范围，一个地址单元大小为8bit，也就是能访问4GB数据

   > 这里只是说能访问的范围是4GB，但是32位机器每次只能处理4B，64位机器每次只能处理8B

2. CPU位宽表示能处理的数据范围大小，CPU位宽最好不要小于线路位宽，否则读取到了这么大的数据cpu也无法一次处理，并且32位CPU只能处理4GB范围内的数据，超过范围的**无法表示**这么大的地址

#### 程序执行的基本过程

> 程序执行时需要翻译成汇编代码，最后变成机器码
>
> 数据和指令分开存放，数据存放到**数据段**，指令存放到**正文段**

1. 程序被翻译成汇编代码，最终变成机器码变成指令
2. CPU根据程序计数器的内存地址拿到将要执行的指令
3. 将拿到的指令放入指令寄存器中
4. 根据指令类型将指令交给不同的单元执行，例如计算指令交给运算器
5. 程序计数器根据指令的长度自增，便于拿到后面的指令
6. 上面的过程会不断循环，这个过程称为CPU的指令周期
7. 程序执行时需要翻译成汇编代码，最后变成机器码

#### 指令

> 指令在执行时需要先成为汇编代码，然后翻译成机器码

1. 不同的CPU有不同的指令集，也就是不同的汇编语言和机器码
2. 不同的汇编代码被指令集**映射**成对应的0,1形式的机器码
3. 指令执行时最终被加载到控制器中，然后进行**解析**执行
4. 解析就是将机器码进行分解，得到地址和操作数
5. 最终将得到的结果写回

#### 指令的类型

1. 数据传输：store，load，mov
2. 运算：加减乘除，位运算，比较大小
3. 跳转：if-else，switch-case
4. 信号类型：发生中断的trap
5. 闲置：nop

#### 时钟周期与cpu主频

时钟周期是主频的倒数，主频表示一秒钟产生多少次数的脉冲信号，一次信号就是一个周期，相当于表示一秒钟产生多少个时钟周期，**倒数**就可以计算一个时钟周期的时间

#### 指令的执行速度

> 与时钟频率有关，一个时钟周期内只能完成一个动作，一条指令需要若干时钟周期

1. CPU的时钟频率越快，指令执行越快
2. 同一条指令，涉及到的操作越少执行越快

#### 存储设备的速度

> 从高到低，存储设备只与相邻的打交道，**一级一级**的传递数据

1. 寄存器：cpu正在处理的数据放在寄存器中，肯定最快，一般半个时钟周期就能读取数据
2. cpu三级缓存，越小越快：这里成为数据和指令缓存，离CPU也比较近，使用的是**SRAM**的芯片
   - 一级缓存：指令和数据分开存放，一般2-4个时钟周期就能读取数据，几十KB-几百KB
   - 二级缓存：读数据的速度一般在20-20个时钟周期，大小一般为几百KB-几MB
   - 三级缓存：读数据的速度一般在20-60个时钟周期，大小一般为几MB-几十MB
3. 内存：使用**DRAM**的芯片，数据存储依靠会**漏电的电容**，所以需要动态刷新内存保证数据不丢失，一般读取速度在200-300个时钟周期
4. 硬盘：速度最慢，但是数据可以**持久化**存储
5. 数据访问时是**一级一级的访问**，并不会越过某一个设备直接访问内存或者硬盘

#### 计算密集型和I/O密集型任务

1. 计算密集型：系统大部分时间是在利用CPU进行计算，I/O的事件可以忽略不计、
2. I/O密集型：系统大部分时间消耗在I/O数据上，CPU利用率并不高

#### 如何让代码跑得更快

> 代码存储到缓存中才能使其跑得更快，而代码又分为指令和数据

1. 提高数据的缓存命中率：例如访问数组这种连续存储的数据时，尽可能按照顺序访问，不要跳跃式的访问
2. 提高指令的缓存命中率：利用CPU的分支预测器，如果可以预测到接下来应该执行代码的哪个分支，提前将这些代码缓存，就可以加快执行速度
3. 防止因线程切换导致缓存命中率降低：多核cpu中，一个线程的执行可能在多个核心中。而一二级缓存是核心内独有的，这样切换会降低缓存的命中率

#### 缓存和内存一致性

> 当cpu操作产生新数据后，需要**写**入cache，然后从cache写入内存，这其中涉及到缓存和内存的**一致性**

1. 写直达：把数据**同时**写入内存和cache中，这种每次都写入内存的方法花费的时间更多
2. 写回：需要写数据时，判断当前数据将要存入的地址内的数据是什么状态
   - 如果当前数据是脏数据，也就是缓存和内存中不一致的数据，此时出发写内存的操作
   - 如果当前数据是旧数据，那么直接覆盖，并且将当前数据标记为**脏数据**
   - 后期仅当当前脏数据要被覆盖时才写入内存，减少内存的写入次数
   - 根据时间局部性原理，当前缓存的数据命中率大大提高
3. 主要是确定什么时候写入内存

#### 缓存之间的一致性

> cpu多核之间只共享第三级缓存，前两级缓存是核心内独有的，所以存在缓存不一致问题

1. 第一个核心操作数据x，将其+1，之后利用写回的策略，只会更新第一二级缓存
2. 第二个核心也操作数据x，此时从内存中读取到的数据是错的，因为第一个核心已经修改过了
3. 有两种策略：
   1. 写传播：核心内的cache更新时，必须**传播**到其他核心的cache中
   2. 串行化：核心对数据的操作不管哪个核心看都是**顺序一致**的，也就是数据先+100，后*200，顺序要一样才能保证缓存同步
4. 基于**总线嗅探**的**MESI协议**就可以实现缓存一致性

#### 总线嗅探

#### 总线嗅探

> 数据发生变化就**广播**

1. 一个核心修改了数据之后，通过总线进行广播
2. 其余核心收到广播之后，判断自己的缓存中是否有这个数据，有的话就更新

#### MESI协议

- *Modified*，已修改：数据被修改过，还没有同步到内存
- *Exclusive*，独占：数据没被修改，但是独占
- *Shared*，共享：数据没被修改，且共享
- *Invalidated*，已失效：数据是无效的，不能读取该数据

1. 独占数据直接读取，一旦有多个内核读取独占数据，独占将变成共享
2. 一旦当前共享数据要被修改，其余核心中的数据就变成无效，当前核心内的数据变成已修改
3. 当前已修改数据要被替换时，要先写入内存
4. 后续要访问的数据是已修改状态时，要先写入内存再访问

#### CPU伪共享

> 不同的核心读取的是**同一个内存块**的**不同数据**就会造成伪共享

1. 核心1读取数据A，核心2读取数据B
2. 由于A,B在同一个内存块中，所以这个内存块被标记为共享
3. 核心1修改数据A，会将核心2的内存块标记为已失效并将自己标记为已修改
4. 但是核心2想操作的数据B并没有变化，这种共享了还是没用的情况称为**伪共享**
5. 核心2要想操作B，需要先将已修改的A的内存块写入内存，然后从内存读取

**解决办法**

1. 热点数据**避免**放到同一个内存块中

#### 中断

> os接收到**硬件**的中断请求，就会**打断**在执行的进程，响应硬件的请求，所以针对的是硬件

1. 中断分为硬中断和软中断
   - 硬中断：直接处理硬件请求，耗时较短
   - 软中断：硬中断后续的工作就由软中断完成，耗时较长
2. 软中断的情况：
   - 网络收发
   - 定时
   - 调度

#### 浮点数存储方式

**符号位+指数位+尾数**

1. 浮点数在计算机内存储是按照二进制，所以有的浮点数并不精确

2. 因为转二进制时就**无法精确转换**

3. 针对1001.1101，**规格化**为1.0011101*2^3，其中符号位为0，指数位为3，尾数为0011101

4. 单精度float和双精度double的区别就在于这三个位置所占位数

   - float占4字节，32位

   - double占8字节，64位

     ![image-20240319160459912](C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240319160459912.png)

将小数转换成二进制小数之后，进一步规格化，然后确定符号位，指数位以及尾数位

1. 符号位，正数为0，负数为1

2. 指数位：为了防止出现负数造成麻烦，所以float加上127的**偏移量**，要计算十进制数时再减去127，double加上2055 

   > 例如当前指数位是-8，加上127变成119，转换十进制时119-127还原成`-8`即可

3. 尾数位：小数点后的就是尾数位，由于是小数，所以不够的在**后面**补零

#### 负数为什么要用补码

> 除符号位外，剩下所有位取反+1

为了统一操作，这样就和正数的操作方法一样了，最终的得到的结果按照补码转换即可

#### 虚拟内存

1. 为了将程序使用的地址**隔离**起来，这样程序之间的地址就不会互相冲突
2. 可以使得进程需要的运行内存**超过**物理的内存大小，因为是用时才**换入**
3. 用于映射的段表或者页表标记了物理地址的操作权限，更加安全
4. 降低程序员开发负担，不用关心操作的内存会冲突，因为操作的是虚拟内存
5. 程序使用的虚拟地址与物理地址之间需要操作系统的**MMU**（内存管理单元）来**映射**
6. 有几种管理映射的方式：
   - 分段式存储管理
   - 分页式存储管理
   - 段页式存储管理
7. 表示进程的结构体中存在一个虚拟内存的**结构体属性**，父子进程之间**拷贝共享**的就是这个结构体属性
8. 不同进程之间的结构体不一样，也就是虚拟地址是隔离的

#### 进程打开的过程

1. 分配进程id
2. 给进程分配资源，主要是提供进程运行所必要的数据
3. 如果是子进程的话，还需要**拷贝父进程**结构体中关于虚拟内存和页表的相关内容
4. 如果与父进程之间共享了地址空间，那么此时子进程就会变成线程

#### 虚拟内存的划分

> 进程表示虚拟内存的结构体中有一个属性标识内核虚拟空间和用户虚拟空间的**分界线**

1. 32位：
   - 用户虚拟空间：00,01,10开头的2^30，刚好3G
   - 内核虚拟空间：11开头的2^30，刚好1G
2. 64位（只利用了48位）：
   - 用户虚拟空间：低位0开头的2^47，刚好128T
   - 内核虚拟空间：高位1开头的2^47，刚好128T
   - 剩下的部分没有分配，称为**空洞**

#### 分段式内存管理

> **段表**来建立桥梁，根据段表找到物理内存分段的起始位置，根据偏移量找到具体的数据所在位置

1. 认为程序由逻辑上的一段一段组成，代码分段，数据分段，栈段等
2. 分段机制下，虚拟地址由**段选择因子**和**段内偏移量**组成：
3. 段选择因子：内部的段号最重要，指向了段表中的某一个段的描述信息，主要包含段的起始位置
4. 段内偏移量：根据段选择因子找到的段的起始位置来进行偏移，最终确定数据的真实位置
5. 需要访问两次内存：一次找到段表，一次找到段内数据
6. 内存分段会造成**外部碎片**，因为段与段之间是分开的，导致一个段的内存空间被释放，可能与空闲内存之间不连续，两个128MB的不连续空间无法当成256MB用
7. 不会造成内部碎片，因为**想要**使用多大的内存就分配多大
8. 为了解决外部碎片，引入了**内存交换**，先将导致不连续内存之间的数据交换到硬盘上，这样就会空出一大部分空闲内存，然后再重新分配交换出去的数据所占的内存

<img src="https://cdn.xiaolincoding.com//mysql/other/6142bc3c917e4a6298bdb62936e0d332.png" alt="img" style="zoom: 25%;" />

> 上图来说，两个空闲的128MB无法当做256MB使用，出现外部内存碎片，可以将中间音乐占用的256MB数据交换到磁盘，之后得到512MB的空闲内存，最后再将音乐的数据交换回来，紧挨着游戏的内存后面放，最终就得到了256MB的空暇内存
>
> 可以理解为音乐向前移动，

#### 分页式内存管理

> 数据存储的基本单位变成了更小的页，使用**页表**来进行映射

1. 一个程序可能使用很多页，虚拟页和物理页之间的映射关系保存在页表中
2. 虚拟页想要访问物理页失败时，产生缺页异常，此时操作系统会分配一个物理页进行映射
3. 内存空间不够，会将最近没使用的页中的数据**写入磁盘**，然后这些页的映射关系重新分配，写入磁盘的过程叫做**换出**
4. 需要的数据不在内存中，就需要**换入**
5. 每次只加载需要的数据页，通过**页号+偏移量**确定数据的存放位置
6. 每个进程都有自己的页表，导致页表很大，所以引出**多级页表**
7. **多级页表**：一级页表中存放的时二级页表的地址，一层一层向下
8. TLB（页表缓存，快表，旁路缓存）：根据程序的局部性原理，存在一些经常被访问的页面，CPU中有一个**页表缓存**专门存储**经常访问**的页面
9. 由于内存分配的最小单位就是页，所以页内可能出现无法使用的**内部碎片**
10. 需要访问两次内存：一次找到页表，第二次找到页内数据

#### 段页式内存管理

1. 先进行分段，段内进行分页
2. 先找到段表中对应的页表位置，然后在页表中找到页面所在位置
3. 需要访问三次内存：第一次找到段表，第二次找到页表，第三次找到数据
4. 利用分段信息共享（一段数据有实际意义，一页数据没有意义），动态链接等特点，结合分页没有外部碎片，提出段页式内存管理

#### 用户虚拟空间格式

> 分为六个部分，这些格式之间都有指针作为**分界线**，防止出现**越界**的情况

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/32%E4%BD%8D%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80.png" alt="虚拟内存空间划分" style="zoom:25%;" />

1. 代码段：存放编译好的机器码形式的代码
2. 数据段：存储指定了初值的数据全局变量和静态变量
3. BSS段：包括未初始化的静态变量和全局变量
4. 堆段：程序运行期间动态申请的内存
5. 文件映射段：存储程序运行调用的其他库的代码段
6. 栈段：存储运行时调用函数使用的局部变量和参数

#### 32位内核虚拟空间格式

> 32位系统只有1G内核虚拟空间，需要**精细划分**

1. 直接（连续）映射区：这块连续区域映射到的物理内存也是连续的，大约896MB
   - 内部存放内核代码和数据
   - 进程创建之后的数据结构也会存放到这里
   - 存放进程调用链的内核栈也存放到这里
2. 内存空洞：大约8M大小的内存空洞
3. 动态映射区：逻辑连续，物理不连续，通过页表映射
4. 永久映射区：可以与物理内存建立永久的映射关系
5. 固定映射区：这个区域中的**虚拟地址不变**，对应的物理地址可以变，这些固定的虚拟地址有固定的用途
6. 临时映射区：存储一些临时的数据

#### 64位内核虚拟空间格式

> 64位虚拟内核空间128T，基本可以**随意挥霍**

<img src="https://cdn.xiaolincoding.com//mysql/other/84eb41fc42b790865eb8bc15d3a2892a.png" alt="image.png" style="zoom:20%;" />

#### 虚拟内存整体布局

> 这里介绍的是**32位**的系统，64的系统如上图所示

<img src="https://cdn.xiaolincoding.com//mysql/other/68763fe509b7adf5987a3ce96c9d12ee.png" alt="image.png" style="zoom:23%;" />

#### 内核如何管理用户虚拟内存

1. 设置一个结构体，内部划分了用户虚拟内存和内核虚拟内存

2. 还划分了用户空间内的六个部分之间的**边界**

3. 结构体内部保存了表示每一个部分的结构体，之间使用双向链表连接便于遍历，为了便于查找，还建立了红黑树的结构

   <img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240322100005966.png" alt="image-20240322100005966" style="zoom:50%;" />

4. 虚拟内存和物理内存之间的关系由页表映射

5. 页面的访问权限由一个**参数**的不同值决定（可读，可写，可执行。。。）

#### cpu从内存中读数据的过程

> 数据传输通过**总线**，IO bridge负责中间的联系

1. 通过总线发起读事务
2. 将虚拟地址转换成内存地址
3. 将内存地址A放到系统总线上，然后**IO bridge**传输到存储总线
4. 存储总线上一旦有地址信号，存储控制器就**根据这个内存地址从内存中读取数据**
5. 将读取到的数据放到存储总线上，然后IO bridge将数据转换到系统总线上
6. CPU接收到系统总线上的数据，将其接收到之后存入三级缓存或者寄存器中

#### 如何根据内存地址读取数据

> 主要是存储控制器的功劳

1. 存储控制器将内存地址转换成内存DRAM芯片中的二维地址，因为数据在内存中存储之后，靠这个二维地址定位
2. 根据二维地址读取到对应的数据
3. 存储控制器将读取到的数据放到存储总线上

#### cpu向内存中写数据的过程

> 主要是总线和IO bridge加上存储控制器在工作

1. 通过总线发起写事务
2. 将虚拟地址转换成内存地址
3. 将内存地址传递到系统总线上
4. 然后IO bridge将系统总线上的内存地址转换到存储总线上
5. 之后存储控制器定位到对应的内存地址
6. cpu将数据放到系统总线上，再次经过IO bridge转换到存储总线上
7. 存储控制器读取到存储总线上的数据，写入刚才指定的内存中

#### 二进制文件如何映射到用户虚拟内存中

> 先放入物理内存，然后调用映射函数做映射

1. 二进制文件中的只读内容会放入内存中的只读权限的区域，可读写的数据会被放到可读写权限的区域，要执行的文件会被放到可执行区域
2. 之后内核调用一个映射函数完成物理内存到虚拟内存的映射
3. 初始化结构体中的信息，包括进程id，六大部分的起始位置等等
4. 将不同类型的数据映射到虚拟内存中的不同区域

#### malloc分配内存的方式

> 从**用户空间**中分配

1. 使用brk()系统调用从**堆段**中分配，需要的内存大小**小于** 128kb时使用
2. 使用mmap()系统调用从**文件映射区**分配，需要的内存大小**超过**128kb时使用
3. 分配时并不是指定多少分配多少，而是预分配**更大**的空间
4. 分配的空间是虚拟的，只有被访问时才会映射到物理内存中，此时出发**缺页中断**
5. 使用brk()分配的内存free()释放后会放到内存池中，便于后面直接复用
6. 使用mmap()分配的内存空间free()释放后，会归还给OS
7. 使用brk()和mmap()配合可以提高内存的使用效率
8. free()释放时，内存块有自己的描述信息，从而使得free()可以知道释放多大的内存

#### 分配内存的过程

1. 虚拟内存没有分配内存时，会触发缺页中断，此时进行内存分配
2. 有空闲内存直接分配
3. 没有空闲内存就进行内存回收
   1. 后台内存回收：异步进行内存回收，可以**早点触发**后台回收
   2. 直接内存回收：后台内存回收的速度赶不上需要的速度就会同步进行内存回收，此时前台的进程会被阻塞
   3. 内存回收后还不够，此时触发OOM(Out Of Memory内存溢出)机制，不停地选择内存占用多的进程杀死，直到内存够用
4. 回收内存时可以回收文件页（干净页直接释放，脏页先写入磁盘再释放）或者匿名页（写入磁盘再释放）

#### 如何减小回收内存带来的影响

1. 尽量先回收文件页，因为大部分文件页可以直接释放（不是脏页），不用写入内存
2. 争取早点进行异步回收，这样空闲空间就会变大
3. 重要的进程就调整他的一个参数（用来计算被杀死的概率），使其不会因为内存不够而被杀死，也就是手动让其被杀死的概率**降低**

#### 4G机器申请8G内存

> 分为只分配和分配之后访问

1. 针对只分配不访问：由于分配的是虚拟内存，只要不访问就不会分配物理内存，所以：
   - 32位机器：用户空间可分配的大小为3GB，也就是虚拟内存最多申请3GB，申请8G会失败，因为其最多表示4GB的内存大小
   - 64位机器：用户空间可分配的大小为128T，也就是虚拟内存最多申请128T，申请8G会成功
2. 分配成功之后需要访问：
   - 没开启swap：此时只有4G物理内存，分配8G虚拟内存之后进行访问会出现内存溢出的情况，此时进程会被杀掉
   - 开启swap：此时虽然只有4G物理内存，但是由于可以进行换入换出，所以长时间不用的数据会被**换出**，腾出内存空间，从而8G内存空间可以不停地**换入换出**满足需求

#### linux缓解预读失效

> 与mysql差不多，改进LRU算法，使用两个链表存数据

1. 设计一个**活跃**链表和一个**非活跃**链表
2. 预读数据先放入非活跃链表头部
3. 数据被使用时，将其拿到活跃链表头部
4. 活跃链表尾部**降级**的数据被放入非活跃链表的头部，并不是真正淘汰
5. 当新数据读入时，最终被淘汰的是非活跃链表的尾部
6. 相当于将数据**分级**，这样就不会影响经常被访问的数据
7. mysql是类似的，只是链表名称叫做young和old。young在前，old**链接**在后
8. redis是使用LFU算法，除了计算数据的使用时间还计算数据的使用频率，根据这两个值淘汰数据

#### 缓存污染相关知识

1. 缓存污染：短时间内大量数据只被访问一次，由于LRU算法的特性，这些只被访问一次的数据很久才会被淘汰，占用缓存空间，被污染了
2. 导致大量热点数据被淘汰，降低缓存命中率
3. 解决办法（提高进入链表头部的**门槛**）：
   - linux：**不是第一次**访问就将其放到LRU链表头部，而是第二次
   - mysql：根据数据停留在old中的时间判断，**前后两次**访问时间**超过1s**才将数据拿到young链表头部
