---
title: "系统面经"
description: "系统面经"
keywords: "系统面经"

date: 2024-03-19T08:47:11+08:00
lastmod: 2024-03-19T08:47:11+08:00

categories:
  - 面试
tags:
  - 面经
  - 操作系统
# 原文作者
# Post's origin author name
author: zzzi
# 开启数学公式渲染，可选值： mathjax, katex
# Support Math Formulas render, options: mathjax, katex
math: mathjax
# 原文链接
# Post's origin link URL
#link:
# 图片链接，用在open graph和twitter卡片上
# Image source link that will use in open graph and twitter card
#imgs:
# 在首页展开内容
# Expand content on the home page
#expand: true
# 外部链接地址，访问时直接跳转
# It's means that will redirecting to external links
#extlink:
# 在当前页面关闭评论功能
# Disabled comment plugins in this post
#comment:
#  enable: false
# 关闭文章目录功能
# Disable table of content
#toc: false
# 绝对访问路径
# Absolute link for visit
#url: "系统面经.html"
# 开启文章置顶，数字越小越靠前
# Sticky post set-top in home page and the smaller nubmer will more forward.
#weight: 1

# 开启各种图渲染，如流程图、时序图、类图等
# Enable chart render, such as: flow, sequence, classes etc
#mermaid: true

---

> 🥽 系统面经

本文中主要介绍一些操作系统相关的面试题，资料来源于[小林coding](https://xiaolincoding.com/)，文章长期更新

<!--more-->

#### 冯诺依曼模型

> 运算器，控制器，存储器，输入输出设备

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C/%E5%86%AF%E8%AF%BA%E4%BE%9D%E6%9B%BC%E6%A8%A1%E5%9E%8B.png" alt="img" style="zoom:33%;" />

#### 内存

1. 基本存储单位为字节，1字节等于8位
2. 内存地址从0开始编号，类似于**数组**，读写任何一个数据速度一样

#### 中央处理器CPU

1. 32位cpu一次最多可以处理四个字节（32位），能计算的最大整数就是`2^32=4,294,967,296`
2. 64位cpu一次最多可以处理8个字节（64位）
3. 一个地址单元就有8bit，所以64位一次只能处理一个地址单元，32位两次才能处理一个
4. 32位cpu能表示的最大值为2^32，也就是超过4GB的数据就无法表示了，64位机器只用了48位来表示虚拟内存的大小，也就是258T
5. cpu内部的控制单元：负责控制cpu工作
6. 逻辑运算单元负责运算
7. 寄存器分为几种：
   - 通用寄存器：存放需要运算的数据
   - 程序计数器：存储下一条指令的地址
   - 指令寄存器：保存正在执行的指令

#### 总线

> 用于CPU和其他设备之间的通信

1. 地址总线：指定CPU要操作的内存地址
2. 数据总线：读写内存中的数据
3. 控制总线：发送和接受各种信号，cpu收到信号之后进行响应，例如中断，设备复位

#### 线路位宽和CPU位宽

> 一个地址单元大小为8bit，也就是1Byte
>
> 电压高表示1，电压低表示0，所以可以通过**操作电压**传输数据

1. 线路位宽表示地址总线能访问的内存地址**范围**大小，1条总线能表示0,1，两条总线能表示00,01,10,11个地址,32条总线能标识2^32=4G大小范围，一个地址单元大小为8bit，也就是能访问4GB数据

   > 这里只是说能访问的范围是4GB，但是32位机器每次只能处理4B，64位机器每次只能处理8B

2. CPU位宽表示能处理的数据范围大小，CPU位宽最好不要小于线路位宽，否则读取到了这么大的数据cpu也无法一次处理，并且32位CPU只能处理4GB范围内的数据，超过范围的**无法表示**这么大的地址

#### 程序执行的基本过程

> 程序执行时需要翻译成汇编代码，最后变成机器码
>
> 数据和指令分开存放，数据存放到**数据段**，指令存放到**正文段**

1. 程序被翻译成汇编代码，最终变成机器码变成指令
2. CPU根据程序计数器的内存地址拿到将要执行的指令
3. 将拿到的指令放入指令寄存器中
4. 根据指令类型将指令交给不同的单元执行，例如计算指令交给运算器
5. 程序计数器根据指令的长度自增，便于拿到后面的指令
6. 上面的过程会不断循环，这个过程称为CPU的指令周期
7. 程序执行时需要翻译成汇编代码，最后变成机器码

#### 指令

> 指令在执行时需要先成为汇编代码，然后翻译成机器码

1. 不同的CPU有不同的指令集，也就是不同的汇编语言和机器码
2. 不同的汇编代码被指令集**映射**成对应的0,1形式的机器码
3. 指令执行时最终被加载到控制器中，然后进行**解析**执行
4. 解析就是将机器码进行分解，得到地址和操作数
5. 最终将得到的结果写回

#### 指令的类型

1. 数据传输：store，load，mov
2. 运算：加减乘除，位运算，比较大小
3. 跳转：if-else，switch-case
4. 信号类型：发生中断的trap
5. 闲置：nop

#### 时钟周期与cpu主频

时钟周期是主频的倒数，主频表示一秒钟产生多少次数的脉冲信号，一次信号就是一个周期，相当于表示一秒钟产生多少个时钟周期，**倒数**就可以计算一个时钟周期的时间

#### 指令的执行速度

> 与时钟频率有关，一个时钟周期内只能完成一个动作，一条指令需要若干时钟周期

1. CPU的时钟频率越快，指令执行越快
2. 同一条指令，涉及到的操作越少执行越快

#### 存储设备的速度

> 从高到低，存储设备只与相邻的打交道，**一级一级**的传递数据

1. 寄存器：cpu正在处理的数据放在寄存器中，肯定最快，一般半个时钟周期就能读取数据
2. cpu三级缓存，越小越快：这里成为数据和指令缓存，离CPU也比较近，使用的是**SRAM**的芯片
   - 一级缓存：指令和数据分开存放，一般2-4个时钟周期就能读取数据，几十KB-几百KB
   - 二级缓存：读数据的速度一般在20-20个时钟周期，大小一般为几百KB-几MB
   - 三级缓存：读数据的速度一般在20-60个时钟周期，大小一般为几MB-几十MB
3. 内存：使用**DRAM**的芯片，数据存储依靠会**漏电的电容**，所以需要动态刷新内存保证数据不丢失，一般读取速度在200-300个时钟周期
4. 硬盘：速度最慢，但是数据可以**持久化**存储
5. 数据访问时是**一级一级的访问**，并不会越过某一个设备直接访问内存或者硬盘

#### 计算密集型和I/O密集型任务

1. 计算密集型：系统大部分时间是在利用CPU进行计算，I/O的事件可以忽略不计、
2. I/O密集型：系统大部分时间消耗在I/O数据上，CPU利用率并不高

#### 如何让代码跑得更快

> 代码存储到缓存中才能使其跑得更快，而代码又分为指令和数据

1. 提高数据的缓存命中率：例如访问数组这种连续存储的数据时，尽可能按照顺序访问，不要跳跃式的访问
2. 提高指令的缓存命中率：利用CPU的分支预测器，如果可以预测到接下来应该执行代码的哪个分支，提前将这些代码缓存，就可以加快执行速度
3. 防止因线程切换导致缓存命中率降低：多核cpu中，一个线程的执行可能在多个核心中。而一二级缓存是核心内独有的，这样切换会降低缓存的命中率

#### 缓存和内存一致性

> 当cpu操作产生新数据后，需要**写**入cache，然后从cache写入内存，这其中涉及到缓存和内存的**一致性**

1. 写直达：把数据**同时**写入内存和cache中，这种每次都写入内存的方法花费的时间更多
2. 写回：需要写数据时，判断当前数据将要存入的地址内的数据是什么状态
   - 如果当前数据是脏数据，也就是缓存和内存中不一致的数据，此时出发写内存的操作
   - 如果当前数据是旧数据，那么直接覆盖，并且将当前数据标记为**脏数据**
   - 后期仅当当前脏数据要被覆盖时才写入内存，减少内存的写入次数
   - 根据时间局部性原理，当前缓存的数据命中率大大提高
3. 主要是确定什么时候写入内存

#### 缓存之间的一致性

> cpu多核之间只共享第三级缓存，前两级缓存是核心内独有的，所以存在缓存不一致问题

1. 第一个核心操作数据x，将其+1，之后利用写回的策略，只会更新第一二级缓存
2. 第二个核心也操作数据x，此时从内存中读取到的数据是错的，因为第一个核心已经修改过了
3. 有两种策略：
   1. 写传播：核心内的cache更新时，必须**传播**到其他核心的cache中
   2. 串行化：核心对数据的操作不管哪个核心看都是**顺序一致**的，也就是数据先+100，后*200，顺序要一样才能保证缓存同步
4. 基于**总线嗅探**的**MESI协议**就可以实现缓存一致性

#### 总线嗅探

> 数据发生变化就**广播**

1. 一个核心修改了数据之后，通过总线进行广播
2. 其余核心收到广播之后，判断自己的缓存中是否有这个数据，有的话就更新

#### MESI协议

- *Modified*，已修改：数据被修改过，还没有同步到内存
- *Exclusive*，独占：数据没被修改，但是独占
- *Shared*，共享：数据没被修改，且共享
- *Invalidated*，已失效：数据是无效的，不能读取该数据

1. 独占数据直接读取，一旦有多个内核读取独占数据，独占将变成共享
2. 一旦当前共享数据要被修改，其余核心中的数据就变成无效，当前核心内的数据变成已修改
3. 当前已修改数据要被替换时，要先写入内存
4. 后续要访问的数据是已修改状态时，要先写入内存再访问

#### CPU伪共享

> 不同的核心读取的是**同一个内存块**的**不同数据**就会造成伪共享

1. 核心1读取数据A，核心2读取数据B
2. 由于A,B在同一个内存块中，所以这个内存块被标记为共享
3. 核心1修改数据A，会将核心2的内存块标记为已失效并将自己标记为已修改
4. 但是核心2想操作的数据B并没有变化，这种共享了还是没用的情况称为**伪共享**
5. 核心2要想操作B，需要先将已修改的A的内存块写入内存，然后从内存读取

**解决办法**

1. 热点数据**避免**放到同一个内存块中

#### 中断

> os接收到**硬件**的中断请求，就会**打断**在执行的进程，响应硬件的请求，所以针对的是硬件

1. 中断分为硬中断和软中断
   - 硬中断：直接处理硬件请求，耗时较短
   - 软中断：硬中断后续的工作就由软中断完成，耗时较长
2. 软中断的情况：
   - 网络收发
   - 定时
   - 调度

#### 浮点数存储方式

**符号位+指数位+尾数**

1. 浮点数在计算机内存储是按照二进制，所以有的浮点数并不精确

2. 因为转二进制时就**无法精确转换**

3. 针对1001.1101，**规格化**为1.0011101*2^3，其中符号位为0，指数位为3，尾数为0011101

4. 单精度float和双精度double的区别就在于这三个位置所占位数

   - float占4字节，32位

   - double占8字节，64位

     ![image-20240319160459912](C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240319160459912.png)

将小数转换成二进制小数之后，进一步规格化，然后确定符号位，指数位以及尾数位

1. 符号位，正数为0，负数为1

2. 指数位：为了防止出现负数造成麻烦，所以float加上127的**偏移量**，要计算十进制数时再减去127，double加上2055 

   > 例如当前指数位是-8，加上127变成119，转换十进制时119-127还原成`-8`即可

3. 尾数位：小数点后的就是尾数位，由于是小数，所以不够的在**后面**补零

#### 负数为什么要用补码

> 除符号位外，剩下所有位取反+1

为了统一操作，这样就和正数的操作方法一样了，最终的得到的结果按照补码转换即可

#### 虚拟内存

1. 为了将程序使用的地址**隔离**起来，这样程序之间的地址就不会互相冲突
2. 可以使得进程需要的运行内存**超过**物理的内存大小，因为是用时才**换入**
3. 用于映射的段表或者页表标记了物理地址的操作权限，更加安全
4. 降低程序员开发负担，不用关心操作的内存会冲突，因为操作的是虚拟内存
5. 程序使用的虚拟地址与物理地址之间需要操作系统的**MMU**（内存管理单元）来**映射**
6. 有几种管理映射的方式：
   - 分段式存储管理
   - 分页式存储管理
   - 段页式存储管理
7. 表示进程的结构体中存在一个虚拟内存的**结构体属性**，父子进程之间**拷贝共享**的就是这个结构体属性
8. 不同进程之间的结构体不一样，也就是虚拟地址是隔离的

#### 进程打开的过程

1. 分配进程id
2. 给进程分配资源，主要是提供进程运行所必要的数据
3. 如果是子进程的话，还需要**拷贝父进程**结构体中关于虚拟内存和页表的相关内容
4. 如果与父进程之间共享了地址空间，那么此时子进程就会变成线程

#### 虚拟内存的划分

> 进程表示虚拟内存的结构体中有一个属性标识内核虚拟空间和用户虚拟空间的**分界线**

1. 32位：
   - 用户虚拟空间：00,01,10开头的2^30，刚好3G
   - 内核虚拟空间：11开头的2^30，刚好1G
2. 64位（只利用了48位）：
   - 用户虚拟空间：低位0开头的2^47，刚好128T
   - 内核虚拟空间：高位1开头的2^47，刚好128T
   - 剩下的部分没有分配，称为**空洞**

#### 分段式内存管理

> **段表**来建立桥梁，根据段表找到物理内存分段的起始位置，根据偏移量找到具体的数据所在位置

1. 认为程序由逻辑上的一段一段组成，代码分段，数据分段，栈段等
2. 分段机制下，虚拟地址由**段选择因子**和**段内偏移量**组成：
3. 段选择因子：内部的段号最重要，指向了段表中的某一个段的描述信息，主要包含段的起始位置
4. 段内偏移量：根据段选择因子找到的段的起始位置来进行偏移，最终确定数据的真实位置
5. 需要访问两次内存：一次找到段表，一次找到段内数据
6. 内存分段会造成**外部碎片**，因为段与段之间是分开的，导致一个段的内存空间被释放，可能与空闲内存之间不连续，两个128MB的不连续空间无法当成256MB用
7. 不会造成内部碎片，因为**想要**使用多大的内存就分配多大
8. 为了解决外部碎片，引入了**内存交换**，先将导致不连续内存之间的数据交换到硬盘上，这样就会空出一大部分空闲内存，然后再重新分配交换出去的数据所占的内存

<img src="https://cdn.xiaolincoding.com//mysql/other/6142bc3c917e4a6298bdb62936e0d332.png" alt="img" style="zoom: 25%;" />

> 上图来说，两个空闲的128MB无法当做256MB使用，出现外部内存碎片，可以将中间音乐占用的256MB数据交换到磁盘，之后得到512MB的空闲内存，最后再将音乐的数据交换回来，紧挨着游戏的内存后面放，最终就得到了256MB的空暇内存
>
> 可以理解为音乐向前移动，

#### 分页式内存管理

> 数据存储的基本单位变成了更小的页，使用**页表**来进行映射

1. 一个程序可能使用很多页，虚拟页和物理页之间的映射关系保存在页表中
2. 虚拟页想要访问物理页失败时，产生缺页异常，此时操作系统会分配一个物理页进行映射
3. 内存空间不够，会将最近没使用的页中的数据**写入磁盘**，然后这些页的映射关系重新分配，写入磁盘的过程叫做**换出**
4. 需要的数据不在内存中，就需要**换入**
5. 每次只加载需要的数据页，通过**页号+偏移量**确定数据的存放位置
6. 每个进程都有自己的页表，导致页表很大，所以引出**多级页表**
7. **多级页表**：一级页表中存放的时二级页表的地址，一层一层向下
8. TLB（页表缓存，快表，旁路缓存）：根据程序的局部性原理，存在一些经常被访问的页面，CPU中有一个**页表缓存**专门存储**经常访问**的页面
9. 由于内存分配的最小单位就是页，所以页内可能出现无法使用的**内部碎片**
10. 需要访问两次内存：一次找到页表，第二次找到页内数据

#### 段页式内存管理

1. 先进行分段，段内进行分页
2. 先找到段表中对应的页表位置，然后在页表中找到页面所在位置
3. 需要访问三次内存：第一次找到段表，第二次找到页表，第三次找到数据
4. 利用分段信息共享（一段数据有实际意义，一页数据没有意义），动态链接等特点，结合分页没有外部碎片，提出段页式内存管理

#### 用户虚拟空间格式

> 分为六个部分，这些格式之间都有指针作为**分界线**，防止出现**越界**的情况

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/32%E4%BD%8D%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80.png" alt="虚拟内存空间划分" style="zoom:25%;" />

1. 代码段：存放编译好的机器码形式的代码
2. 数据段：存储指定了初值的数据全局变量和静态变量
3. BSS段：包括未初始化的静态变量和全局变量
4. 堆段：程序运行期间动态申请的内存
5. 文件映射段：存储程序运行调用的其他库的代码段
6. 栈段：存储运行时调用函数使用的局部变量和参数

#### 32位内核虚拟空间格式

> 32位系统只有1G内核虚拟空间，需要**精细划分**

1. 直接（连续）映射区：这块连续区域映射到的物理内存也是连续的，大约896MB
   - 内部存放内核代码和数据
   - 进程创建之后的数据结构也会存放到这里
   - 存放进程调用链的内核栈也存放到这里
2. 内存空洞：大约8M大小的内存空洞
3. 动态映射区：逻辑连续，物理不连续，通过页表映射
4. 永久映射区：可以与物理内存建立永久的映射关系
5. 固定映射区：这个区域中的**虚拟地址不变**，对应的物理地址可以变，这些固定的虚拟地址有固定的用途
6. 临时映射区：存储一些临时的数据

#### 64位内核虚拟空间格式

> 64位虚拟内核空间128T，基本可以**随意挥霍**

<img src="https://cdn.xiaolincoding.com//mysql/other/84eb41fc42b790865eb8bc15d3a2892a.png" alt="image.png" style="zoom:20%;" />

#### 虚拟内存整体布局

> 这里介绍的是**32位**的系统，64的系统如上图所示

<img src="https://cdn.xiaolincoding.com//mysql/other/68763fe509b7adf5987a3ce96c9d12ee.png" alt="image.png" style="zoom:23%;" />

#### 内核如何管理用户虚拟内存

1. 设置一个结构体，内部划分了用户虚拟内存和内核虚拟内存

2. 还划分了用户空间内的六个部分之间的**边界**

3. 结构体内部保存了表示每一个部分的结构体，之间使用双向链表连接便于遍历，为了便于查找，还建立了红黑树的结构

   <img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240322100005966.png" alt="image-20240322100005966" style="zoom:50%;" />

4. 虚拟内存和物理内存之间的关系由页表映射

5. 页面的访问权限由一个**参数**的不同值决定（可读，可写，可执行。。。）

#### cpu从内存中读数据的过程

> 数据传输通过**总线**，IO bridge负责中间的联系

1. 通过总线发起读事务
2. 将虚拟地址转换成内存地址
3. 将内存地址A放到系统总线上，然后**IO bridge**传输到存储总线
4. 存储总线上一旦有地址信号，存储控制器就**根据这个内存地址从内存中读取数据**
5. 将读取到的数据放到存储总线上，然后IO bridge将数据转换到系统总线上
6. CPU接收到系统总线上的数据，将其接收到之后存入三级缓存或者寄存器中

#### 如何根据内存地址读取数据

> 主要是存储控制器的功劳

1. 存储控制器将内存地址转换成内存DRAM芯片中的二维地址，因为数据在内存中存储之后，靠这个二维地址定位
2. 根据二维地址读取到对应的数据
3. 存储控制器将读取到的数据放到存储总线上

#### cpu向内存中写数据的过程

> 主要是总线和IO bridge加上存储控制器在工作

1. 通过总线发起写事务
2. 将虚拟地址转换成内存地址
3. 将内存地址传递到系统总线上
4. 然后IO bridge将系统总线上的内存地址转换到存储总线上
5. 之后存储控制器定位到对应的内存地址
6. cpu将数据放到系统总线上，再次经过IO bridge转换到存储总线上
7. 存储控制器读取到存储总线上的数据，写入刚才指定的内存中

#### 物理内存模型

1. 内核中以struct page来对基本单位页来进行管理，每一个struct page都有一个索引编号PFN。而**管理**这些struct page的方式称为物理内存模型

   - flatMEM平坦内存模型：物理内存连续，分配的页面也连续。所以struct page和PFN之间的映射关系可以保存到一个**数组**中，通过偏移量找到下一个struct page

     <img src="https://cdn.xiaolincoding.com//mysql/other/89fe28d0feb1cd31cbaad5352e1f43d9.png" alt="image.png" style="zoom:20%;" />

   - discontingMEM非连续·内存模型：由于flatMEM按照数组进行管理，一旦物理地址不连续，数组中就会出现很多空洞，于是使用节点node管理每一个断开的连续段，每一个node**内部都是一个数组**：

     <img src="https://cdn.xiaolincoding.com//mysql/other/ae106d5d780328aae34d40560dc0442f.png" alt="image.png" style="zoom:15%;" />

   - sparseMEM稀疏内存模型：为了对更小的连续内存小块进行精细管理，相当于node划分的更小，变成了section，并且每个section还带上了在不在线的状态以支持热插拔

#### 内存热插拔实现原理

> 主要是要优雅的拔下，插上直接等待映射即可，拔下需要保证内部数据还是可用

1. 分为物理热插拔和逻辑热插拔，稀疏内存模型就能支持热插拔
2. 支持热插拔的内存内部存储的全是可以迁移的物理页，例如用户空间使用的物理地址，迁移只需要改变虚拟地址和物理地址之间的映射即可
3. 不可迁移的物理页不能保存到热插拔内存中，例如内核空间中的直接映射区，由于是虚拟地址减去偏移计算得到物理地址，所以物理地址不能变，所以不能迁移
4. 一旦内存物理拔掉，此时稀疏物理模型的中被拔掉的section标记为下线
5. 之后完成物理页的迁移
6. 内存插上之后，等待虚拟地址的映射即可

#### 物理内存架构

> CPU访问内存需要经过总线

1. 一致性访问UMA架构：CPU和内存被总线隔开，并且每个CPU到每个内存的距离是一样的（访问速度一样，所以称为一致性访问架构），CPU个数增多导致总线压力变大：

   <img src="https://cdn.xiaolincoding.com//mysql/other/79170f0256ed383e3934b99a156911fd.png" alt="image.png" style="zoom:10%;" />

2. 非一致性访问NUMA架构：分为本地内存和远程内存，每个cpu都有自己的本地内存，访问速度快，内存不够时才访问远程内存，由于是这种**不连续**的内存，所以前面提到的平坦内存模型就**无法使用**：

   <img src="https://cdn.xiaolincoding.com//mysql/other/672a905532a801f8811040265cae2d0f-20230310000450243.png" alt="image.png" style="zoom:14%;" />

   - NUMA的内存分配策略（先分配本地内存还是远程内存）：
     - 本地和远程都可以
     - 优先在指定节点分配，不够时在距离最近的节点分配
     - 优先在本地，本地不够在远程

#### 内核如何管理NUMA节点

1. UMA架构看做只有一个NUMA节点的伪NUMA架构

2. 针对每一个NUMA节点都建立一个结构体

3. 定义一个全局数组node_date，每个数组中的元素都指向一个NUMA节点的结构体

4. 每一个NUMA结构体中都有以下的内容：

   - 节点id

   - 物理模型中管理**一段**连续内存使用到的mem-map数组

   - 节点内第一个物理页的索引编号PFN

   - 节点内可用物理页个数

   - 所有的物理页个数（可用+空洞）

     ![image-20240323102303344](C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240323102303344.png)

5. 每个NUMA节点的物理内存主要划分为：
   - zone_DMA：用于寻址范围有要求的设备，例如ISA设备只能对内存前16MB寻址
   - zone_DMA32：专门提供给64位系统的DMA设备
   - 高端内存：32位系统中使用的非线性映射区
   - zone_DEVICE：支持热插拔的非易失性内存，或者用于内核崩溃保存调试信息
   - zone_movable：保存可迁移数据，为了支持热插拔
6. 针对不经常使用的页面，内核还会定期规整回收
7. 每个节点有一个状态，这个状态在热插拔时变化，在线还是离线

#### 二进制文件如何映射到用户虚拟内存中

> 先放入物理内存，然后调用映射函数做映射

1. 二进制文件中的只读内容会放入内存中的只读权限的区域，可读写的数据会被放到可读写权限的区域，要执行的文件会被放到可执行区域
2. 之后内核调用一个映射函数完成物理内存到虚拟内存的映射
3. 初始化结构体中的信息，包括进程id，六大部分的起始位置等等
4. 将不同类型的数据映射到虚拟内存中的不同区域

#### malloc分配内存的方式

> 从**用户空间**中分配

1. 使用brk()系统调用从**堆段**中分配，需要的内存大小**小于** 128kb时使用
2. 使用mmap()系统调用从**文件映射区**分配，需要的内存大小**超过**128kb时使用
3. 分配时并不是指定多少分配多少，而是预分配**更大**的空间
4. 分配的空间是虚拟的，只有被访问时才会映射到物理内存中，此时出发**缺页中断**
5. 使用brk()分配的内存free()释放后会放到内存池中，便于后面直接复用
6. 使用mmap()分配的内存空间free()释放后，会归还给OS
7. 使用brk()和mmap()配合可以提高内存的使用效率
8. free()释放时，内存块有自己的描述信息，从而使得free()可以知道释放多大的内存

#### 分配内存的过程

1. 虚拟内存没有分配内存时，会触发缺页中断，此时进行内存分配
2. 有空闲内存直接分配
3. 没有空闲内存就进行内存回收
   1. 后台内存回收：异步进行内存回收，可以**早点触发**后台回收
   2. 直接内存回收：后台内存回收的速度赶不上需要的速度就会同步进行内存回收，此时前台的进程会被阻塞
   3. 内存回收后还不够，此时触发OOM(Out Of Memory内存溢出)机制，不停地选择内存占用多的进程杀死，直到内存够用
4. 回收内存时可以回收文件页（干净页直接释放，脏页先写入磁盘再释放）或者匿名页（写入磁盘再释放）

#### 如何减小回收内存带来的影响

1. 尽量先回收文件页，因为大部分文件页可以直接释放（不是脏页），不用写入内存，少回收**匿名页**，也就是程序运行过程总动态产生的页面
2. 匿名页回收必须保存到磁盘，因为数据不可复制性太大，磁盘换入换出涉及swap机制
3. 争取早点进行异步回收，这样空闲空间就会变大
4. 重要的进程就调整他的一个参数（用来计算被杀死的概率），使其不会因为内存不够而被杀死，也就是手动让其被杀死的概率**降低**

#### 物理内存的水位线

> 当物理内存超过水位线时，开始进行内存回收

1. 页最小阈值：剩余内存在页低阈值到页最小阈值之间时。给当前进程分配完内存**后**，就会**触发内存回收**，一旦超过这个阈值，就会立马触发内存回收
2. 页低阈值：剩余内存在页高阈值和页低阈值之间时，说明内存有一定消耗，但是可以接受
3. 页高阈值：剩余容量高于这个时，说明内存充足

#### 物理内存水位线的计算

> 依赖于一个内核参数min_free_kbytes 计算得来

1. 根据内核参数计算出页最小阈值
2. 页低阈值一般为页最小阈值的1.25倍
3. 页高阈值一般为页低阈值的1.5倍
4. 水位线之间的**间距可调**，根据一个内核参数，根据系统运行情况动态调整水位线，这样可以避免内存回收带来的影响

#### 物理内存页的格式



#### 4G机器申请8G内存

> 分为只分配和分配之后访问

1. 针对只分配不访问：由于分配的是虚拟内存，只要不访问就不会分配物理内存，所以：
   - 32位机器：用户空间可分配的大小为3GB，也就是虚拟内存最多申请3GB，申请8G会失败，因为其最多表示4GB的内存大小
   - 64位机器：用户空间可分配的大小为128T，也就是虚拟内存最多申请128T，申请8G会成功
2. 分配成功之后需要访问：
   - 没开启swap：此时只有4G物理内存，分配8G虚拟内存之后进行访问会出现内存溢出的情况，此时进程会被杀掉
   - 开启swap：此时虽然只有4G物理内存，但是由于可以进行换入换出，所以长时间不用的数据会被**换出**，腾出内存空间，从而8G内存空间可以不停地**换入换出**满足需求

#### linux缓解预读失效

> 与mysql差不多，改进LRU算法，使用两个链表存数据

1. 设计一个**活跃**链表和一个**非活跃**链表
2. 预读数据先放入非活跃链表头部
3. 数据被使用时，将其拿到活跃链表头部
4. 活跃链表尾部**降级**的数据被放入非活跃链表的头部，并不是真正淘汰
5. 当新数据读入时，最终被淘汰的是非活跃链表的尾部
6. 相当于将数据**分级**，这样就不会影响经常被访问的数据
7. mysql是类似的，只是链表名称叫做young和old。young在前，old**链接**在后
8. redis是使用LFU算法，除了计算数据的使用时间还计算数据的使用频率，根据这两个值淘汰数据

#### 缓存污染相关知识

1. 缓存污染：短时间内大量数据只被访问一次，由于LRU算法的特性，这些只被访问一次的数据很久才会被淘汰，占用缓存空间，被污染了
2. 导致大量热点数据被淘汰，降低缓存命中率
3. 解决办法（提高进入链表头部的**门槛**）：
   - linux：**不是第一次**访问就将其放到LRU链表头部，而是第二次
   - mysql：根据数据停留在old中的时间判断，**前后两次**访问时间**超过1s**才将数据拿到young链表头部

#### 进程结构

1. 进程：正在内存中运行的程序
2. 进程结构：使用进程控制块PCB来描述，是进程存在的唯一标识，通过链表组织：
   - 进程标识符：进程的唯一id
   - 用户标识符：标识当前进程属于哪个用户
   - 进程状态：运行，就绪，阻塞等
   - 进程优先级：根据这个判断谁先用cpu
   - 资源分配清单：当前进程正在使用哪些资源
   - cpu相关信息：进程切换时保存的cpu状态信息，便于后期进程恢复

#### 创建进程的步骤

1. 申请空白PCB，填入控制和管理进程的信息，例如进程的唯一标识
2. 为进程分配运行所需资源
3. 进入就绪队列等待调度执行

#### 终止进程的步骤

1. 找到进程对应的pcb
2. 如果处于执行状态，直接停止执行，将资源还给cpu
3. 如果进程有子进程，这个子进程变成孤儿进程，将子进程交给1号进程
4. 将pcb从对应的队列中删除

#### 进程的状态

> 进程按照链表组织，例如所有就绪的进程链接起来组成了就绪队列

1. 运行：正在运行
2. 就绪：可运行，但是需要等待cpu
3. 阻塞：不可运行，需要等待某些资源，这些进程通常会被换出到磁盘，等待的资源出现时才会被换入到内存中成为就绪态
4. 运行：正在运行
5. 就绪：可运行，需要等待cpu
6. 可运行，需要等待某些资源，这些进程通常会被换出到磁盘，等待的资源出现时才会被换入到内存中成为就绪态
7. 挂起：进程被换出到磁盘中的状态，分为阻塞挂起和就绪挂起
8. 创建：正在被创建
9. 结束：正在从系统中消失

#### 进程上下文切换

> 从一个进程切换到另外一个进程

1. 程序运行依赖cpu中的**寄存器**和**程序计数器**
2. 寄存器中存放的程序运行的数据，程序计数器用来存储指令，这两个合起来称为**上下文**
3. 进程的切换就是切换这两个设备中的内容

#### 线程上下文切换

1. 当两个线程**不属于同一个进程**，此时上下文切换就和进程上下文切换一样
2. 当两个线程属于同一个进程，此时只需要切换线程独有的寄存器和栈的信息即可，其余共享的信息不变

#### 线程实现

1. 用户线程：在用户空间中实现的线程，在用户态进行管理
2. 内核线程：在内核中实现的线程，由内核管理
3. 轻量级线程：在内核中来支持用户线程

#### 进程和线程的比较

1. 进程是正在运行的程序，而线程是进程内部的一条执行流程
2. 进程是分配资源的范围，线程是cpu调度的单位
3. 进程拥有完整的资源，线程只独有很少的资源，例如寄存器和栈
4. 线程可以共享进程的资源空间
5. 线程创建时间快，运行开销小

#### 进程调度原则

> 进程状态转换的过程称为进程调度
>
> 调度分为抢占式和非抢占式

1. cpu利用率：保证cpu始终忙碌
2. 系统吞吐量：保证同样时间内运行完成的进程更多
3. 周转时间：进程运行+阻塞+等待的时间尽可能小
4. 等待时间：在就绪队列中等待的时间尽可能小
5. 响应时间：用户请求到得到响应的时间越小越好

#### 调度算法

1. 先来先服务FCFS：当长进程先来时，对后面的短进程不太友好

2. 最短作业优先SJF：长作业很可能长时间得不到响应

3. 高响应比优先：计算进程的响应比，高的先执行：、

   等待时间相同，短作业优先，等待时间过长的长作业也能得到运行机会（由于预先得不到进程的执行时间，所以这个算法是**无法实现**的）：

   <img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240324220038192.png" alt="image-20240324220038192" style="zoom:25%;" />

4. 时间片轮转：每个进程都执行一段时间，时间片一般被设置为20-50ms，时间太长会**退化**成先来先服务
5. 最高优先级调度：根据进程的优先级调度：
   - 静态优先级：创建进程时就确定的优先级
   - 动态优先级：进程运行过程中动态变化
6. 多级反馈队列：
   - 多个队列，队列优先级从高到低，时间片从短到长
   - 新来的进程现在高优先级的队列末尾按照FCFS执行一个时间片
   - 一个时间片没执行完当前进程转到下一队列的末尾
   - 当前队列没有进程，才调度下一队列中的进程
   - 大多数进程在高优先级队列就可以执行完
   - 长进程虽然等待了一段时间，但是轮到自己之后，时间片也会边长

#### 进程通信方式

> 由于进程间的用户空间隔离，内核空间共享，所以通信要通过**内核空间**

1. 管道：单向传递数据，需要双向时要创建两个管道
   - 管道中的数据实际上保存在内核的缓存中
   - **匿名**管道只能实现父子进程之间的通信：grep前面的 `|`
   - **命名**管道可以在不相关的进程间通信，相当于创建了一个共享的文件

2. 消息队列：一个保存在内核中的消息链表
   - 双方需要协商好通信的**数据格式**
   - 只要消息队列没释放或者操作系统没关闭，此时消息队列就一直在
   - 不适合传输大文件，有**大小限制**
   - 发送消息需要将数据从用户态拷贝到内核态，接收消息需要从内核态拷贝到用户态，存在**拷贝开销**

3. 共享内存：拿出一块虚拟地址，映射到一块共享的物理内存中
   - **避免数据拷贝**，直接开辟一块共享的物理内存，这边写入，那一边就能读到

4. 信号量：是一个整型的计时器用于进程间的**同步和互斥**，保护共享资源
   - 防止共享的内存由于多个进程修改出现版本不一致的问题
   - P操作：将信号量-1，相减之后信号量<0说明此资源不能再被访问
   - V操作：将信号量+1，相加之后信号量>0说明此资源可以被访问
   - P，V操作需要成对出现
   - 信号量为1说明是**互斥**信号量
   - 信号量为0说明是**同步**信号量

5. 信号：异常情况下，使用信号来进行通信
   - 例如ctrl+c强行停止进程就会发送一个SIGINT信号
   - 使用kill -9杀死进程此时会发送一个SIGKILL信号
6. socket：跨网络通信时使用socket
   - 指定好通信的协议，通信双方的地址，经过bind，llisten，connect，accept或者recvfrom和sendto就可以开始通信
   - 建立连接的socket与真正传输数据的socket不一样
   - 使用socket本地传输时，直接绑定到一个本地文件，不需要绑定ip和端口

#### 临界区和临界资源

1. 临界区：每个进程访问临界资源的一段代码
2. 临界资源：一次只允许一个进程访问的资源

#### 进程同步互斥

1. 同步：进程间在一些关键点上需要互通等待与互通消息，这种互相制约的等待称为同步，例如必须先吃饭后洗碗，这种制约关系就是同步
2. 互斥：针对某一资源来说，同一时间只允许一个进程操作
3. 锁：加锁可以实现进程互斥：
   - 忙等待锁：也就是CAS算法，只要原值不是我们知道的原值，说明当前数据被修改过，就不能进行操作，拿着**新的原值**又去判断
     - 会出现**自旋**情况，也就是不是期待的原值时一直循环判断
     - 出现**ABA**问题，期待的原值是A，拿到的也是A，但是版本不一样，可以加上版本号，挪用公款后面补上，但是也违法了
     - 只能保证**一个变量**的原子操作，因为只能比较一个变量是否改变
   - 无等待锁：发现期待的值与当前值不符，不进行自旋，而是直接将当前进程放入等待队列，等待后面cpu的调度
4. 信号量：为1代表互斥信号量，为0代表同步信号量

#### 生产者消费者问题

1. 生产者生产数据放到缓冲区，消费者消费缓冲区中的数据

2. 缓冲区互斥访问

3. 生产者消费者之间同步，有了数据才能消费<img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240326101129225.png" alt="image-20240326101129225" style="zoom: 50%;" />

   <img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240326101030782.png" alt="image-20240326101030782" style="zoom: 33%;" /><img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240326101050346.png" alt="image-20240326101050346" style="zoom:33%;" />

4. 生产者拿到缓冲区的互斥锁之后，开始生产数据
5. 消费者拿到缓冲区的互斥锁之后，开始消费数据

#### 哲学家就餐问题

> 哲学家围一圈，中间有叉子，有两个叉子才能就餐，可能存在死锁，同时先拿左边再去拿右边拿不到

1. 增加互斥量，一次只能一个哲学家就餐，其余哲学家需要阻塞
2. 奇数先拿左再拿右，偶数先拿右再拿左
3. 两个邻居都没有进餐时，自己才能进餐，这需要一个状态数组记录哲学家的状态

#### 读者写者问题

> 同一时间允许多个读。读写，写写同一时间互斥

1. 读者优先：有写者直接阻塞，优先读，可能造成写者一直阻塞
   - 只要有读者（数量大于0），后续读者直接进入临界区
   - 针对读者数量的变化操作要**互斥**防止出错
   - 第一个读者进入临界区读数据时，将写者阻塞，后面的**读者直接进来**读
   - 最后一个读者离开临界区后，释放临界区资源，后续读者写者竞争临界区
2. 写者优先：有读者会阻塞，优先写，
   - 只要有写者（数量大于0），后续写者可以直接竞争临界区进行写操作，相当于插队
   - 操作写者数量的变化操作要互斥防止出错，并且**写者之间**竞争临界区也需要互斥
   - 第一个写者拿到临界区之后，直接写，后续的写者只要当前写者写完就可以直接写，读者获取不到临界区可能一直阻塞
   - 最后一个写者写完释放临界区，之后读者写者竞争
3. 公平方式：
   1. 一旦有写者，后面的读者就不能插队，可以设置一个flag，写者到达就p(falg)，读者p(falg)时会被阻塞，相当于不能插队
   2. 没有写者的时候，多个读者可以同时读
   3. 当读者数量为0时释放缓冲区，此时如果有写者就可以获得缓冲区
   4. 相当于等先来的读者读完之后，写者就可以写

#### 避免死锁

> 由于保护共享资源加了互斥锁，加锁不当会产生进程互相死等的情况，同时满足四个条件才会产生死锁：
>
> 1. 互斥条件：多个进程不能同时使用一个资源
> 2. 持有并等待：等待新资源的时候，已经拿到的资源不会释放
> 3. 不可剥夺：自己使用完之前，别的进程无法使用
> 4. 环路等待：两个进程的资源获取顺序形成了环

只要破坏四个条件的任何一个就可以打破死锁

1. 互斥条件无法破坏，这是由资源的性质决定的，为了安全不能破坏
2. 破坏持有并等待：进程运行前一次性分配所有资源，没分配够就直接等待。
3. 破坏不可剥夺：申请其他资源失败时，现有的资源会被释放
4. 破坏环路等待：给所有的资源编号，必须按照资源号递增的顺序申请资源
5. **银行家**算法：保证分配资源后不会进入不安全状态（可能死锁）
   - 进程需要预先提出自己的最大资源请求
   - 分为最大需求矩阵，已分配矩阵，可用矩阵
   - 给某一个进程分配之后，按照某一种顺序，所有的进程是不是都可以正常运行结束
   - 如果可以说明当前时刻是安全的
   - 如果不可以说明当前时刻不安全

#### 互斥锁和自旋锁

> 是一种独占锁

1. 互斥锁：加锁成功正常执行，加锁失败将线程置为睡眠状态，锁被释放，当前线程被唤醒
2. 第一次上下文切换：加锁失败，会将线程设置为睡眠状态
3. 第二次上下文切换：锁被释放，当前线程变成就绪状态
4. 自旋锁：加锁不成功一直询问
5. 互斥锁加锁失败会**线程切换**，自旋锁加锁失败会**忙等待**
6. 加锁时间很短时，互斥锁的线程切换时间比加锁时间消耗更多，此时应该尽可能选择自旋锁

#### 读写锁

1. 当前没有写锁，多个线程能并发的持有读锁，当前有写锁，其余线程无法加锁，所以写锁是一个**独占锁**。读锁是一个**共享锁**
2. 读写锁就像读者写者问题一样，分为读者优先，写者优先，公平竞争（使用队列）
3. 如果可以区分读写场景，读写锁更加合适

#### 乐观锁和悲观锁

1. 悲观锁：认为多线程修改共享资源概率很高，容易出现并发读写问题，所以操作之前必须上锁
2. 乐观锁：认为多线程修改共享资源概率较低，不容易出现并发读写问题，每次先修改，修改之后判断当前数据在修改过程中是不是被其他人修改从而判断是否需要放弃本次操作
   - 记录当前操作前的原值
   - 进行修改
   - 修改之后判断原值是否变化，变化说明修改的过程中被别人修改过了，此时放弃本次修改
   - 修改过后原值没有变化，此时提交修改
   - 像多人编辑文档，git都使用了乐观锁，真的发生冲突让用户自己解决

#### 进程最多可创建多少线程

1. 主要取决于进程的虚拟空间多大以及每个线程占用多大
2. 32位系统，进程最多可以占满3G的用户空间
3. 进程创建线程时，每个线程默认分配10MB的栈空间，这个大小可以改
4. 所以大约最多可以创建300个线程，如果将默认分配的栈空间改小，创建的线程数还能变多
5. 另外系统支持的最大线程数，线程ID的最大范围都会限制线程的数量，超过这些范围，线程会创建失败

#### 线程崩溃，进程怎么办

> 普通进程会崩溃，Java中的JVM不会崩溃，因为内部定义了信号处理函数，内部线程出现异常之后，系统发出**信号**尝试中断进程，JVM的**信号处理函数**会将出现错误的线程资源回收，自己正常运行

1. 线程因为访问非法内存崩溃，此时进程也崩溃，因为系统认为这种非法操作可能影响别人，所以干脆让整个进程崩溃

2. 想要进程崩溃，此时就发送一个信号，例如kill -9会发送一个SIGKILL信号，进程收到信号之后，调用信号处理函数（如果有的话）完成最后的处理，最后进程退出

3. JVM就有自己的信号处理函数，一旦出现异常，JVM会完成对应的资源回收后选择继续运行或者退出

   
