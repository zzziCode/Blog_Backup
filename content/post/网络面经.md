---
title: "网络面经"
description: "网络面经"
keywords: "网络面经"

date: 2024-03-11T08:52:11+08:00
lastmod: 2024-03-11T08:52:11+08:00

categories:
  - 面试
tags:
  - 面经
  - 网络

# 原文作者
# Post's origin author name
author: zzzi
# 开启数学公式渲染，可选值： mathjax, katex
# Support Math Formulas render, options: mathjax, katex
math: mathjax
# 原文链接
# Post's origin link URL
#link:
# 图片链接，用在open graph和twitter卡片上
# Image source link that will use in open graph and twitter card
#imgs:
# 在首页展开内容
# Expand content on the home page
#expand: true
# 外部链接地址，访问时直接跳转
# It's means that will redirecting to external links
#extlink:
# 在当前页面关闭评论功能
# Disabled comment plugins in this post
#comment:
#  enable: false
# 关闭文章目录功能
# Disable table of content
toc: false
# 绝对访问路径
# Absolute link for visit
#url: "网络面经.html"
# 开启文章置顶，数字越小越靠前
# Sticky post set-top in home page and the smaller nubmer will more forward.
#weight: 1

# 开启各种图渲染，如流程图、时序图、类图等
# Enable chart render, such as: flow, sequence, classes etc
#mermaid: true
---

> 🕸 网络面经

本文中介绍了一些计算机网络中常见的面试题，也可以当做平时的学习笔记来使用，知识点参考小林coding的[图解系列](https://xiaolincoding.com/)，文章长期更新

<!--more-->

#### TCP/IP的层数

> 这是对OSI七层网络协议的简化，现在变成了四层

1. 应用层：应用软件在这一层实现，不同应用需要通信时，就把数据交给下一层传输层

2. 传输层：有两个协议TCP,UDP，加上端口号等信息，端口号负责区分消息到达另一台设备时，交给哪个端口对应的应用，可能进行**分段**，之后交给下一层

3. 网络层：将从上层接收到的报文加上IP等信息，ip负责表示将消息交给哪一台主机，可能进行**分片**，交给下一层，ip地址分为网络号（找子网）和主机号（找子网中的主机）

4. 网络接口层：在数据的ip头部加上MAC头部，封装成数据**帧**，这样就可以通过mac地址区分网络上的设备

   <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/%E5%B0%81%E8%A3%85.png" alt="img" style="zoom:35%;" />

#### 输入网址到页面显示的过程

1. 解析url：确定要访问哪个服务器和服务器中哪个文件

2. 根据上述信息生成http请求（请求行，请求头。。）

3. 根据要访问的服务器名在DNS服务器中查询其ip地址，这里涉及到**域名解析**

4. 找到通信的目标ip之后，浏览器通过调用socket库来委托协议栈进行通信

5. 由于http基于tcp进行通信，此时需要三次握手建立连接

6. 建立连接也需要按照这个流程传输数据，是为了确保双方确实可以收发数据

7. 建立连接之后将数据进行封装，加上TCP头部（端口和序列号），进一步交给ip层

8. ip层将数据封装成网络包，加上IP头部（源IP和目标IP），可能进行分片

9. 之后对数据包加上MAC头部，主要加上MAC地址信息，包括发送方和接收方，此时需要用到ARP协议，填入MAC地址就知道数据**先发送**给哪个设备

10. 当客户端和服务器不在同一个子网中时，得到的MAC地址就是发送端所在子网的路由器MAC地址，在同一个子网时，此时MAC地址就是接收方的MAC地址

11. 数据封装好之后，经由发送方的网卡发送出去

12. 发送方网卡发送的消息先到达交换机，判断该消息从交换机哪个端口转发出去，这根据交换机中缓存的mac地址与端口的映射表

13. 找不到端口的映射，就发送给所有的端口（除了来时的端口）

14. 从端口出来到达路由器，路由器判断这个包自己需不需要转发（MAC地址是否一样）

15. 需要转发就去掉数据的MAC头信息，根据内部的IP头信息进行转发

16. 最终消息在网络上传输，这里根据ip地址进行转发，看接收方ip在哪个网段就转发给路由器的哪个端口

17. 都没有匹配的就转发给默认端口

18. 到达最后一跳时加上MAC地址，因为此时路由器的下一跳应该是消息的接收方了

    > 也就是在数据链路层的通信才会需要MAC地址

19. 接收方判断MAC地址是否与自己一样

20. 判断IP地址是不是符合的

21. 判断TCP中的序列号是不是我想要的（我上次ACK什么，就说明这次想要什么）

22. 以上判断都通过，此时根据TCP中记录的端口号进行转发，最终到达HTTP的服务器

23. HTTP的服务器发现对方想要请求网页，于是将网页封装到http响应报文中

24. 经过TCP，IP，MAC的封装，从网卡出去，到达交换机，路由器，最终一步一步到达请求网页的客户端，相当于是逆过程

25. 客户端还是一层一层的进行判断MAC，IP，TCP序列号，然后按照端口转发

26. 浏览器收到HTTP服务器发送过来的页面之后，就可以显示了

27. 最终会发起四次挥手断开连接

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/2.jpg" alt="简单的网络模型" style="zoom: 33%;" />

> 类似于要发送八条消息，三次握手，一条真实消息，四次挥手

#### DNS解析过程

> 为了获取目标主机的ip地址

1. 本地发送一个DNS请求到本地记录的DNS服务器
2. DNS服务器查找缓存，有目标就直接返回
3. 找不到就给客户端一个新的上层DNS服务器地址，客户端继续询问
4. 找到就返回，找不到继续给一个新的DNS服务器地址，这是由要通信的域名决定的
5. 最终得到通信目标的ip地址

#### ARP协议过程

> 为了获取下一跳的设备MAC地址

1. 先查询ARP缓存，缓存中由ip和mac的对应信息直接获取
2. 没有就以广播的形式询问xxx这个ip地址是谁的
3. 每个人判断一下，是自己的话就回答自己的mac地址是多少
4. 如果没有人的ip与之匹配，此时返回的时路由器的MAC地址

#### TCP/IP 网络模型与 OSI 网络模型（四层与七层）

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/OSI%E4%B8%8ETCP.png" alt="img" style="zoom:33%;" />

#### linux接收网络包流程

1. 网卡收到别人传递来的消息

2. 通过DMA技术（硬件机制）将网络包写入到内存地址中

   > DMA技术允许外围组件直接将数据传递给内存或者从内存中读取数据，可以减小无用操作，提高吞吐量

3. 使用NAPI机制（中断+轮询）唤醒数据处理程序，之后来轮询网络包中的内容即可

4. 读取到数据首先会到达网络接口层，去掉帧头帧尾交给网络层

5. 网络层根据ip判断数据的走向，转发还是继续处理

6. 继续处理的话就将IP头去掉，交给传输层

7. 根据传输层的TCP头或者UDP头来决定将数据放到哪个Socket的缓冲区

8. 应用程度调用socket接口读取数据给自己

>**socket**：工作在应用层和传输层之间，采用Unix**一切皆文件**的思想，数据看成文件进行读写操作

#### linux发送网络包流程

1. 应用程序调用Socket接口将数据放到socket缓冲区
2. TCP协议拷贝缓冲区副本进行发送，防止需要重传
3. 对缓冲区数据加上TCP头，**这里使用TCP协议举例**
4. 网络层收到数据之后会选取路由，填充IP头，可能进行数据分片
5. 通过ARP协议获取**下一跳**的MAC地址，可能是目标主机，也可能是路由器
6. 网卡驱动检测到数据之后，会将其保存到缓冲器区中
7. 之后使用DMA机制将缓冲区中的数据读取到内存中准备发送到网络中
8. 发送完成接收到消息的ACK说明不在重传，此时清理缓冲区

#### HTTP协议概念

超文本传输协议：定义了计算机之间通信的规范，主要是针对**两点**之间传输数据的，传输的内容是**超文本**（文字，图片，视频，超链接）

#### HTTP常见状态码

> 1表示中间状态，2表示成功，3表示重定向，4表示客户端错误，5表示服务端错误

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png" alt=" 五大类 HTTP 状态码 " style="zoom:33%;" />

#### HTTP常见字段

> 主要有以下几种，其余的记不住了

1. Host：客户端发送请求时指定服务端的域名
2. Content-Length：标识服务端返回的数据长度，这是为了解决TCP传输时的**粘包问题**
3. Connection：是否保持长连接，以便客户端的其他请求复用这个连接
4. Content-Type：本次响应的数据的格式
5. Accept：客户端用这个字段声明自己可以接受哪些字段
6. Content-Encoding：服务端说明此次数据的压缩格式
7. Accept-Coding：客户端声明自己可以接受哪些压缩方法

#### GET和POST的区别

> 本质上都是TCP链接，但是由于HTTP的规定和浏览器的限制导致有一些细微的差异

1. GET：
   - 指的是从服务端获取指定的资源
   - 参数一般写到请求URL中，所以更不安全，但是这只是规范，并不强制要求，GET也可以向POST一样将参数放到body中
   - 浏览器将请求数据一次性发出去
2. POST：
   - 根据请求报文的body对指定资源做出处理
   - 参数放到body中，只是一个规定，可以不遵守
   - 浏览器将请求数据分为header和data两次发送，Firefox好像就发送一次

#### GET 和 POST 都是安全和幂等的吗？

1. 安全：请求不会破坏服务器上的资源
2. 幂等：多次执行相同的操作，结果是相同的

**GET**方法<u>是</u>安全且幂等的，因为他只是请求资源，相当于只读，所以GET请求的数据可以进行缓存，因为每次请求的数据都是相同的

**POST**方法<u>不是</u>安全和幂等的，因为他会修改服务器的资源

#### HTTP缓存实现方式

<img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240311100505643.png" alt="image-20240311100505643" style="zoom:33%;" />

> 针对幂等（每次请求结果都一样）的请求，我们可以将请求的数据缓存到本地
>
> 强制缓存是只判断数据的过期时间，协商缓存是**每次**都问问服务器缓存还能用吗

1. 强制缓存：只要浏览器说缓存没过期，那么就直接使用缓存的数据

   > 浏览器第一次请求这个数据的时候，服务器给其加上一个过期时间，每次请求时判断当前缓存数据过期没，没过期就直接使用缓存数据

2. 协商缓存：向服务端发送请求，服务端根据请求携带的一些参数判断是否可以使用缓存

   - 基于时间实现：当服务端的数据最后修改时间大于本地缓存的最后修改时间，说明本地缓存失效，直接返回新资源返回200，本地缓存没失效直接返回304访问缓存

   - 基于唯一标识实现：资源一旦变化，唯一标识就会变化，服务端根据客户端传递过来的唯一标识判断缓存是否失效，没失效就可以使用

     > 核心就是判断本地缓存和服务端的数据是否一致

**只有没命中强制缓存时才进行协商缓存**

```java
 Cache-Control  > expires > Etag > Last-Modified
```

#### HTTP1.1的优缺点

1. 简单，灵活，易于扩充：各种请求方法，状态码，头部字段都可以扩充
2. 应用广泛，跨平台：随处可见HTTP的应用，浏览器，APP，新闻，游戏，天然跨平台
3. 无状态：没有额外的信息记录请求的状态信息，减轻了服务器的压力，但是对于登录>加入购物车>下单>结算>支付这种业务来说，每次都需要验证身份，简单解决方法就是**cookie**（标识符）
4. 明文传输：抓包时极其方便，但是信息直接暴露，不安全
5. 不安全：通信使用明文，信息容易泄露，不验证通信方身份，容易登录到假网站，报文无法确保完整或是否被篡改

#### HTTP/1.1的性能

1. 长连接：不用每次请求都建立连接，减小开销，只有主动断开或者超时才会断开连接
2. 管道网络传输（有但是没用过）：在一个TCP连接中可以发出多个请求，按照请求的顺序响应，一旦前面的阻塞，后面的也会持续等待

#### HTTP与HTTPS的区别

> 建立连接时多了TLS握手（生成对话秘钥）的过程，传输数据多了加密的过程

1. HTTP明文传输，HTTPS加入了SSL/TLS协议，使得报文加密传输
2. HTTP进行TCP三次握手之后就可以传输，HTTPS三次握手之后还需要进行SSL/TLS的握手过程才能传输
3. 默认端口不一样，HTTP默认80，HTTPS默认443
4. HTTPS需要申请数字证书，保证身份可信

#### SSL/TLS协议是什么

> 是一个密码通信框架，集成了很多密码学中的内容

1. 客户端向服务端索要公钥

2. 为了防止公钥不被篡改，需要将服务端的公钥放到数字证书(CA)中

3. 双方协商生成一个"对话秘钥"，公私钥加密这个对话秘钥（非对称加密）

   > 上面几步是TLS握手阶段

4. 使用对话秘钥加密通信的报文（对话秘钥使用对称加密，速度很快）

#### HTTPS中的TLS使用RSA的握手过程

1. TCP三次握手之后开始传递请求
2. 第**一**次TLS握手：客户端发起加密通信请求，请求内主要包含一个随机数（用于生成对话秘钥）和支持的加密算法
3. 第**二**次TLS握手：服务端针对加密通信请求作出响应，主要包含一个随机数（用于生成对话秘钥），使用的加密算法(RSA等)以及一个数字证书
4. 客户端**确认**数字证书的真实性之后，从中取出服务器的公钥
5. 第**三**次TLS握手：向服务端再次通信，此次使用公钥加密数据，主要包含一个随机数
6. 双方都根据上面的**三个**随机数计算出一个对话秘钥
7. 之后客户端将之前通信的数据做一个摘要并加密发送，来验证加密通信是否可用以及之前的通信过程中是否有数据被篡改
8. 第**四**次TLS握手：服务端也将之前通信的数据做摘要并加密发送，来验证加密通信的可用性以及之前通信过程中是否有数据被篡改
9. 后期就使用对话秘钥进行对称加密来通信

#### HTTPS中的TLS使用ECDHE握手过程

> ECDHE是一种基于椭圆曲线的密钥交换算法，通信过程中的会话秘钥是计算出来的，不是传递得到的，所以不会被中间人窃取，具有前向安全性

1. TCP三次之后开始传递请求

2. 第一次TLS握手：客户端发起加密通信请求，主要包含一个随机数和支持的加密算法

3. 第二次TLS握手：服务端针对请求进行响应，主要包含一个随机数和使用的加密算法还有数字证书

4. 服务端选择一个椭圆曲线G，然后生成一个随机数a作为服务端椭圆曲线的私钥保存到本地

5. 根据私钥计算出服务端的椭圆曲线公钥（A=aG），然后对公钥进行签名防止第三方篡改，之后发给客户端

   > 这里计算是根据椭圆的点运算，私钥计算出公钥之后，在想利用公钥计算出私钥就很困难，所以具有前向安全性
   >
   > 相当于即使中间人拦截到了公钥也无法破解私钥，也就是知道A，G想反向计算a很困难

6. 第三次TLS握手：客户端验证服务端证书的合法性，之后生成一个随机数b作为客户端椭圆曲线的私钥

7. 然后根据私钥计算出客户端的椭圆曲线公钥（B=bG），将公钥发给服务端

8. 之后双方利用自己的私钥和对方的公钥计算出一个共享密钥，这个是相同的

   > 客户端：自己的私钥*服务端公钥=bxA=bx（aG）=abG
   >
   > 服务端：自己的私钥*客户端公钥=axB=ax（bG）=abG
   >
   > 所以计算出的共享密钥是相同的

9. 共享密钥+之前传递的两个随机数计算出会话秘钥，这个自然也是相同的

   > 上面涉及到[协商密钥的过程](https://wenfh2020.com/2023/10/08/https/)

10. 客户端将之前发送的消息做一个摘要并加密发送，用来验证加密通信是否可用以及之前的通信过程中是否有数据被篡改

11. 第四次TLS握手：服务端执行同样的操作来验证

12. 之后使用会话秘钥来加密通信

#### 对称加密和非对称加密

1. 对称加密：加密数据双方只使用**一个**秘钥，运算速度更快
2. 非对称加密：通信双方使用公私钥**两个**秘钥进行加密

#### 服务端得到数字证书的过程

1. 服务器将自己的公钥注册到CA(数字证书认证机构)
2. CA使用自己的私钥对公钥进行数字签名，主要是将公钥，用途，颁发者，有效时间等信息封装在一起计算哈希
3. CA使用自己的私钥对这个哈希值加密，将其添加到文件证书上(主要包括加密的内容，公钥，用途等信息)，形成数字证书
4. 服务端收到自己的数字证书

#### 客户端检验数字证书的过程

1. 客户端使用相同的哈希算法按照CA计算哈希的步骤自己计算证书文件，得到一个哈希值
2. 使用CA的公钥解密得到另外一个哈希值
3. 两个哈希值相同说明数字证书可信，不相同还需要进行**信任链**的验证操作

#### 信任链验证操作

1. 客户端收到一个证书C，验证发现哈希值不相同，此时进行信任链验证操作
2. 客户端发现证书C由机构B颁发，而机构B的证书由机构A颁发
3. 机构A是根机构，是自签证书，**客户端信任此证书**
4. 此时客户端使用机构A的证书去验证机构B的证书是否可信
5. 可信的话再使用机构B的证书去验证C是否可信
6. 如果还是可信的话，此时客户端就信任证书C

> 可以看出是一个**链传递**的关系，客户端信任A，而A信任B，B信任C，最终客户端也信任C，操作系统中一般会内置一些根证书

#### HTTPS如何保证数据完整性

> 使用TLS**记录协议**保证数据的完整性和来源

1. 数据被分成很多片段，每个片段要进行压缩
2. 压缩的片段会加上消息认证码，保证数据完整性
3. 为了保证消息不会重复发送多次，每个片段还会带上一个编码
4. 使用协商好的会话秘钥进行对称加密
5. 加密好的数据加上传输的必要信息（数据类型，版本号，长度等）就可以传输了

#### HTTPS优化

1. 加快计算密钥的过程：换好CPU
2. 密钥交换算法：将RSA改成ECDHE可以加快TLS的握手过程，并且安全性更高
3. 减小证书大小，这样传递证书时的开销就会更小
4. 服务端定期向CA查询自己的证书状态是否过期，获得一个带时间戳的签名缓存住，客户端请求得到证书之后，只需要根据这个时间戳签名就可以直接判断证书是否过期，不用向CA查询
5. 会话复用：第一次建立连接后缓存会话秘钥，后期直接复用密钥即可减少TLS握手时间：
   1. 使用唯一的SessionID标识这个会话秘钥，后期该客户端再次连接时会携带一个SessionID，该SessionID的会话秘钥还在则直接返回会话秘钥，不需要TLS握手
   2. Session Ticket：第一次建立连接之后，服务端将会话秘钥加密形成Ticket交给客户端，下次连接时传递这个Ticket，服务端解密并验证这个会话秘钥的有效期，有效的话才开始通信
   3. Pre-shared key：将Ticket和请求一起发给服务端，如果解析出来的会话秘钥没过期，此时可以直接响应请求，时间更快

#### 重放攻击

> 要给会话秘钥设置过期时间，防止别人得到了SessionID或者Session Ticket解析出会话秘钥进行重放攻击

中间人恶意截取了客户端通信时的SessionID或者SessionID Ticket和POST报文，之后就可以冒充客户端发送POST请求，而POST可以修改数据库，最终数据被修改，客户端并不知情

#### HTTPS一定可靠吗

> HTTPS**本身是可靠**的，如果你信任了不安全的证书或者电脑被入侵导入了不想信任的证书，此时才会出现不可靠的情况，例如：

1. 客户端向服务器发起请求时，被假基站拦截到了，经过假基站再将请求转发到服务端

2. 此时客户端和服务端之间就会多出一个假基站，假基站通过伪造的证书与客户端进行通信

3. 浏览器是能识别到证书不安全的，但是如果你接受了这个不安全的证书，此时假基站就能获取到客户端请求的明文数据，也能知道服务端响应的明文数据

4. 此时变得不可靠

   > 这种不可靠是因为用户手动信任了不安全的假基站证书导致的，或者电脑被恶意导入了假基站的证书导致的

#### 抓包工具的工作原理

> 承担一个假基站的效果，主要是要让客户端信任抓包工具自己的证书

1. 抓包工具让客户端信任自己的证书，在客户端受信任的证书列表中导入自己的证书
2. 之后客户端正常和抓包工具建立连接
3. 抓包工具得到客户端传递的数据之后，进行解密，实现抓包
4. 之后将解密后的包用自己的秘钥进行加密传递给服务端
5. 由于服务端不校验客户端的身份，所以可以正常通信
6. 服务端将响应数据交给抓包工具，抓包工具解压之后，用与客户端通信的秘钥加密并返回给客户端
7. 客户端与服务端之间都不知道中间存在一个中间人，以为是直接进行通信

#### 如何避免被抓包或者出现假基站

1. 不要信任任何不安全的证书
2. 使用电脑应规范，防止被恶意注入不安全的证书
3. HTTPS**双向认证**，服务端要验证客户端通信的身份，服务端认为不安全的证书就拒绝通信，不像客户端提示不安全的证书可以选择信任

#### HTTP/1.1相比HTTP/1.0的改进

1. 使用长连接减小开销
2. 支持管道，一个请求发送之后，不必等待响应就可以发送下一个请求

#### 如何优化HTTP/1.1

1. 减少重复HTTP请求的发送，将不变的数据缓存（强制缓存+协商缓存）到本地

   > 强制缓存过期（过期不一定更新）之后，会尝试使用协商缓存(时间或者标识符)来确认缓存中的数据是否可以继续使用

2. 合并请求：多个请求共享请求头，减小通信时的开销

   - 将多张图片利用合并的技术合并成一个大图片，这样一次请求就可以获得多个图片
   - 使用webpack技术将js，css等资源打包，请求时一个请求就可以获得这些资源
   - 图片使用二进制编码嵌入HTML文件中，一次请求就可以获得图片和HTML文件

3. 延迟发送请求：请求按需发送，不需要的请求暂时不发送，只有需要的时候才发送请求

4. 减小响应数据的大小：将响应数据进行压缩

#### HTTP/2相比HTTP/1.1的改进

> 主要是引入一个Stream

1. 基于HTTPS，通信更加安全
2. 通信时**头部**数据也可以压缩(HPACK算法)，减小传输开销
3. 通信报文采用二进制的格式，对计算机更加友好，减小转换开销，并且消耗空间更小
4. 可以并发传输，引入了Stream的概念，不同的请求有不同的StreamID，Stream间可以乱序发送，Stream内需要按序发送，此时就可以做到有序组装消息
5. Stream可以设置优先级，从而优先响应某些请求，提高用户体验
6. 服务器主动推送，HTTP/2可以支持服务器主动向客户端推送消息，客户端的StreamID必须是**奇数**，服务端的StreamID必须是**偶数**

#### HPACK算法

1. 静态字典：高频出现在头部的内容建立静态字典，之后就用这些内容对应的编码代替，从而减小头部大小

2. 动态字典：一次连接中动态变化的字符串建立动态字典，然后还是用编码代替变化的内容，依次连接中的请求过多就会导致动态字典变得很大，从而影响服务器性能

   > 当一次连接中的请求过多时就会断开连接，从而**释放**动态表占用的内存

3. 哈夫曼编码：剩下没有被索引的内容还可以使用哈弗曼编码来进一步压缩

> 就这样利用索引+哈弗曼编码来**压缩头部**

#### HTTP/3相比HTTP/2.0的改进

> 底层的TCP改成UDP，所以主要是UDP的优点

1. HTTP2在TCP层面会有**对头阻塞**问题，也就是前面的包没收到，必须等这个包重传好之后后面的包才能处理，HTTP3将TCP协议改成UDP协议，丢包不重传
2. 发生丢包时，只有当前的Stream阻塞，其余的Stream不影响，阻塞的影响变小，丢弃的包也需要重传
3. 没有TCP的三次握手，连接建立更快
4. 连接迁移：当通信双方IP变化时，不会重新建立连接，只要上次建立连接分配的连接ID还在就可以直接通信，因为HTTP/3不是基于IP端口的，而是**基于连接ID**的

#### 有了HTTP为什么还要有RPC

1. 早期HTTP适用于B/S，而RPC适用于C/S，二者适用范围不同，现在没有区分这么大
2. 二者连接方式不一样：HTTP一般向DNS服务器获取目标服务器的ip进行通信，而RPC一般有一个中间服务存储所有服务的ip信息，通过中间服务获取目标服务器的IP
3. RPC会建立一个连接池，可以做到连接复用，用完的连接放回连接池下次还能接着用
4. HTTP请求中冗余的头信息太多，RPC更加关注于要发送的数据本身，所以微服务项目内部一般使用RPC远程调用
5. RPC比HTTP出现的早，很多老项目还是使用的RPC，并且RPC比HTTP/1.1性能要好，灭有过多的冗余头信息，结构化的数据传输起来也更方便

#### 有了HTTP为什么还要有WebSocket

HTTP设计之初是为了浏览网页，只有客户端主动请求，后期需求变多，需要服务端主动推送，此时才出现了WebSocket，比如网页主动弹窗广告，网页游戏主动更新环境变化，所以**应用场景不一样**

1. 浏览网页时使用HTTP协议，网页游戏就是用WebSocket协议，这取决于应用场景是半双工还是全双工
2. WebSocket协议建立连接时需要使用到HTTP，这是因为所有浏览器都支持HTTP协议，所以先使用HTTP尝试建立WebSocket连接进行升级，升级成功就可以进行全双工通信

#### HTTP如何实现服务端主动推送

1. 定时轮询：每个几秒就在后台发送一个请求给服务端，前台看起来就是服务端主动推送，因为用户自己没有主动发出请求
2. 长轮询：在一段时间内只要收到了某个事件服务器就自动推送，例如前端一扫码成功服务器就自动推送登陆成功后的页面，RabbitMQ就是这种机制，队列中一旦有消息，消费者就开始处理
3. 将HTTP改成WebSocket：由于HTTP是半双工的，导致服务端不能主动推送，而WebSocket是全双工的，可以直接推送消息，并且WebSocket是利用HTTP来进行升级的

#### TCP的头格式

<img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230534096.png" alt="TCP 头格式" style="zoom:23%;" />

1. 序列号：给传递的包标记一个序号防止乱序
2. 确认号：对之前数据的确认，对下一数据的期望
3. 控制位：控制哪些字段有效，例如ACK有效证明确认应答的字段有效，FIN有效代表希望断开连接
4. 数据：真实发送的数据

#### 为什么需要TCP

> TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。

因为上层的应用层只关注将数据交给下层，而下层的IP层不可靠，他不保证网络包的按序交付和完整性，这些只能依靠TCP来保证

####  什么是TCP

> TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。

1. 面向连接：一对一连接之后才能发送消息
2. 可靠：不论网络链路怎么变化，TCP一定保证报文能够到达
3. 字节流：前一个报文没有收到，后面的报文即使收到了也无法处理，并且重复的报文会被丢弃，并且如果不知道消息的边界就无法读取有效的消息，例如夏洛，特烦恼，接收端可能读取为夏洛特，烦恼

#### 什么是TCP连接

> 用于保证可靠性和流量控制的状态信息，包括Socket，序列号，窗口大小这些信息组合起来成为连接

1. Socket：ip和端口
2. 序列号：用来防止网络包乱序
3. 窗口大小：用来流量控制，一旦当前数据没有被应用层处理，就将数据放到接收缓冲区，然后通过这个**窗口大小告知缓冲区还能放多少数据**，警告发送方要减少发送的数据量或者要让接收方有时间处理数据

#### 如何确定一个TCP链接

1. IP头部中的双方IP地址
2. TCP头部中的双方端口号

#### 服务端的一个端口最多可以接受多少链接

> **理论**上客户端只要有了链接到来就可以接受，但是**实际**上收到一些因素的影响：

1. 每个TCP连接都是一个文件，因此文件描述符被占满了，此时就无法再接受连接了
   1. 系统级：当前系统可使用的最大文件描述符数量
   2. 用户级：当前用户可使用的最大文件描述符数量
   3. 进程级：当前进程可使用的最大文件描述符数量
2. 内存限制：每一个连接都会占用一定内存，当内存占用满了，也无法接受连接

#### UDP和TCP的区别和应用场景

1. 连接：TCP面向连接，UDP不需要连接
2. 服务对象：TCP只能一对一，UDP可以一对多，多对多
3. 可靠性：TCP是可靠的，UDP本身不可靠，但是可以基于UDP实现一个可靠的传输协议，例如**QUIC协议**
4. 拥塞控制，流量控制：TCP有，UDP没有
5. 头部大小：TCP的头部开销较大并且头部可变，因为有一个选项字段可选，最小都需要20字节，UDP的头部开销较小并且头部不可变，固定为8字节
6. 传输方式：TCP是流式传输，没有边界，UDP是一个包一个包的发送，有边界
7. 分片方式：数据过大时，TCP在传输层进行分片和组装，UDP在IP层分片组装
8. 应用场景：TCP常用于FTP传输文件，HTTP，而UDP常用于视频音频通信，广播等

#### TCP和UDP可以使用同一个端口吗

> 端口的作用是为了区分一台主机中的不同应用程序

1. 主机收到数据之后，可以根据IP头的信息知道到底使用的是TCP还是UDP
2. 之后按照不同的协议使用不同的方式处理完信息之后，从指定的端口号中交给应用程序

#### TCP三次握手过程

1. 客户端随机初始化一个序号(1000)，然后将TCP头部中的SYN设置为1代表想要建立连接，之后将报文发送给服务端，此报文不带数据
2. 服务端收到客户端的报文后，随机初始化一个序号(2000)，然后确认客户端发来的报文(确认号字段为1000+1)，然后将SYN和ACK都设置为1，将报文发送给客户端，此报文不带数据
3. 客户端收到报文之后，确认服务端发来的报文(确认号字段为2000+1)，ACK设置为1，此时**可以携带数据**

#### TCP快速建立连接

1. 在第二次握手时产生了一个cookie，通信双方都知道这个cookie
2. 第一次通信还是正常的三次握手
3. 后续通信带上这个cookie就可以直接跨越三次握手，因为cookie中保存了一些信息

#### [为什么是三次握手，不是两次，四次](https://xiaolincoding.com/network/3_tcp/tcp_interview.html#%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B-%E4%B8%8D%E6%98%AF%E4%B8%A4%E6%AC%A1%E3%80%81%E5%9B%9B%E6%AC%A1)

> 三次握手是为了建立TCP连接，也就是初始化Socket，序列号和窗口大小，两次太少，四次太多

1. 三次握手才能**阻止重复历史连接的初始化**：

   - 当想要收到的确认号与真正收到的确认号**不一样**时就不会建立连接，
   - 这样即使客户端发送了两次SYN报文想要建立连接，
   - 只要收到的确认号不是确认**最新**的SYN报文就不会建立连接，也就是阻止历史重复连接

   > 如果是两次握手的话，服务端发送完确认报文之后就直接进入可以收发数据的阶段，如果这个确认报文不是客户端想要收到的就不建立连接，此时发送数据也是浪费资源

2. 同步双方的序列号：三次握手时存在一个序号的同步，双方都知道下一步对方应该发送什么序号的数据，从而使得数据可以按序处理，重复数据也可以丢弃
3. 避免资源浪费：如果服务端对客户端的ACK客户端没有收到，此时客户端就会不停地发送SYN请求连接，而服务端每收到一个SYN都会确认一次，并且建立一个链接（没有第三次握手服务端不知道客户端是否收到），这样就导致很多冗余连接被建立

#### 三次握手时第三次客户端的 ACK丢失了还能传输数据吗

> 可以

1. ACK的含义是对之前的报文的确认，客户端发送数据时的ACK一定会大于之前的ACK，也就是相当于隐含的将客户端的ACK再次发送了
1. 如果在发送数据之前服务端由于重传SYN+ACK导致连接断开，此时客户端发送的数据就收不到恢复，此时触发重传

#### TCP三次握手的初始化序号为什么每次都不一样

1. 防止**收到历史报文**：如果每次都一样，上一次连接中**没收到**的报文就可能在下一个连接中收到

   > 例如上次连接的报文还没收到，连接意外断开，而下一次连接使用相同的序号建立，那么上次没收到的报文就会被**误**认为是本次的报文，也就是收到了历史报文

2. 但是序号是**循环生成**的，此时如果刚好循环生成的序号是历史报文所处连接的序号，那么也会导致收到历史报文，只是**概率很小**，一次循环下来应该是4-5个小时

3. 为了方式序号循环产生矛盾，给报文分配一个时间戳，历史报文到达之后，如果时间戳**小于**当前有效的时间（不是**递增**的），就**丢弃**，时间戳也会循环生成

#### 初始化序号如何产生

> 初始化序号== M + F(localhost, localport, remotehost, remoteport)。
>
> 这样计算几乎不可能重复

1. M：计时器，每隔4微妙+1
2. F：哈希算法，以源IP和端口，目的IP和端口为输入生成一个哈希值

#### IP层会分片，为什么TCP还需要MSS

> 为了控制数据加上TCP和IP头部之后不会触发IP分片，因为IP层分片效率不高

1. MTU：网络包的最大长度，包含IP头,TCP头，数据三部分，一旦这部分超过长度IP层就会进行分片
2. MSS：在MTU基础上除去IP和TCP头部之后的数据部分的最大长度

一旦IP层分片丢失，整个TCP数据包都要重传，此时非常没有效率，所以要想确认MSS，也就是数据包的最大长度，使其加上TCP和IP头部不会超过MTU，此时IP层就不会进行分片

这样即使重新发送数据，大小也会更小，消耗和影响也会更小

#### 三次握手丢失会发生什么

> 核心就是**收不到自己包的确认就会重传**，重传次数受到参数控制（默认5），重传时间为前一次的2倍，例如1,2,4,8,16,32s。。。

1. 第一次握手丢失：客户端收不到第一次握手的SYN包的确认，所以触发SYN的重传
2. 第二次握手丢失：客户端收不到第一次握手的SYN包的确认，所以触发SYN的重传，服务端收不到第二次握手的SYN+ACK包的确认，所以触发SYN+ACK的重传
3. 第三次握手丢失：服务端收不到对于第二次握手SYN+ACK的确认，此时触发SYN+ACK的重传，重传次数超过限制**服务端直接断开连接**
   - 客户端不知道断开连接，继续发送数据，收不到相应就**重传数据**，超过重传此时才断开连接
   - **保活机制**确保连接建立的一段时间内如果没有发送数据，则主动发送探测报文监测连接是否正常，不正常就断开连接


#### 什么是SYN攻击

> 攻击者短时间内伪造出很多想要建立连接的SYN包发送给服务端
>
> 服务端收到SYN包之后就尝试给对应主机发送SYN+ACK包，占用大量资源

1. 一旦有客户端发送了SYN包给服务端，此时服务端就会将SYN包存储在队列中
2. 当服务端针对当前SYN包发送确认包并得到了客户端的确认后，就将SYN包从半连接队列中删除
3. 当短时间到来大量SYN包，并且虚拟客户端不确认服务端的SYN+ACK时，就会导致半连接队列被占满，正常的用户连接请求就无法建立，这属于DDos攻击的一种

#### 如何避免SYN攻击

1. 加大存储SYN包的队列长度，使其不容易被占满
2. 开启一个synCokkie功能：此时SYN半连接队列占满，其余的请求不放入SYN半连接队列，而是针对请求生成一个Cookie，直接尝试与客户端建立连接
3. 减少SYN+ACK的重传次数：当服务端发送了SYN+ACK没有响应时就会触发重传，重传次数过多会消耗大量资源，减少重传次数可以使得连接**快速断开**

#### TCP半连接(SYN)队列

> 收到客户端的SYN包之后，内核会将当前连接存储到半连接队列

1. 半连接队列溢出之后，没有开启synCookie，后面的请求会被丢弃
2. 开启了synCookie，半连接队列满了之后，其余的请求直接尝试建立连接，这需要分配一个cookie，双方利用cookie进行验证并建立连接
3. 半连接队列的最大值有参数指定

#### TCP全连接(accept)队列

> 三次握手成功的连接就会放入全连接队列

1. 队列中存储不下后，客户端第三次握手的ACK请求会被丢弃（默认），也就是队列溢出了，此时造成客户端认为连接无法建立
2. 队列装不下还可以设置为发送一个RST报文
3. 被丢弃的请求个数会被统计记录
4. 持续有被丢弃的请求时，就应该将全连接队列的长度调大，有参数可以调大队列

#### DDos攻击

> 分布式拒绝服务,导致合法用户不能访问网络服务的攻击

1. SYN攻击：不停地发送三次握手请求
2. HTTP攻击：不停地向HTTP服务器请求资源
3. 慢速攻击：与HTTP服务器建立很多长连接不释放，耗费HTTP服务器的请求处理能力
4. ICMP攻击：向服务器发送大量的ping命令

#### TCP四次挥手过程

> 三次握手只能客户端主动发起，四次挥手双方都可以主动发起

1. 客户端发起一个FIN包代表想要断开连接
2. 服务端针对FIN包进行确认，发送一个ACK包
3. 服务端处理完剩下的数据之后，向客户端发送FIN包代表可以断开连接，如果服务端此时没有数据要处理，那么就会将ACK+FIN合并起来发送，变成**三次挥手**
4. 客户端收到FIN包之后对其进行确认，发送ACK包，服务端收到之后进入close状态
5. 过一段时间之后（2MSL），客户端自动进入close状态

#### 为什么需要四次挥手

> 可能处理不完数据

1. 客户端发送FIN之后，表示客户端不在发送数据，但是此时还可以接收数据
2. 服务端接收到FIN之后，先回复一个ACK，之后可能还需要处理没处理完的数据
3. 服务端需要等待数据处理完之后才能真正断开，所以**两次挥手不够**

#### 四次挥手丢失会发生什么

1. 第一次挥手：客户端会重传FIN包，如果规定次数内还没有接收到ACK，只能直接断开连接，重传次数是受参数控制的
2. 第二次挥手：相当于ACK包丢失，此时第一次挥手的FIN包会重传，规定次数内还没有收到二次挥手的ACK，此时直接断开连接
   - close：如果收到了二次挥手的包，使用close关闭连接的方式，此时需要等待第三次挥手的包到达，并且**等待时间默认不能超过60秒**，超时自动关闭
   - shutdown：如果收到了二次挥手的包，使用shutdown关闭连接的方式，此时需要等待第三次挥手的包到达，并且**没有等待时间的限制**
3. 第三次挥手：相当于服务端发出的FIN包，此包丢失会导致收不到ACK包，也就会触发重传，重传次数受参数控制
4. 第四次挥手：相当于服务端没有收到最后一次ACK，此时就会一直重传FIN，直到达到次数就直接断开，客户端此时发送完最后一个ACK之后一段时间内（2MSL）就直接断开连接，这个时间有规定（2MSL）。在这期间如果收到了服务端重传的FIN，此时就会重新开始倒计时，这个时间称为time_wait

#### 为什么等待2MSL之后再断开连接（time_wait）

1. 报文最大生存时间为MSL，报文一个来回刚好2MSL，确保没被接收到的数据可以被接受到，**比如**发送了一个数据之后开始计时，对方收到数据之后处理又返回，正常情况下就可以在2MSL时间内返回，就可以正常收到数据
2. 2MSL代表至少允许报文丢失一次，增加网络的健壮性，比如此时第四次挥手的ACK丢失，对方重传的FIN会在第二个MSL中到达。此时还可以继续重传FIN包

#### 为什么需要time_wait状态

> 只有主动断开连接的一方发送完第四次挥手报文之后才能进入time_wait状态

1. 防止**收到历史数据**：由于四次挥手中的初始序号按照一定规则**循环生成**，所以可能前后两个链接使用的序号是一样的，此时上一个连接中的数据就有可能被下一个连接收到，此时加上time_wait状态**保证当前连接中的所有报文都自然消失**，不会被下一个连接收到

2. 保证被动关闭的一方能正确关闭：第四次挥手的ACK丢失 之后，触发了被动方的FIN重传，主动方接收到后，此时有time_wait状态等待，保证FIN会被正确确认从而正确断开

#### time_wait过多的危害

time_wait过多导致连接释放的过程变慢，占用资源的无效时间变长，**浪费资源**

1. 客户端time_wait过多：导致**同一个服务器**的请求不能过多，因为是按照（源ip和端口，目的ip和端口）来区分连接的，客户端的端口被占满了就无法建立新连接了
2. 服务端time_wait过多：没被释放的请求过多导致占用系统资源过多

#### 如何优化time_wait

1. 开启一个选项：开启之后time_wait超过1秒的连接直接可以被重新**复用**，系统认为此连接已经处理完上一次的业务
2. 系统中处于time_wait的连接数超过一个**阈值**，将后面的time_wait的连接直接断开

#### 服务端为什么出现大量time_wait

> 服务端**主动**断开了很多链接才有time_wait：

1. HTTP没有使用长连接，导致很多请求被直接断开，双方都设置keep-alive
2. HTTP长连接超时之后，服务端也会主动断开连接
3. HTTP长连接数量达到限制，服务端也会主动断开连接

#### 服务端为什么出现大量的close_wait

> 服务端**被动**断开了很多链接才有close_wait，被动断开连接之后，发送完第一个ACK到发送第一个FIN之间的状态叫做close_wait

在这个时间内应用程序没有调用close函数才会使得无法发出FIN报文，就会导致出现大量的close_wait

**也就是说原因在于应用程序没有调用close函数**，应该是代码逻辑出现了问题

#### 连接建立后，客户端故障怎么办

> 服务端会一直处于连接状态，感知不到客户端出现故障

1. TCP在指定时间内发送探测报文，如果好几个报文都没有响应，认为此连接已经死亡，系统报错，时间和发送报文次数都可配置
2. tomcat，nginx等可以检测在一段时间内都没有新请求的连接，将这些连接释放

#### 连接建立后，服务端故障怎么办

内核会介入，此时正常发送四次挥手断开连接，不需要服务端进程的参与

#### socket编程通信的过程

1. 服务端和客户端初始化自己的 socket，得到文件描述符
2. 服务端调用bind将socket绑定到指定ip和端口上，之后监听，最后调用accept等待客户端的连接
3. 客户端调用connect发起连接
4. 三次握手建立连接之后，返回一个用于传输数据的socket文件描述符，开始通信
5. 客户端调用write写数据，服务端调用read读数据
6. 断开连接时调用close函数，写入一个结束符EOF，对方读到之后就会调用close断开连接

#### 客户端调用close，断开的流程是什么

> 主要就是TCP的四次挥手

1. 客户端第一次挥手，发送FIN包
2. 服务端收到FIN包之后，会追加一个EOF，表示后续不会再收到数据
3. 读到EOF的时候，服务端也发送一个FIN包
4. 客户端针对收到的FIN包进行ACK
5. 服务端收到ACK之后就进入close状态
6. 客户端经历time_wait状态之后进入close状态

#### 没有accept，可以建立连接吗

> 可以

TCP的三次握手和accept之间互不影响，accept只是获取到一个已经建立连接的socket进行读写操作

#### 没有listen，可以建立连接吗

> 可以

#### TCP重传机制

> 当主机收不到自己发送消息的确认应答，此时就会将自己的消息进行重传：

1. 超时重传：
   - 做法：**超过一定时间**没有收到对方的确认应答报文，就开始重传，时间可以设置，数据包丢失或者确认应答丢失都会触发重传
   - 缺点：重传时间不好设置，可能导致超时
2. 快速重传：
   - 做法：为了解决超时重传可能等待时间较长的问题，一旦收到**三个重复的ACK**，说明这个ACK想确认的包没有收到，此时直接重传
   - 缺点：不知道后面的包哪些丢失，重传一个还是重传后面的所有，因为后面的包也有丢失的可能性，无法做到两全
3. SACK：
   - 做法：在TCP头部**增加一个字段**，保存所有已收到的数据，这样在重传时就只用重传所有丢失的数据，收到三次重复的ACK之后就开始重传
   - 缺点：发送的ACK丢失（超时重传）或者网络延时没收到数据包（三次ACK）时会触发重传，此时会重传重复数据
4. D-SACK：
   - 做法：收到重复数据发送一个D-SACK报文告诉对方数据重复，发送方可以根据D-SACK中的报文

#### 超时重传的超时时间设置

> RTT：从报文发出到应答报文到达中间的时间差

1. 超时时间应该略大于RTT，太大导致等待时间过差个，降低传输效率
2. 太小导致不必要的重传，应答报文还没来得及回来就触发重传
3. 实际上超时重传的值根据当时的网络状况会动态变化·

#### 滑动窗口

> 窗口实际上是内存中的一个**缓冲区**，发送的数据要被存储在缓冲区中，不用发送一条数据后必须等待应答才能发送下一条数据

1. 收到确认应答就将对应数据从缓冲区中删除
2. 应答丢失也可以通过后续应答来确认（累计确认或累计应发），因为ACK的含义就是对之前所有包的确认
3. 数据丢失就从缓冲区中拿到数据重传

#### 发送方滑动窗口的格式

> 一共有三个指针来指示滑动窗口的大小，整个滑动窗口内可以裁成两半，前面是已发送但未收到确认，后面是未发送但可发送

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/19.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="SND.WND、SND.UN、SND.NXT" style="zoom:33%;" />

1. 滑动窗口的总大小，取决于接收方和拥塞控制窗口的最小值
2. 已发送但未收到确认的数据的第一个字节处
3. 未发送但是可发送的数据的第一个字节处
4. 使用滑动窗口总大小+已发送但是未收到确认的第一个字节处的指针可以得到不能处理的数据的第一个字节的位置

#### 接收方滑动窗口的格式

> 用两个指针划分，与发送方的窗口大致相等，因为窗口大小在协商过程中有的网络延迟

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/20.jpg" alt="接收窗口" style="zoom:33%;" />

1. 接收窗口的大小，这个大小会传递给发送方，告知自己现在处理数据的速度
2. 希望发送方下一次发送的数据的序列号

#### 流量控制

> 根据接收方缓冲区（滑动窗口）的大小，动态**调整发送数据的速度**，这就是流量控制

1. 传输数据的通信过程中，会更新缓冲区的大小，也就是告知对方自己处理数据的能力变化
2. **丢包问题**：更新窗口的过程中如果**先减小了缓冲区大小，然后再减小窗口**，此时可能造成丢包，因为窗口更新存在延迟，发送方认为此时窗口大小没有变小，发送的数据过多造成丢包，解决办法就是**先缩小窗口，再减小缓存**
3. **窗口关闭**：窗口大小为0时，说明此时无法再继续接收数据，此时就不再发送数据，直到窗口大小不为0
4. 问题：窗口关闭时**恢复窗口的报文丢失**，别人不知道窗口恢复了，此时无法通信了，一旦窗口关闭就启动计时器，倒计时结束**主动探测**窗口是否恢复，探测次数一般为3次，计时器一般计时30-60秒
5. **糊涂窗口综合征**：接收方窗口有了几个字节的空闲之后，发送方就会发送几个字节的数据，加上几十字节的头部，**不太划算**，要么窗口太小就不通知发送方，要么发送方觉得窗口太小先不发送数据，这涉及到**延迟确认和Nagle算法**

#### Nagle算法

> Nagle的思想是延时处理，满足下面任意一个条件就可以发送数据
>
> MSS：网络设备可以接受的最大TCP数据包的大小

1. 窗口大小大于MSS并且数据大小大于MSS
2. 收到之前发送数据的ACK

#### 延迟确认

> 延迟确认是让**ACK也要携带数据**，充分利用ACK的头部
>
> 因为ACK只是为了确认，不携带数据，但是头部占用了一定的网络资源，所以浪费资源

1. 当有**响应数据**要发送时，将响应数据放到ACK数据部分发送
2. 当没有响应数据时，ACK会延迟等待
3. 在ACK延迟等待期间，对方发送的第二个数据报文又到了，此时就不管是否等到响应数据，直接发送ACK，避免对方误会第一个数据报文丢失（因为没收到ACK）

#### 拥塞控制

> **流量控制**是为了防止发送方将接收方的缓冲区填满
>
> **拥塞控制**是为了防止发送方的数据大量出现在网络中，造成网络拥堵，只要发生了超时重传，就认为出现了拥塞

1. 慢启动：TCP链接刚建立时，慢慢提高发送数据的数量，每收到一个ACK，就增加一个发送数据包的数量，**数量超过慢启动门限就启动拥塞避免算法**
2. 拥塞避免：每收到一个ACK，拥塞窗口的大小增加**1/大小**，现在窗口大小为8，收到了一个ACK，那么此时窗口大小增加`1/8`，窗口大小过大会出现丢包，此时**触发拥塞发生**
3. 拥塞发生：
   - 超时重传触发的拥塞发生：慢启动门限为当前窗口大小的一半，窗口大小重置为1，重新开始慢启动
   - 快速重传触发的拥塞发生：窗口设置为当前的一半，慢启动门限设置为当前更新后的窗口大小，**启动快速恢复算法**
4. 快速恢复：
   - 窗口更新为慢启动门限+3，3代表有确认有三个数据包被收到，这里增大窗口是为了快速将丢失的数据包重传
   - 重传丢失的数据包
   - 再有重复的ACK，窗口大小+1
   - 收到新数据的ACK就将窗口大小更新为慢启动门限的值，开始拥塞避免，这里减小窗口的大小是为了减小网络的拥塞，所以**先增大后减小**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F-%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="快速重传和快速恢复" style="zoom: 33%;" />

#### 优化TCP

> 主要是针对内核参数的调整，针对不同情况使用不同的参数

1. **三次握手**优化：
   - 根据网络状态控制第一次握手SYN包的重传次数，避免等待太久或者等待时间不够
   - 半连接队列满了之后，调大半连接队列长度
   - 或者开启synCookie，这样就可以减小syn攻击带来的影响
   - 绕过三次握手，第一次请求正常经过三次握手，并将连接信息保存到cookie中，后期再次发起连接请求之后，只要携带了这个cookie，就可以直接进行通信，第一次SYN包就可以携带数据
2. **四次挥手**优化：
   - 使用四次挥手断开连接，而不是使用RST强制断开连接，更加优雅
   - 调整FIN报文的重传次数
   - **复用**time_wait状态的连接，time_wait超过1s系统认为当前连接已经没有旧数据传送了，此时趁链接还在直接复用，避免三次握手
3. **数据传输**优化：
   - 不是发送一个包等一个ACK，而是利用**滑动窗口**提高吞吐率，批量发送请求
   - 尝试**扩大窗口**大小，也就是缓冲区大小，这样吞吐率就会进一步提高
   - 打开缓冲区自动调整的开关，这样根据网络状态就会动态调整缓冲区大小，网络好传输的数据多，缓冲区就变大

#### TCP面向字节流

1. 因为消息可能会被分成多个TCP报文，以字节流进行发送，不像UDP一个报文就是一个完整的消息
2. TCP报文中的数据可能由于分片并不完整
3. 可能出现**粘包**的问题，不知道消息的边界无法读取有效的消息

#### TCP粘包的解决办法

1. 指定**数据边界**，有了边界就可以读取数据
2. **关闭Nagle**算法，防止数据累计造成粘包，因为Nagle算法就是为了不发送较小的数据而提出的，这可能造成粘包

#### SYN包什么时候会被丢弃

1. 遭遇SYN攻击导致半连接队列满了：预防SYN攻击
2. 全连接队列满了，无法接受后面的请求，SYN包**默认**会被丢弃

#### 三次握手后客户端宕机

> 客户端宕机之后，重启之后会重新建立连接

1. 建立连接的ip和端口号**不变**：
   - 客户端发送SYN包
   - 服务端发送一个ACK包，其中的序号是**上一次连接**中的**想要**的序号，因为客户端的ip和端口已经建立连接，但是还发送SYN包
   - 客户端发现不是自己想要的ACK，所以发送RST报文断开连接
2. 建立连接的ip和端口号**变化**：
   - 三次握手建立新的连接
   - 旧连接有**两种**情况：
     - 服务端发送了数据，客户端回复RST报文，此时连接释放
     - 服务端没有发送数据，一段时间没有数据交换触发**保活机制**，最终释放连接

#### 如何关闭一条TCP连接

> 伪造RST报文（源ip和端口，目的ip和端口，**序列号**）
>
> 序列号很重要，不正确的序列号不会被接受

1. **主动**关闭killcx工具：
   - 主动**模拟一个SYN包**发送给服务端，由于是对已连接的服务端发送SYN，此时服务端会回复一个包，序列号是客户端想要的，确认号是自己想要的
   - killcx伪造两个RST包，根据上面的两个序列号就可以断开双方的链接
2. **被动**关闭tcpkill工具：
   - 连接**双方必须通信**，才能知道他们的序号和确认号
   - 根据序列号和确认号伪造两个RST报文用于关闭连接
   - 无法关闭不活跃不通信的连接
