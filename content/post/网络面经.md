---
title: "网络面经"
description: "网络面经"
keywords: "网络面经"

date: 2024-03-11T08:52:11+08:00
lastmod: 2024-03-11T08:52:11+08:00

categories:
  - 面试
tags:
  - 面经
  - 网络

# 原文作者
# Post's origin author name
author: zzzi
# 开启数学公式渲染，可选值： mathjax, katex
# Support Math Formulas render, options: mathjax, katex
math: mathjax
# 原文链接
# Post's origin link URL
#link:
# 图片链接，用在open graph和twitter卡片上
# Image source link that will use in open graph and twitter card
#imgs:
# 在首页展开内容
# Expand content on the home page
#expand: true
# 外部链接地址，访问时直接跳转
# It's means that will redirecting to external links
#extlink:
# 在当前页面关闭评论功能
# Disabled comment plugins in this post
#comment:
#  enable: false
# 关闭文章目录功能
# Disable table of content
toc: false
# 绝对访问路径
# Absolute link for visit
#url: "网络面经.html"
# 开启文章置顶，数字越小越靠前
# Sticky post set-top in home page and the smaller nubmer will more forward.
#weight: 1

# 开启各种图渲染，如流程图、时序图、类图等
# Enable chart render, such as: flow, sequence, classes etc
#mermaid: true
---

> 🕸 网络面经

本文中介绍了一些计算机网络中常见的面试题，也可以当做平时的学习笔记来使用，知识点参考小林coding的[图解系列](https://xiaolincoding.com/)，文章长期更新

<!--more-->

#### TCP/IP的层数

> 这是对OSI七层网络协议的简化，现在变成了四层，常用的也是四层

1. 应用层：应用软件在这一层实现，不同应用需要通信时，就把数据交给下一层传输层

2. 传输层：有两个协议TCP,UDP，加上端口号等信息，端口号负责区分消息到达另一台设备时，交给哪个端口对应的应用，可能进行**分段**，之后交给下一层

3. 网络层：将从上层接收到的报文加上IP等信息，ip负责表示将消息交给哪一台主机，可能进行**分片**，交给下一层，ip地址分为网络号（找子网）和主机号（找子网中的主机）

4. 网络接口层：在数据的ip头部加上MAC头部，封装成数据**帧**，这样就可以通过mac地址区分网络上的设备

   <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/%E5%B0%81%E8%A3%85.png" alt="img" style="zoom:35%;" />

#### 输入网址到页面显示的过程

1. 解析url：确定要访问哪个服务器和服务器中哪个文件

2. 根据上述信息生成http请求（请求行，请求头。。）

3. 根据要访问的服务器名在DNS服务器中查询其ip地址，这里涉及到**域名解析**

4. 找到通信的目标ip之后，浏览器通过调用socket库来委托协议栈进行通信

5. <u>由于http基于tcp进行通信</u>，此时需要三次握手建立连接

6. 建立连接也需要按照这个流程传输数据，是为了确保双方确实可以收发数据

7. 建立连接之后将数据进行封装，加上TCP头部（**<u>端口和确认号</u>**），进一步交给ip层

8. ip层将数据封装成网络包，加上IP头部（源IP和目标IP），可能进行分片

9. 之后对数据包加上MAC头部，主要加上MAC地址信息，包括发送方和接收方，此时需要用到**ARP**协议，填入MAC地址就知道数据**先发送**给哪个设备（从交换机哪个端口出去）

10. mac地址是用于两点传输的，在传输的过程中需要不断变化，不断获取

11. 当客户端和服务器不在同一个子网中时，得到的MAC地址就是发送端所在子网的路由器MAC地址，在同一个子网时，此时MAC地址就是接收方的MAC地址，反正是**直连设备**的mac地址

12. 数据封装好之后，经由发送方的网卡发送出去

13. 发送方网卡发送的消息**<u>先到达交换机</u>**，判断该消息从交换机哪个端口转发出去，这根据交换机中缓存的mac地址与端口的映射表

14. 找不到端口的映射，就发送给所有的端口（除了来时的端口）

15. 从端口出来到达路由器，路由器判断这个包自己需不需要转发（MAC地址是否一样）

16. 需要转发就去掉数据的MAC头信息，根据内部的IP头信息进行转发

17. 最终消息在网络上传输，这里根据ip地址进行转发，看接收方ip在哪个网段就转发给路由器的哪个端口，也就是下一跳是谁

18. 都没有匹配的就转发给默认端口

19. 到达最后一跳时加上MAC地址，因为此时路由器的下一跳应该是消息的接收方了

    > 也就是在数据链路层的通信才会需要MAC地址

20. 接收方判断MAC地址是否与自己一样

21. 判断IP地址是不是符合的

22. 判断TCP中的序列号是不是我想要的（我上次ACK什么，就说明这次想要什么）

23. 以上判断都通过，此时根据TCP中记录的端口号进行转发，最终到达HTTP的服务器

24. HTTP的服务器发现对方想要请求网页，于是将网页封装到http响应报文中

25. 经过TCP，IP，MAC的封装，从网卡出去，到达交换机，路由器，最终一步一步到达请求网页的客户端，相当于是逆过程

26. 客户端还是一层一层的进行判断MAC，IP，TCP序列号，然后按照端口转发

27. 浏览器收到HTTP服务器发送过来的页面之后，就可以显示了

28. 最终会发起四次挥手断开连接

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/2.jpg" alt="简单的网络模型" style="zoom: 33%;" />

> 类似于要发送八条消息，三次握手，一条真实消息，四次挥手

#### DNS解析过程

> 为了获取目标主机的ip地址，也就是域名解析

1. 本地发送一个DNS请求到本地记录的DNS服务器
2. DNS服务器查找缓存，有目标就直接返回
3. 找不到就给客户端一个新的上层DNS服务器地址，客户端继续询问
4. 找到就返回，找不到继续给一个新的DNS服务器地址，这是由要通信的域名决定的
5. 最终得到通信目标的ip地址

#### ARP协议过程

> 为了获取**下一跳**的设备MAC地址

1. 先查询ARP缓存，缓存中由ip和mac的对应信息直接获取
2. 没有就以广播的形式询问xxx这个ip地址是谁的
3. 每个人判断一下，是自己的话就回答自己的mac地址是多少
4. 如果没有人的ip与之匹配，此时返回的时路由器的MAC地址
5. 这就可以实现要么下一跳是路由器，要么下一条街就是最终目的地

#### RARP协议过程

> 是ARP协议的**逆**过程

根据mac地址求出ip地址

#### TCP/IP 网络模型与 OSI 网络模型（四层与七层）

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/OSI%E4%B8%8ETCP.png" alt="img" style="zoom:33%;" />

#### linux接收网络包流程

1. 网卡收到别人传递来的消息

2. 通过DMA技术（硬件机制）将网络包写入到内存地址中

   > DMA技术允许外围组件直接将数据传递给内存或者从内存中读取数据，可以减小无用操作，提高吞吐量

3. 使用NAPI机制（中断+轮询）唤醒数据处理程序，之后来轮询网络包中的内容即可

4. 轮询使用的是poll，也就是有一个链表存放所有有读写请求的socket，某一个被中断唤醒，状态就会发生变化，poll是轮询这个链表知道哪个套接字发生变化

5. 读取到数据首先会到达网络接口层，去掉帧头帧尾交给网络层

6. 网络层根据ip判断数据的走向，转发还是继续处理

7. 继续处理的话就将IP头去掉，交给传输层

8. 根据传输层的TCP头或者UDP头来决定将数据放到哪个Socket的缓冲区

9. 应用程度调用socket接口读取数据给自己

>**socket**：工作在应用层和传输层之间，采用Unix**一切皆文件**的思想，数据看成文件进行读写操作

#### linux发送网络包流程

1. 应用程序调用Socket接口将数据放到socket缓冲区
2. TCP协议拷贝缓冲区副本进行发送，防止需要重传
3. 对缓冲区数据加上TCP头，**这里使用TCP协议举例**
4. 网络层收到数据之后会选取路由，填充IP头，可能进行数据分片
5. 通过ARP协议获取**下一跳**的MAC地址，可能是目标主机，也可能是路由器
6. 网卡驱动检测到数据之后，会将其保存到缓冲器区中
7. 之后使用DMA机制将缓冲区中的数据读取到内存中准备发送到网络中
8. 发送完成接收到消息的ACK说明不在重传，此时清理缓冲区

#### MTU、MSS、MSL、RTT、TTL

1. MTU：最大传输单元，链路层中的数据最大字节数，1500
2. MSS：最大报文大小，TCP中数据的最大字节数，一般为1460
3. MSL：报文最大生存时间，一般为2分钟
4. RTT：报文一次往返时间
5. TTL：IP数据包在网络中的存活时间，走一跳（一个路由器）减小一次

#### HTTP协议概念

超文本传输协议：定义了计算机之间**<u>通信的规范</u>**，主要是针对**两点**之间传输数据的，传输的内容是**超文本**（文字，图片，视频，超链接）

#### HTTP常见状态码

> 1表示中间状态，2表示成功，3表示重定向，4表示客户端错误，5表示服务端错误

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png" alt=" 五大类 HTTP 状态码 " style="zoom:33%;" />

1. 200：表示成功
2. 204：成功，但是响应头没有数据
3. 302：临时重定向，需要使用新的链接访问
4. 403：服务端禁止访问的资源
5. 404：访问到不存在的资源
6. 500：服务端发生了错误
7. 503：网络正忙，处理不过来了

#### HTTP常见字段

> 主要有以下几种，其余的记不住了

1. Host：客户端发送请求时指定服务端的域名，也就是目的地是谁
2. Content-Length：标识服务端返回的数据长度，这是为了解决TCP传输时的**粘包问题**，防止不同的消息被划分到了同一个TCP报文中
3. Connection：是否保持长连接（keep-alive），以便客户端的其他请求复用这个连接
4. Content-Type：本次响应的数据的格式
5. Accept：客户端用这个字段声明自己可以接受哪些字段
6. Content-Encoding：服务端说明此次数据的压缩格式
7. Accept-Coding：客户端声明自己可以接受哪些压缩方法

#### GET和POST的区别

> 本质上都是TCP链接，但是由于HTTP的规定和浏览器的限制导致有一些细微的差异

1. GET：
   - 指的是从服务端**<u>获取</u>**指定的资源
   - **参数一般写到请求URL中**，所以更不安全，但是这只是规范，并不强制要求，GET也可以向POST一样将参数放到body中
   - 浏览器将请求数据一次性发出去
   - 幂等，因为get一般只用来查数据，不涉及到数据的修改
2. POST：
   - 根据请求报文的body对指定资源做出处理
   - **参数放到body中**，只是一个规定，可以不遵守
   - 浏览器将请求数据分为header和data两次发送，Firefox好像就发送一次
   - 不幂等，因为post涉及到数据的修改

#### GET 和 POST 都是安全和幂等的吗？

1. 安全：请求不会破坏服务器上的资源
2. 幂等：多次执行相同的操作，结果是相同的

**GET**方法<u>**是**</u>安全且幂等的，因为他只是请求资源，相当于只读，所以GET请求的数据可以进行缓存，因为每次请求的数据都是相同的

**POST**方法<u>**不是**</u>安全和幂等的，因为他会修改服务器的资源

#### HTTP缓存实现方式

<img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240311100505643.png" alt="image-20240311100505643" style="zoom:33%;" />

> 针对幂等（每次请求结果都一样）的请求，我们可以将请求的数据缓存到本地
>
> 强制缓存是只判断数据的过期时间，协商缓存是**每次**都问问服务器缓存还能用吗

1. 强制缓存：只要浏览器说缓存没过期，那么**就必须直接使用缓存**的数据

   - 第一次请求服务器时，服务器会给当前数据定一个过期时间

   - 后期只要没过期，一定会先去缓存中拿


   > 浏览器第一次请求这个数据的时候，服务器给其加上一个过期时间，每次请求时判断当前缓存数据过期没，没过期就直接使用缓存数据

2. 协商缓存：向服务端发送请求，服务端根据请求携带的一些参数**判断**是否可以使用缓存（只是告诉客户端可以使用缓存，不是强制的）

   - 基于时间实现：当服务端的数据最后修改时间大于本地缓存的最后修改时间，说明本地缓存失效，直接返回新资源返回200，本地缓存没失效直接返回304访问缓存

   - 基于唯一标识实现：资源一旦变化，唯一标识就会变化，服务端根据客户端传递过来的唯一标识判断缓存是否失效，没失效就可以使用

     > 核心就是判断本地缓存和服务端的数据是否一致

**只有没命中强制缓存时才进行协商缓存**

前两个部分是强制缓存，后两个部分是协商缓存

```java
 Cache-Control  > expires > Etag > Last-Modified
```

#### HTTP1.1的优缺点

1. 简单，灵活，易于扩充：各种请求方法，状态码，头部字段都可以扩充
2. 应用广泛，跨平台：随处可见HTTP的应用，浏览器，APP，新闻，游戏，天然跨平台
3. 无状态：没有额外的信息记录请求的状态信息，减轻了服务器的压力，但是对于登录>加入购物车>下单>结算>支付这种业务来说，每次都需要验证身份，简单解决方法就是**cookie**（标识符）
4. 明文传输：抓包时极其方便，但是信息直接暴露，不安全
5. 不安全：通信使用明文，信息容易泄露，不验证通信方身份，容易登录到假网站，报文无法确保完整或是否被篡改

#### HTTP/1.1的性能

1. 长连接：不用每次请求都建立连接，减小开销，只有主动断开或者超时才会断开连接
2. 管道网络传输（有但是没用过）：在一个TCP连接中可以发出多个请求，按照请求的顺序响应，一旦前面的阻塞，后面的也会持续等待

#### HTTP与HTTPS的区别

> 建立连接时多了TLS握手（生成对话秘钥）的过程，传输数据多了加密的过程

1. HTTP明文传输，HTTPS加入了SSL/TLS协议，使得报文加密传输
2. HTTP进行TCP三次握手之后就可以传输，HTTPS三次握手之后还需要进行SSL/TLS的握手过程才能传输
3. 默认端口不一样，HTTP默认80，HTTPS默认443
4. HTTPS需要申请数字证书，保证身份可信

#### SSL/TLS协议是什么

> 是一个密码通信框架，集成了很多密码学中的内容

1. 客户端向服务端索要公钥

2. 为了防止公钥不被篡改，需要将服务端的公钥放到数字证书(CA)中，也就是CA使用自己的私钥对服务端的公钥，用途，信息，有效期等信息哈希之后加密

3. 客户端收到这个消息之后，利用CA的公钥解密得到服务端的公钥

4. 利用CA保证公钥不被篡改，交换得到公钥之后，就可以使用公私钥先进行非对称加密的通信

5. 双方协商生成一个"对话秘钥"，公私钥加密这个对话秘钥（非对称加密）

   > 上面几步是TLS握手阶段

6. 使用对话秘钥加密通信的报文（对话秘钥使用对称加密，速度很快）

#### HTTPS中的TLS使用RSA的握手过程

> 主要是有一个CA加密服务端的公钥防止伪造，然后客户端拿到合法的公钥之后，去协商一个会话秘钥，后期使用会话秘钥通信，这个会话秘钥只有双方知道

1. TCP三次握手之后开始传递请求
2. 第**一**次TLS握手：客户端发起加密通信请求，请求内主要包含一个随机数（用于生成对话秘钥）和支持的加密算法
3. 第**二**次TLS握手：服务端针对加密通信请求作出响应，主要包含一个随机数（用于生成对话秘钥），选用的加密算法(RSA等)以及一个数字证书
4. 数字证书主要是CA利用自己的私钥对服务端的公钥进行加密
5. 客户端**确认**（用CA的公钥解密）数字证书的真实性之后，从中取出服务器的公钥
6. 第**三**次TLS握手：向服务端再次通信，此次使用公钥加密数据，主要包含一个随机数
7. 双方都根据上面的**三个**随机数计算出一个对话秘钥
8. 之后客户端将之前通信的数据做一个摘要并加密发送，来验证加密通信是否可用以及之前的通信过程中是否有数据被篡改
9. 第**四**次TLS握手：服务端也将之前通信的数据做摘要并加密发送，来验证加密通信的可用性以及之前通信过程中是否有数据被篡改
10. 后期就使用对话秘钥进行对称加密来通信

#### HTTPS中的TLS使用ECDHE握手过程

> ECDHE是一种基于椭圆曲线的密钥交换算法，通信过程中的会话秘钥是计算出来的，不是传递得到的，所以不会被中间人窃取，具有前向安全性

1. TCP三次之后开始传递请求

2. 第一次TLS握手：客户端发起加密通信请求，主要包含一个随机数和支持的加密算法

3. 第二次TLS握手：服务端针对请求进行响应，主要包含一个随机数和使用的加密算法还有数字证书

4. 服务端选择一个椭圆曲线G，然后生成一个随机数a作为服务端椭圆曲线的私钥保存到本地

5. 根据私钥计算出服务端的椭圆曲线公钥（A=aG），然后对公钥进行签名防止第三方篡改，之后发给客户端

   > 这里计算是根据椭圆的点运算，私钥计算出公钥之后，在想利用公钥计算出私钥就很困难，所以具有前向安全性
   >
   > 相当于即使中间人拦截到了公钥也无法破解私钥，也就是知道A，G想反向计算a很困难

6. 第三次TLS握手：客户端验证服务端证书的合法性，之后生成一个随机数b作为客户端椭圆曲线的私钥

7. 然后根据私钥计算出客户端的椭圆曲线公钥（B=bG），将公钥发给服务端

8. 之后双方利用自己的私钥和对方的公钥计算出一个共享密钥，这个是**相同**的

   > 客户端：自己的私钥*服务端公钥=bxA=bx（aG）=abG
   >
   > 服务端：自己的私钥*客户端公钥=axB=ax（bG）=abG
   >
   > 所以计算出的共享密钥是相同的

9. 共享密钥+之前传递的两个随机数计算出会话秘钥，这个自然也是相同的

   > 上面涉及到[协商密钥的过程](https://wenfh2020.com/2023/10/08/https/)

10. 客户端将之前发送的消息做一个摘要并加密发送，用来验证加密通信是否可用以及之前的通信过程中是否有数据被篡改

11. 第四次TLS握手：服务端执行同样的操作来验证

12. 之后使用会话秘钥来加密通信

#### 对称加密和非对称加密

1. 对称加密：加密数据双方只使用**一个**秘钥，运算速度更快
2. 非对称加密：通信双方使用公私钥**两个**秘钥进行加密，https中非对称加密主要是为了得到会话秘钥

#### 服务端得到数字证书的过程

1. 服务器将自己的公钥注册到CA(数字证书认证机构)

2. CA使用自己的私钥对公钥进行数字签名，主要是将公钥，用途，颁发者，有效时间等信息封装在一起计算哈希

3. CA使用自己的私钥对这个哈希值加密，将其添加到文件证书上(主要包括加密的内容，公钥，用途等信息)，形成数字证书

4. 相当于数字证书由两部分，第一部分是服务端的公钥，用途，有效期等信息，第二部分是CA利用私钥加密之后的签名

5. 服务端收到自己的数字证书

   <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E8%AF%81%E4%B9%A6%E7%9A%84%E6%A0%A1%E9%AA%8C.png" alt="img" style="zoom:33%;" />

#### 客户端检验数字证书的过程

1. 客户端拿到证书之后，将其中的服务端公钥，用途，有效期等信息进行哈希得到一个新的哈希值
2. 然后利用CA的公钥解密对应的签名，得到另外一个哈希值
3. 对比这两个哈希值就可以判断出当前公钥是否被篡改，安不安全
4. 如果哈希值不一样，可能是由于签名的CA不一样，所以此时还会进行信任链的验证操作
5. 验证也不通过，那说明当前的公钥确实不可靠

#### 信任链验证操作

1. 客户端收到一个证书C，验证发现哈希值不相同，此时进行**信任链验证**操作
2. 客户端发现证书C由机构B颁发，而机构B的证书由机构A颁发
3. 机构A是根机构，是**自签**证书，**客户端信任此证书**，也就是一级一级向上找
4. 此时客户端使用机构A的证书去验证机构B的证书是否可信
5. 可信的话再使用机构B的证书去验证C是否可信
6. 如果还是可信的话，此时客户端就信任证书C

> 可以看出是一个**链传递**的关系，客户端信任A，而A信任B，B信任C，最终客户端也信任C，操作系统中一般会内置一些根证书，相当于一个树形结构，不断开枝散叶

#### HTTPS如何保证数据完整性

> 使用TLS**记录协议**保证数据的完整性和来源

1. 保证数据本身的完整：
   1. 数据会被分成很多片段，然后会被压缩
   2. 每个压缩的片段会被加上消息认证码，保证数据本身完整
2. 保证数据不被篡改：
   1. 使用双方协商好的会话秘钥加密数据
   2. 接收到数据之后会进行验证，进一步保证完整性

#### HTTPS优化

1. 加快计算密钥的过程：换好CPU
2. 密钥交换算法：将RSA改成ECDHE可以加快TLS的握手过程，并且安全性更高
3. 减小证书大小，这样传递证书时的开销就会更小
4. 服务端定期向CA查询自己的证书状态是否过期，获得一个带时间戳的签名缓存住，客户端请求得到证书之后，只需要根据这个时间戳签名就可以直接判断证书是否过期，不用向CA查询
5. 会话复用：第一次建立连接后**缓存会话秘钥**，后期直接复用密钥即可减少TLS握手时间：
   1. 使用唯一的SessionID标识这个会话秘钥，后期该客户端再次连接时会携带一个SessionID，该SessionID的会话秘钥还在则直接返回会话秘钥，不需要TLS握手
   2. Session Ticket：第一次建立连接之后，服务端将会话秘钥加密形成Ticket交给客户端，下次连接时传递这个Ticket，服务端解密并验证这个会话秘钥的有效期，有效的话才开始通信
   3. Pre-shared key（TLS1.3）：将Ticket和请求**一起发**给服务端，如果解析出来的会话秘钥没过期，此时可以直接响应请求，时间更快

#### TCP的Fast Open

> 尝试越过三次握手，使用旧连接来直接通信，更快

1. 首次建立连接还是正常三次握手，在三次握手的过程中生成一个`cookie`，保存连接的信息
2. 后续通信时验证这个cookie是否正确即可
3. 此时第一次的SYN包就可以**携带数据**。
4. cookie正确就可以提前进行通信，处理SYN包中携带的数据
5. 不正确就正常通过三次握手建立连接

#### 重放攻击

> 要给会话秘钥设置过期时间，防止别人得到了SessionID或者Session Ticket解析出会话秘钥进行重放攻击

中间人恶意截取了客户端通信时的SessionID或者SessionID Ticket和POST报文，之后就可以冒充客户端发送POST请求，而POST可以修改数据库，最终数据被修改，客户端并不知情

#### HTTPS一定可靠吗

> HTTPS**本身是可靠**的，如果你信任了不安全的证书或者电脑被入侵导入了不想信任的证书，此时才会出现不可靠的情况，例如：

1. 客户端向服务器发起请求时，被假基站拦截到了，经过假基站再将请求转发到服务端

2. 此时客户端和服务端之间就会多出一个假基站，假基站通过伪造的证书与客户端进行通信

3. 浏览器是能识别到证书不安全的，但是如果你接受了这个不安全的证书，此时假基站就能获取到客户端请求的明文数据，也能知道服务端响应的明文数据

4. 也就是浏览器提醒当前访问的网站不是安全的，问你是不是仍要访问

5. 此时变得不可靠

   > 这种不可靠是因为用户手动信任了不安全的假基站证书导致的，或者电脑被恶意导入了假基站的证书导致的

#### 抓包工具的工作原理

> 承担一个假基站的效果，主要是要让客户端信任抓包工具自己的证书

1. 抓包工具让客户端信任自己的证书，在客户端受信任的证书列表中导入自己的证书
2. 之后客户端正常和抓包工具建立连接
3. 抓包工具得到客户端传递的数据之后，进行解密，实现抓包
4. 之后将解密后的包用自己的秘钥进行加密传递给服务端
5. 由于服务端不校验客户端的身份，所以可以正常通信
6. 服务端将响应数据交给抓包工具，抓包工具解压之后，用与客户端通信的秘钥加密并返回给客户端
7. 客户端与服务端之间都不知道中间存在一个中间人，以为是直接进行通信

#### 如何避免被抓包或者出现假基站

1. 不要信任任何不安全的证书
2. 使用电脑应规范，防止被恶意注入不安全的证书
3. HTTPS**双向认证**，服务端要验证客户端通信的身份，服务端认为不安全的证书就拒绝通信，不像客户端提示不安全的证书可以选择信任

#### HTTP/1.1相比HTTP/1.0的改进

1. 使用长连接减小开销
2. 支持管道，一个请求发送之后，不必等待响应就可以发送下一个请求

#### 如何优化HTTP/1.1

1. 减少重复HTTP请求的发送，将不变的数据缓存（强制缓存+协商缓存）到本地

   > 强制缓存过期（过期不一定更新）之后，会尝试使用协商缓存(时间或者标识符)来确认缓存中的数据是否可以继续使用

2. 合并请求：多个请求共享请求头，减小通信时的开销

   - 将多张图片利用合并的技术合并成一个大图片，这样一次请求就可以获得多个图片
   - 使用webpack技术将js，css等资源打包，请求时一个请求就可以获得这些资源
   - 图片使用二进制编码嵌入HTML文件中，一次请求就可以获得图片和HTML文件

3. 延迟发送请求：请求按需发送，不需要的请求暂时不发送，只有需要的时候才发送请求

4. 减小响应数据的大小：将响应数据进行压缩

#### HTTP/2相比HTTP/1.1的改进

> 主要是引入一个Stream

1. 基于HTTPS，通信更加安全
2. 通信时**头部**数据也可以压缩(HPACK算法)，减小传输开销
3. 通信报文采用**二进制**的格式，对计算机更加友好，减小转换开销，并且消耗空间更小
4. 可以**并发传输**，引入了Stream的概念，不同的请求有不同的StreamID，Stream间可以乱序发送，Stream内需要按序发送，此时就可以做到有序组装消息
5. Stream可以设置优先级，从而优先响应某些请求，提高用户体验
6. 服务器**主动推送**，HTTP/2可以支持服务器主动向客户端推送消息，客户端的StreamID必须是**奇数**，服务端的StreamID必须是**偶数**

#### HPACK算法

> 压缩的核心思想就是用小代替大，然后大小之间建立映射关系

1. **静态字典**：高频出现在头部的内容建立静态字典，之后就用这些内容对应的编码代替，从而减小头部大小，静态表字典包含62中字符串的映射

2. **动态字典**：一次连接中动态变化的字符串建立动态字典，然后还是用**编码**代替变化的内容，一次连接中的请求过多就会导致动态字典变得很大，从而影响服务器性能

   > 当一次连接中的请求过多时就会断开连接，从而**释放**动态表占用的内存

3. 哈夫曼编码：剩下没有被索引的内容还可以使用哈弗曼编码来进一步压缩

> 就这样利用字典+哈弗曼编码来**压缩头部**

#### HTTP如何实现服务端主动推送

1. 定时轮询：每个几秒就在后台发送一个请求给服务端，前台看起来就是服务端主动推送，因为用户自己没有主动发出请求
2. 长轮询：在一段时间内只要收到了某个事件服务器就自动推送，例如前端一扫码成功服务器就自动推送登陆成功后的页面，RabbitMQ就是这种机制，队列中一旦有消息，消费者就开始处理
3. 将HTTP改成WebSocket：由于HTTP是半双工的，导致服务端不能主动推送，而WebSocket是全双工的，可以直接推送消息，并且WebSocket是利用HTTP来进行升级的

#### HTTP/3相比HTTP/2.0的改进

> 底层的TCP改成UDP，所以主要是**UDP的优点**

1. HTTP2在TCP层面会有**对头阻塞**问题，也就是前面的包没收到，必须等这个包重传好之后后面的包才能处理，HTTP3将TCP协议改成UDP协议，丢包不重传
2. 发生丢包时，只有当前的Stream阻塞，其余的Stream不影响，阻塞的影响变小，丢弃的包也需要重传
3. **没有TCP的三次握手**，连接建立更快
4. **连接迁移**：当通信双方IP变化时，不会重新建立连接，只要上次建立连接分配的连接ID还在就可以直接通信，因为HTTP/3不是基于IP端口的，而是**基于连接ID**的】
5. 头部压缩升级：升级成QPACK，静态表从61项变成91项

#### 有了HTTP为什么还要有RPC

> 发展阶段有关，并且rpc主要适用于C/S架构

1. **早期**HTTP适用于B/S，而RPC适用于C/S，二者适用范围不同，现在没有区分这么大
2. 二者**连接方式**不一样：HTTP一般向**DNS服务器**获取目标服务器的ip进行通信，而RPC一般有一个**中间服务**存储所有服务的ip信息，通过中间服务获取目标服务器的IP
3. RPC会建立一个**连接池**，可以做到连接复用，用完的连接放回连接池下次还能接着用
4. HTTP请求中**冗余的头信息比较多**，RPC更加关注于要发送的数据本身，所以微服务项目内部一般使用RPC远程调用
5. RPC比HTTP出现的早，很多老项目还是使用的RPC，并且RPC比HTTP/1.1性能要好，没有过多的冗余头信息，结构化的数据传输起来也更方便

#### 有了HTTP为什么还要有WebSocket

> 主要是适用于服务端主动推动的场景，使用场景不一样

HTTP设计之初是为了浏览网页，只有客户端主动请求，后期需求变多，**需要服务端主动推送**，此时才出现了WebSocket，比如网页主动弹窗广告，网页游戏主动更新环境变化，所以**应用场景不一样**

1. 浏览网页时使用HTTP协议，网页游戏就是用WebSocket协议，这取决于应用场景是半双工还是全双工，全双工就是服务端会主动推送数据
2. WebSocket协议**建立连接时需要使用到HTTP**，这是因为所有浏览器都支持HTTP协议，所以先使用HTTP尝试建立WebSocket连接进行**升级**，升级成功就可以进行全双工通信

#### 如何实现扫码登录

1. 客户端主动查询：每隔1~2秒，客户端主动去服务端查询看是否扫了码，扫码登录之后，客户端知道了，此时就自动跳转
2. 长轮询：

#### TCP的头格式

<img src="https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230534096.png" alt="TCP 头格式" style="zoom:23%;" />

1. 序列号：给传递的包标记一个序号防止乱序
2. 确认号：对之前数据的确认，对下一数据的期望
3. 控制位：控制哪些字段有效，例如ACK有效证明确认应答的字段有效，FIN有效代表希望断开连接
4. 数据：真实发送的数据

#### 为什么需要TCP

> TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。

因为上层的应用层只关注将数据交给下层，而下层的IP层不可靠，他不保证网络包的按序交付和完整性，这些只能依靠TCP来保证

####  什么是TCP

> TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。

1. 面向连接：一对一连接之后才能发送消息
2. 可靠：不论网络链路怎么变化，TCP一定保证报文能够到达，使用重传，滑动窗口，流量控制，拥塞控制等手段保证TCP的可靠性
3. 字节流：前一个报文没有收到，后面的报文即使收到了也无法处理，并且重复的报文会被丢弃
4. 粘包问题：如果不知道消息的边界就无法读取有效的消息，例如夏洛，特烦恼，接收端可能读取为夏洛特，烦恼

#### 什么是TCP连接

> 用于保证可靠性和流量控制的状态信息，包括Socket，序列号，窗口大小这些信息组合起来成为连接

1. Socket：ip和端口
2. 序列号：用来防止网络包乱序
3. 窗口大小：用来流量控制，一旦当前数据没有被应用层处理，就将数据放到接收缓冲区，然后通过这个**窗口大小告知缓冲区还能放多少数据**，警告发送方要减少发送的数据量或者要让接收方有时间处理数据

#### 如何确定一个TCP链接

> 只需要一个四元组

1. IP头部中的**双方IP**地址
2. TCP头部中的**双方端口**号

#### 服务端的一个端口最多可以接受多少链接

> **理论**上客户端只要有了链接到来就可以接受，但是**实际**上收到一些因素的影响：

1. 每个TCP连接都是一个文件，因此文件描述符编号被占满了，此时就无法再接受连接了
   1. 系统级：当前系统可使用的最大文件描述符数量
   2. 用户级：当前用户可使用的最大文件描述符数量
   3. 进程级：当前进程可使用的最大文件描述符数量
2. 内存限制：每一个连接都会占用一定内存，当内存占用满了，也无法接受连接

#### UDP和TCP的区别和应用场景

1. 连接：TCP面向连接，UDP不需要连接
2. 服务对象：TCP只能一对一，UDP可以一对多，多对多
3. 可靠性：TCP是可靠的，UDP本身不可靠，但是可以基于UDP实现一个可靠的传输协议，例如**QUIC协议**(HTTP3.0中的知识)
4. 拥塞控制，流量控制：TCP有，UDP没有
5. 头部大小：TCP的头部开销较大并且头部可变，因为有一个选项字段可选，最小都需要20字节，UDP的头部开销较小并且头部不可变，固定为8字节
6. 传输方式：TCP是流式传输，没有边界，UDP是一个包一个包的发送，有边界
7. 分片方式：数据过大时，TCP在传输层进行分片和组装，UDP在IP层分片组装
8. 应用场景：TCP常用于FTP传输文件，HTTP，而UDP常用于视频音频通信，广播等

#### TCP丢包

> TCP只能**保证传输层的可靠性**，如果其余层不可靠，发生丢包TCP也控制不了

1. 数据在发送的过程中很多地方都可能丢包：
   - 半连接或者全连接队列满了
   - 流量控制丢包：数据传输过快，窗口装不下就可能丢包
   - RingBuffer缓冲区太小可能丢包：数据到达网卡的缓冲区，缓冲区太小可能丢包
2. 引入中间服务器：中间服务器记录最近接收的数据和其对应的id，然后与客户端发送的数据和id对比，就知道哪些丢了，重传（**自己保证可靠性**）

#### TCP和UDP可以使用同一个端口吗

> 端口的作用是为了区分一台主机中的不同应用程序

1. 主机收到数据之后，可以根据IP头的信息知道到底使用的是TCP还是UDP
2. 之后按照不同的协议使用不同的方式处理完信息之后，从指定的端口号中交给应用程序
3. 相当于TCP和UDP处理信息的方式不同，所以即使端口相同，也是可以的

#### TCP三次握手过程

1. 客户端随机初始化一个序号(1000)，然后将TCP头部中的SYN设置为1代表想要建立连接，之后将报文发送给服务端，此报文不带数据
2. 服务端收到客户端的报文后，随机初始化一个序号(2000)，然后确认客户端发来的报文(确认号字段为1000+1)，然后将SYN和ACK都设置为1，将报文发送给客户端，此报文不带数据
3. 客户端收到报文之后，确认服务端发来的报文(确认号字段为2000+1)，ACK设置为1，并且自己的序号变成1001，此时**可以携带数据**

#### TCP快速建立连接

1. 在第二次握手时产生了一个cookie，通信双方都知道这个cookie
2. 第一次通信还是正常的三次握手
3. 后续通信带上这个cookie就可以直接跨越三次握手，因为cookie中保存了一些信息

#### [为什么是三次握手，不是两次，四次](https://xiaolincoding.com/network/3_tcp/tcp_interview.html#%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B-%E4%B8%8D%E6%98%AF%E4%B8%A4%E6%AC%A1%E3%80%81%E5%9B%9B%E6%AC%A1)

> 三次握手是为了建立TCP连接，也就是初始化Socket，序列号和窗口大小，两次太少，四次太多

1. 三次握手才能**阻止重复历史连接的初始化**：

   1. 客户端发送第一个SYN包在网络中阻塞了，过一段时间之后客户端发了第二个SYN包
   2. 针对发送的两个SYN包，如果先到的是第一个**旧**的SYN，此时服务端回复ACK和SYN后，客户端收到包就断开连接了，因为客户端想要的是对新的包回复的ACK
   3. 二次握手的话，此时服务端不知道客户端是否断开连接，于是会发数据，发出去的数据客户端也不会接受，造成资源浪费
   4. 三次握手时，这时候服务端会等客户端第三次握手，还不会发数据，于是避免了历史的链接
   5. 三次握手中，即使客户端发送了两次SYN，只有针对**最新**的这次SYN才会建立连接

   > 如果是两次握手的话，服务端发送完确认报文之后就直接进入可以收发数据的阶段，如果这个确认报文不是客户端想要收到的就不建立连接，此时发送数据也是浪费资源

2. 同步双方的序列号：三次握手时存在一个序号的同步，双方都知道下一步对方应该发送什么序号的数据，从而使得数据可以按序处理，重复数据也可以丢弃

3. 避免资源浪费：如果服务端对客户端的ACK客户端没有收到，此时客户端就会不停地发送SYN请求连接，而服务端每收到一个SYN都会确认一次，并且建立一个链接（没有第三次握手服务端不知道客户端是否收到），这样就导致很多冗余连接被建立

#### 三次握手时第三次客户端的 ACK丢失了还能传输数据吗

> 可以

1. ACK的含义是对之前的报文的确认，客户端发送数据时的ACK一定会**大于之前的ACK**，也就是相当于隐含的将客户端的ACK再次发送了
1. 如果在发送数据之前服务端由于重传SYN+ACK导致连接断开，此时客户端发送的数据就收不到回复，此时触发重传

#### TCP三次握手的初始化序号为什么每次都不一样

1. 防止**收到历史报文**：如果每次都一样，上一次连接中**没收到**的报文就可能在下一个连接中收到

   > 比如上次链接中的数据由于网络阻塞现在才传递到，初始序号相同时，很可能误认为这是本次链接中的数据被接受，初始序号不同就可以避免这个问题

2. 但是序号是**循环生成**的，此时如果刚好循环生成的序号是历史报文所处连接的序号，那么也会导致收到历史报文，只是**概率很小**，一次循环下来应该是4-5个小时

3. 为了防止序号循环产生矛盾，给报文分配一个时间戳，历史报文到达之后，如果时间戳**小于**当前有效的时间（不是**递增**的），就**丢弃**，时间戳也会循环生成

#### 初始化序号如何产生

> 初始化序号== M + F(localhost, localport, remotehost, remoteport)。
>
> 这样计算几乎不可能重复

1. M：计时器，每隔4微妙+1
2. F：哈希算法，以源IP和端口，目的IP和端口为输入生成一个哈希值

#### IP层会分片，为什么TCP还需要MSS来分片

> 为了控制数据加上TCP和IP头部之后不会触发IP分片，因为**IP层分片效率**不高

1. IP层分片效率不高：如果不在TCP层进行分片，那么IP层分片之后，一旦某个分片丢失，**整个TCP报文都要重传，效率不高**
2. 在TCP分片之后，保证加上TCP头部整体的长度**不会触发IP层的分片**，这样IP层直接将数据交给下层，丢失也只有一个更小的TCP报文丢失，重传影响更小

- MTU：网络包的最大长度，包含IP头,TCP头，数据三部分，一旦这部分超过长度IP层就会进行分片
- MSS：在MTU基础上除去IP和TCP头部之后的数据部分的最大长度，数据不超过这部分就不会触发IP层分片

#### 三次握手丢失会发生什么

> 核心就是**收不到自己包的确认就会重传**，重传次数受到参数控制（默认5），重传时间为前一次的2倍，例如1,2,4,8,16,32s。。。

1. 第一次握手丢失：客户端收不到第一次握手的SYN包的确认，所以触发SYN的重传
2. 第二次握手丢失：客户端收不到第一次握手的SYN包的确认，所以触发SYN的重传，服务端收不到第二次握手的SYN+ACK包的确认，所以触发SYN+ACK的重传
3. 第三次握手丢失：服务端收不到对于第二次握手SYN+ACK的确认，此时触发两个重传：
   - 二次握手的SYN+ACK的重传，重传次数超过限制**服务端直接断开连接**
   - 客户端不知道断开连接，继续发送数据，收不到响应就**重传数据**，超过重传次数才断开连接



#### 什么是SYN攻击

> 半连接队列被占满，客户端无法响应

1. 一旦有客户端发送了SYN包给服务端，此时服务端就会将SYN包存储在半连接队列中
2. 当服务端针对当前SYN包发送确认包并得到了客户端的确认后，就将SYN包从半连接队列中删除
3. 当短时间到来大量SYN包，并且虚拟客户端不确认服务端的SYN+ACK时，就会导致半连接队列被占满，正常的用户连接请求就无法建立，这属于DDos攻击的一种

#### 如何避免SYN攻击

1. 加大存储SYN包的半连接队列长度，使其不容易被占满
2. 开启一个synCokkie功能：此时SYN半连接队列占满，其余的请求不放入SYN半连接队列，而是针对请求生成一个Cookie，**直接**尝试与客户端建立连接
3. 减少SYN+ACK的重传次数：当服务端发送了SYN+ACK没有响应时就会触发重传，重传次数过多会消耗大量资源，减少重传次数可以使得连接**快速断开**

#### TCP半连接(SYN)队列

> 收到客户端的SYN包之后，内核会将当前连接存储到半连接队列（哈希表）

1. 半连接队列溢出之后，没有开启synCookie，后面的请求会被丢弃
2. 开启了synCookie，半连接队列满了之后，其余的请求直接尝试建立连接，这需要分配一个cookie，双方利用cookie进行验证并建立连接
3. cookie是**实时计算**的，不需要保存，所以不会遭遇SYN攻击，但是计算cookie比较消耗cpu，所以synCookie**不能作为第一选择**
4. 半连接队列的最大值有参数指定
5. 设计成哈希表是为了根据ip和端口快速找到半连接状态的连接

#### TCP全连接(accept)队列

> 三次握手成功的连接就会放入全连接队列（链表）

1. 队列中存储不下后，客户端第三次握手的ACK请求会被丢弃（默认），也就是队列溢出了，此时造成客户端认为连接无法建立
2. 队列装不下还可以设置为发送一个RST报文
3. 被丢弃的请求个数会被统计记录
4. 持续有被丢弃的请求时，就应该将全连接队列的长度调大，有参数可以调大队列
5. 设计成链表是因为内部保存的都是已建立的连接，不需要快速定位，取走一个就行

#### DDos攻击

> 分布式拒绝服务,导致合法用户不能访问网络服务的攻击

1. SYN攻击：不停地发送三次握手请求
2. HTTP攻击：不停地向HTTP服务器请求资源
3. 慢速攻击：与HTTP服务器建立很多长连接不释放，耗费HTTP服务器的请求处理能力
4. ICMP攻击：向服务器发送大量的ping命令

#### TCP四次挥手过程

> 三次握手只能客户端主动发起，四次挥手双方都可以主动发起

1. 客户端发起一个FIN包代表想要断开连接，此时为fin_wait1状态，客户端发送FIN代表自己不再发送数据，但是可以接受未接收完的数据
2. 服务端针对FIN包进行确认，发送一个ACK包，此时服务端进入close_wait状态，客户端进入fin_wait2状态
3. 服务端处理完剩下的数据之后，向客户端发送FIN包代表可以断开连接，如果服务端此时没有数据要处理，那么就会将ACK+FIN合并起来发送，变成**三次挥手**
4. 客户端收到FIN包之后对其进行确认，发送ACK包，此时客户端处于time_wait状态
5. 服务端收到之后进入close状态
6. 过一段时间之后（2MSL），客户端自动进入close状态

#### 为什么需要四次挥手

> 可能处理不完数据，服务端要将没发完的数据发送给客户端才能断开连接

1. 客户端发送FIN之后，表示客户端不再发送数据，但是此时还可以接收数据（shutdown）
2. 服务端接收到FIN之后，先回复一个ACK，之后可能还需要处理没处理完的数据
3. 服务端需要等待数据处理完之后才能真正断开，所以**两次挥手不够**

#### TCP三次挥手

1. 当被动关闭方**没有数据要处理**，且打开了**延迟确认**机制，此时二三次的挥手过程会合并
2. 也就是ACK+FIN会合并到一起形成三次挥手
3. 延迟确认可以**使得ACK报文也能携带数据**
4. 可以理解为内核进行了优化，将ACK和FIN进行了合并，三次挥手之后就能断开连接

#### 四次挥手丢失会发生什么

1. 第一次挥手：客户端会重传FIN包，如果规定次数内还没有接收到ACK，只能**直接断开**连接，重传次数是受参数控制的
2. 第二次挥手：相当于ACK包丢失，此时第一次挥手的FIN包会重传，规定次数内还没有收到二次挥手的ACK，此时直接断开连接
   - close：如果收到了二次挥手的包，使用close关闭连接的方式，此时需要等待第三次挥手的包到达，并且**等待时间默认不能超过60秒**，超时自动关闭，<u>并且此时不接受数据</u>，接收到数据也无法处理，会返回RST报文
   - shutdown：如果收到了二次挥手的包，使用shutdown关闭连接的方式，此时需要等待第三次挥手的包到达，并且**没有等待时间的限制**
3. 第三次挥手：相当于服务端发出的FIN包，此包丢失会导致收不到ACK包，也就会触发重传，重传次数受参数控制，并且客户端的等待时间可能有限：
   - close：客户端长期没有收到第三次挥手的包，使用close函数默认只等60s，之后直接断开连接
   - shutdown：客户端长期没有收到第三次挥手的包，使用shutdown就会一直等待
4. 第四次挥手：相当于服务端没有收到最后一次ACK：
   1. 服务端一直重传FIN，达到最大重传次数就断开连接了
   2. 客户端传递了第四次挥手的数据之后，就进入TIME_WAIT状态，此时收到了服务端重传的FIN，就会重新回复ACK，然后**重置time-wait的时间**


#### 为什么等待2MSL之后再断开连接（time_wait）

1. MSL代表报文在网络中的最大生存时间，一来一回刚好2MSL
2. 等待2MSL是为了确保没被接受到的数据可以被接受到，容忍报文丢失一次
3. 比如客户端传递的ACK丢失，此时客户端等待一段时间后会重传FIN，这一来一回差不多就是2MSL，此时客户端收到重传的FIN之后，还会重置这个2MSL，然后重发ACK，确保服务端尽可能被正常关闭

#### 为什么需要time_wait状态

> 只有主动断开连接的一方发送完第四次挥手报文之后才能进入time_wait状态

1. 防止**收到历史数据**：由于四次挥手中的初始序号按照一定规则**循环生成**，所以可能前后两个链接使用的序号是一样的，此时上一个连接中的数据就有可能被下一个连接收到，此时加上time_wait状态**保证当前连接中的所有报文都自然消失**，不会被下一个连接收到，因为time_wait中的MSL就是大于报文的TTL消耗为0的时间

2. 保证被动关闭的一方能**正常关闭**：第四次挥手的ACK丢失 之后，触发了被动方的FIN重传，主动方接收到后，此时有time_wait状态等待，保证FIN会被尽可能正确确认从而正确断开

#### time_wait过多的危害

time_wait过多导致连接释放的过程**变慢**，占用资源的无效时间变长，**浪费资源**

1. 客户端time_wait过多：导致**同一个服务器**的请求不能过多，因为是按照（源ip和端口，目的ip和端口）来区分连接的，客户端的端口被占满了就无法建立新连接了
2. 服务端time_wait过多：没被释放的请求过多导致占用系统资源过多，系统运行变慢

#### 如何优化time_wait

1. 开启一个选项：开启之后time_wait超过1秒的连接直接可以被重新**复用**，系统认为此连接已经处理完上一次的业务
2. 系统中处于time_wait的连接数超过一个**阈值**，将后面的time_wait的连接直接断开

#### 服务端为什么出现大量time_wait

> 服务端**主动断开了很多链接**才有time_wait：

1. HTTP没有使用长连接，导致很多请求被直接断开，双方都设置HTTP keep-alive保持长连接
2. HTTP长连接超时之后，服务端也会主动断开连接
3. HTTP长连接数量达到限制，服务端也会主动断开连接

#### 服务端为什么出现大量的close_wait

> 服务端**被动**断开了很多链接才有close_wait，被动断开连接之后，发送完第一个ACK到发送第一个FIN之间的状态叫做close_wait

1. 服务端被动收到FIN之后，会回复一个ACK，然后进入close_wait状态，在这期间处理未处理完的数据
2. 数据处理完成之后，会调用close函数，然后发送FIN报文给客户端，此时close-wait状态结束
3. 如果没有成功调用close函数，就会出现close_wait状态无法结束，出现大量的close_wait状态
4. 一般无法调用close函数一般都是socket变成出现了bug

#### 连接建立后，客户端故障怎么办

> 服务端会一直处于连接状态，感知不到客户端出现故障

1. TCP在指定时间内发送探测报文（**保活**），如果好几个报文都没有响应，认为此连接已经死亡，系统报错，时间和发送报文次数都可配置
2. tomcat，nginx等可以检测在一段时间内都没有新请求的连接，将这些连接释放

#### 连接建立后，服务端故障怎么办

**内核**会介入，此时正常发送四次挥手断开连接，不需要服务端进程的参与

#### socket编程通信的过程

1. 服务端和客户端初始化自己的 socket，得到文件描述符
2. 服务端调用bind将socket绑定到指定ip和端口上，之后监听，最后调用accept等待客户端的连接
3. 客户端调用connect向指定的服务端发起连接
4. 三次握手建立连接之后，返回一个**用于传输数据的socket文件描述符**，开始通信
5. 客户端调用write写数据，服务端调用read读数据
6. 断开连接时调用close函数，写入一个结束符EOF，对方读到之后就会调用close断开连接
7. 本地建立socket连接时，直接绑定一个本地文件，此时还是可以正常建立连接

#### 客户端调用close，断开的流程是什么

> 主要就是TCP的四次挥手

1. 客户端第一次挥手，发送FIN包
2. 服务端收到FIN包之后，会追加一个EOF，表示后续不会再收到数据
3. 读到EOF的时候，服务端也发送一个FIN包
4. 客户端针对收到的FIN包进行ACK
5. 服务端收到ACK之后就进入close状态
6. 客户端经历time_wait状态之后进入close状态

#### 服务端没有accept，客户端可以建立连接吗

> 可以

TCP的三次握手和accept之间互不影响，先有建立连接，后有accept

**accept只是获取到一个已经建立连接的socket**进行读写操作，所以可以建立连接，只是**无法进行read/write**

#### 服务端没有listen，与客户端可以建立连接吗

> 不可以，服务端没有listen就无法监听客户端的请求

因为listen的作用是监将当前socket转换成可接受连接的状态，一旦有连接到来就处理

没有listen就还没有监听当前的socket，所以此时无法建立连接，服务端内核帮忙会回复一个RST终止连接

#### 没有listen可以建立TCP连接吗

> 这与上面不一样，上面**必须有服务端参与**，这里没指定必须服务端参与

1. 使用回环地址客户端自己连接自己
2. 两个客户端之间建立连接
3. 例如本地建立socket连接时，直接绑定一个本地文件，此时还是可以正常建立连接

上面两种都是没有服务端的参与，所以没有listen，连接不放入半连接和全连接队列，但是会有一个**全局哈希记录通信的socket**，所以还是可以建立连接

#### bind，listen，accept，connect的作用

> 这是套接字中的几个重要的函数，套接字就是通信双方商量好的一种通信机制，封装好了一系列接口用于通信

1. bind：给套接字分配地址。将ip地址，端口号等内容绑定给套接字，这个操作是服务端在三次握手前就需要执行的
2. listen：让套接字进入等待连接的状态，之后就可以接受客户端的连接，相当于监听指定ip端口的变化
3. connect：**客户端**指定要通信的ip和端口之后，调用此函数向服务端发起请求，相当于第一次握手
4. accept：接收到客户端传递来的连接请求，分配一个用于数据I/O的套接字来通信，第三次握手之后，从全连接队列中取出一个已经建立好的连接进行通信

#### TCP重传机制

> 当主机收不到自己发送消息的确认应答，此时就会将自己的消息进行重传：

1. 超时重传（**时间驱动**）：
   - 做法：**超过一定时间**没有收到对方的确认应答报文，就开始重传，时间可以设置，数据包丢失或者确认应答丢失都会触发重传
   - 缺点：重传时间不好设置，大了小了都不好，有**公式**可以计算
   - 每次重传都将超时时间设置为前一次的两倍
2. 快速重传（**次数驱动**）：
   - 做法：为了解决超时重传可能等待时间较长的问题，一旦收到**三个重复的ACK**，说明这个ACK想确认的包没有收到，此时直接重传
   - 缺点：不知道后面的包哪些丢失，序号为2的丢失了，后面的ack的序号全都是2，不知道2后面的是否也丢失了，重传一个还是重传全部
3. SACK：
   - 做法：在TCP头部**增加一个字段**，保存所有已收到的数据，这样在重传时就只用重传所有丢失的数据，收到三次重复的ACK之后就开始重传
   - 缺点：发送的ACK丢失（超时重传）或者网络延时没收到数据包（三次ACK）时会触发重传，此时会重传重复数据
4. D-SACK：
   - 做法：收到重复数据发送一个D-SACK报文告诉对方数据重复，发送方可以根据D-SACK中的报文

#### 超时重传的超时时间设置

> RTT：从报文发出到应答报文到达中间的时间差

1. 超时时间应该略大于RTT，太大导致等待时间过长，降低传输效率
2. 太小导致不必要的重传，应答报文还没来得及回来就触发重传
3. 实际上超时重传的值根据当时的网络状况会动态变化

#### 滑动窗口是什么

> 窗口实际上是内存中的一个**缓冲区**，发送的数据要被存储在缓冲区中，不用发送一条数据后必须等待应答才能发送下一条数据

1. 分为发送方的滑动窗口和接收方的滑动窗口，二者协商，差不多是一样大的，随着接收方处理能力的变化，窗口也会不断的变化，收发双方存在一个协商的过程
2. 收到确认应答就将对应数据从缓冲区中删除
3. 应答丢失也可以通过后续应答来确认（累计确认或累计应答），因为ACK的含义就是对**之前所有包的确认**
4. 数据丢失就从缓冲区中拿到数据重传

#### 发送方滑动窗口的格式

> 窗口左边代表当前想要被确认的第一个数据

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/19.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="SND.WND、SND.UN、SND.NXT" style="zoom:33%;" />

1. 滑动窗口的总大小，取决于接收方和拥塞控制窗口的**最小值**
2. 已发送但未收到确认的数据的第一个字节处
3. 未发送但是可发送的数据的第一个字节处
4. 使用滑动窗口总大小+已发送但是未收到确认的第一个字节处的指针可以得到不能处理的数据的第一个字节的位置

#### 接收方滑动窗口的格式

> 窗口最左边的数据指的是我想要接受的第一个数据，也就是ACK的值

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/20.jpg" alt="接收窗口" style="zoom:33%;" />

1. 接收窗口的大小，这个大小会传递给发送方，告知自己现在处理数据的能力，其实滑动窗口可以理解为一个缓冲，先发过来我慢慢的处理即可
2. 窗口最左边是想要收到的数据编号，也就是当前ACK的值

#### 流量控制

> 根据接收方缓冲区（滑动窗口）的大小，动态**调整发送数据的速度**，这就是流量控制

1. 传输数据的通信过程中，会更新缓冲区的大小，也就是告知对方自己处理数据的能力变化，缓冲区的变化可以理解为滑动窗口的大小变化
2. **丢包问题**：更新窗口的过程中如果**先减小了缓冲区大小，然后再减小窗口**，此时可能造成丢包，因为窗口更新存在延迟，发送方认为此时窗口大小没有变小，发送的数据过多造成丢包，解决办法就是**先缩小窗口，再减小缓存**
3. **窗口关闭**：窗口大小为0时，说明此时无法再继续接收数据，此时就不再发送数据，直到窗口大小不为0
4. 窗口关闭的**死锁**问题：窗口关闭时**恢复窗口的报文丢失**，别人不知道窗口恢复了，此时无法通信了，一旦窗口关闭就启动计时器，倒计时结束**主动探测**窗口是否恢复，探测次数一般为3次，计时器一般计时30-60秒
5. **糊涂窗口综合征**：接收方窗口有了几个字节的空闲之后，发送方就会发送几个字节的数据，加上至少20字节的头部，**不太划算**，要么窗口太小就不通知发送方，要么发送方觉得窗口太小先不发送数据，这涉及到**延迟确认和Nagle算法**
   - 接收窗口太小：当接收窗口大小不超过MSS或者窗口空闲空间没有超过一半时就不通知发送方发送数据
   - 避免发送小数据：使用Nagle算法
   - 延迟确认：让ACK也携带数据，因为正常的ACK只是为了确认数据，但是他还是要占用至少20字节的头部，所以让ACK延迟确认，有数据要发送时，加上ACK一起发送，提高头部的利用率


#### Nagle算法

> Nagle的思想是延时处理，满足下面任意一个条件就可以发送数据
>
> MSS：网络设备可以接受的最大TCP数据包的大小

1. 窗口大小等于MSS并且数据大小等于MSS
2. 收到之前发送数据的ACK

#### TCP延迟确认

> 延迟确认是让**ACK也要携带数据**，充分利用ACK的头部
>
> 因为ACK只是为了确认，不携带数据，但是头部占用了一定的网络资源，所以浪费资源

1. 当**有响应数据**要发送时，将响应数据放到ACK数据部分发送
2. 当没有响应数据时，ACK会**延迟等待**，等待时间可以配置
3. 在ACK延迟等待期间，对方发送的第二个数据报文又到了，此时就不管是否等到响应数据，直接发送ACK，避免对方误会第一个数据报文丢失（因为没收到ACK）

#### 拥塞控制

> **流量控制**是为了防止发送方将接收方的缓冲区填满，针对**收发双方**
>
> **拥塞控制**是为了防止发送方的数据大量出现在网络中，造成网络拥堵，只要发生了超时重传，就认为出现了拥塞，针对整个**网络**
>
> 都是控制**发送方**发送数据的能力

1. 慢启动：TCP链接刚建立时，慢慢提高发送数据的数量，每收到一个ACK，就增加一个发送数据包的数量，**数量超过慢启动门限就启动拥塞避免算法**
2. 拥塞避免：每收到一个ACK，拥塞窗口的大小增加**1/大小**，现在窗口大小为8，收到了一个ACK，那么此时窗口大小增加`1/8`，窗口大小过大会出现丢包，此时**触发拥塞发生**
3. 拥塞发生（不同情况下触发的拥塞发生，处理方式不一样）：
   - 超时重传触发的拥塞发生：慢启动门限变为当前窗口大小的一半，窗口大小重置为1，重新开始慢启动，到达慢启动门限就是拥塞避免，丢包之后重新拥塞发生
   - 快速重传触发的拥塞发生：窗口设置为当前的一半，慢启动门限设置为当前更新后的窗口大小（也就是当前窗口的一半），**启动快速恢复算法**
   - 对比超时重传直接将窗口大小减小到1然后进行
4. 快速恢复（只要有重复的ACK，窗口大小不断变大，直到收到新的ACK，此时窗口大小恢复成慢启动门限的值，开始拥塞避免）：
   - 窗口更新为慢启动门限+3，3代表确认有三个数据包被收到，这里增大窗口是为了快速将丢失的数据包重传
   - 重传丢失的数据包
   - 再有重复的ACK，窗口大小+1
   - 收到新数据的ACK说明**不丢包了**，此时就将窗口大小更新为慢启动门限的值，开始拥塞避免，这里减小窗口的大小是为了减小网络的拥塞，所以**先增大后减小**
   - 这种先变大再减小的原因是由于加大可以快速的标识当前收到了重复的ACK，我快速重传丢失的包，收到新的ACK代表不丢包了，此时不要把窗口设置的那么大，防止又丢包

<img src="https://zzzi-img-1313100942.cos.ap-beijing.myqcloud.com/img/202404301917678.png" alt="快速重传和快速恢复" style="zoom: 33%;" />

#### 优化TCP

> 主要是针对内核参数的调整，针对不同情况使用不同的参数

1. **三次握手**优化：
   - 根据网络状态控制第一次握手SYN包的重传次数，避免等待太久或者等待时间不够
   - 半连接队列满了之后，调大半连接队列长度
   - 或者开启synCookie，这样就可以减小syn攻击带来的影响
   - 绕过三次握手，第一次请求正常经过三次握手，并将连接信息保存到cookie中，后期再次发起连接请求之后，只要携带了这个cookie，就可以直接进行通信，第一次SYN包就可以携带数据
2. **四次挥手**优化：
   - 使用四次挥手断开连接，而不是使用RST强制断开连接，更加优雅
   - 调整FIN报文的重传次数
   - **复用**time_wait状态的连接，time_wait超过1s系统认为当前连接已经没有旧数据传送了，此时趁链接还在直接复用，避免三次握手
3. **数据传输**优化：
   - 不是发送一个包等一个ACK，而是利用**滑动窗口**提高吞吐率，批量发送请求
   - 尝试**扩大窗口**大小，也就是缓冲区大小，这样吞吐率就会进一步提高
   - 打开缓冲区自动调整的开关，这样根据网络状态就会动态调整缓冲区大小，网络好传输的数据多，缓冲区就变大

#### TCP面向字节流

1. 因为消息可能会被分成多个TCP报文，以字节流进行发送，不像UDP一个报文就是一个完整的消息
2. TCP报文中的数据可能由于分片并不完整
3. 可能出现**粘包**的问题，不知道消息的边界无法读取有效的消息

#### TCP粘包的解决办法

> 两个不同的消息，被划分成了同一个TCP报文，此时就是粘包

1. 指定**数据边界**，有了边界就可以读取数据
2. **关闭Nagle**算法，防止**数据累计造成粘包**，因为Nagle算法就是为了不发送较小的数据而提出的，这可能造成粘包

#### SYN包什么时候会被丢弃

1. 遭遇SYN攻击导致半连接队列满了：预防SYN攻击
2. 全连接队列满了，无法接受后面的请求，SYN包**默认**会被丢弃

#### 三次握手后客户端宕机

> 客户端宕机之后，重启之后会重新建立连接

1. 建立连接的ip和端口号**不变**：
   - 客户端发送SYN包
   - 服务端发送一个ACK包，其中的序号是**上一次连接**中的**想要**的序号，因为客户端的ip和端口已经建立连接，但是还发送SYN包
   - 客户端发现不是自己想要的ACK，所以发送RST报文断开连接
2. 建立连接的ip和端口号**变化**：
   - 三次握手建立新的连接
   - 旧连接有**两种**情况：
     - 服务端发送了数据，客户端回复RST报文，此时连接释放
     - 服务端没有发送数据，一段时间没有数据交换触发**保活机制**，最终释放连接

#### 如何关闭一条TCP连接

> 伪造RST报文（源ip和端口，目的ip和端口，**序列号**）
>
> 序列号很重要，不正确的序列号不会被接受

1. **主动**关闭killcx工具：
   - 主动**模拟一个SYN包**发送给服务端，由于是对已连接的服务端发送SYN，此时服务端会回复一个包，序列号是客户端想要的，确认号是自己想要的
   - killcx伪造两个RST包，根据上面的两个序列号就可以断开双方的链接
2. **被动**关闭tcpkill工具：
   - 连接**双方必须通信**，才能知道他们的序号和确认号
   - 根据序列号和确认号伪造两个RST报文用于关闭连接
   - 无法关闭不活跃不通信的连接

#### 四次挥手中存在乱序的FIN包

> 由于数据包都**存在序号**，所以即使FIN包乱序到达也不会处理，判断其乱序之后将其加入**乱序队列**（红黑树），也就是所有的包都有自己的顺序

1. 在FIN_WAIT2阶段收到服务端传递来的FIN报文，首先判断序号是不是自己想要的
2. 是自己想要的说明是正常的FIN，此时进入TIME_WAIT状态
3. 不是自己想要的说明FIN**乱序**，此时还有正常数据，将FIN包放入**乱序队列**
4. 等到想要的数据到来之后，判断乱序队列中是不是有**按序号保持顺序**的数据
5. 有的话就取出来，若取出来的包**刚好是FIN包**，说明此时才应该进入TIME_WAIT状态

#### 已建立的连接收到SYN包

1. 源端口不一样：此时认为是新连接，此时三次握手建立连接
2. 源端口一样：
   1. 收到SYN之后回复一个正常通信时的序号
   2. 发送SYN包的一端收到这个报文发现序号**不是自己想要**的，此时回复RST
   3. 收到RST之后断开连接

#### time_wait状态下收到了SYN包

> 只有相同源ip和端口，目的ip和端口的SYN包才对当前连接有意义
>
> 不相同的SYN包不会到达此连接

1. SYN包的序号和时间戳**合法**：序号**和**时间戳大于最后通信的序号和时间戳，通信端认为合法，此时可以建立连接
2. SYN包的序号或者时间戳不合法：序号**或者**时间戳小于最后通信的序号和时间戳，此时不合法，然后重新发送第四次挥手的ACK，对方发现ACK的序号和时间戳不是自己想要的，回复**RST**之后就断开连接

#### time_wait状态下收到了RST包

> RST包是为了断开连接

1. 有一个参数控制是否提前断开连接
2. 参数为0，此时提前断开连接，可能收到历史报文，或者连接异常断开
3. 参数为1，丢弃RST报文，等待正常断开

#### TCP keep_alive（保活）的作用

> 确保连接还存在

1. 连接长时间没有数据传输，此时触发保活机制，发送探测报文检测连接的安全性
2. 没有开启TCP keep-alive保活机制，那么就不会主动监测
3. 多长时间触发，隔多久重发一次，重发多少次这三项都受到参数控制

#### TCP连接出现宕机或者进程崩溃

> 一个连接是否存在看通信双方的状态以及是否传输数据，是否开启TCP keep-alive保活

1. 进程**崩溃**：内核检测到后会回收资源，帮忙发送FIN包进行四次挥手
2. **宕机**：此时内核都无法工作
   - **有**数据传输：此时对方收不到数据的响应报文，超时重传达到阈值之后断开连接
   - **无**数据传输，**有**TCP keep-alive：一段时间没有数据传输，此时保活机制检测连接是否正常，不正常断开连接
   - **无**数据传输，**无**TCP keep-alive：连接保持建立，

#### TCP连接被拔掉网线

> 就看网线是否及时插回去，不会立马影响连接

1. 及时插回去了：此时对方**还没来得及发现**，好像无事发生
2. 没及时插回去：
   - 有数据传输：此时对方收不到数据的确认报文，触发超时重传，超过阈值才断开连接，中间网线插回来就正常工作
   - 没有数据连接：
     - 开启TCP keep-alive：长时间没有传输数据，出发保活机制之后，最终断开连接
     - 没开启TCP keep-alive：不做任何操作，网线插回之后正常工作

#### time_wait状态下的连接复用为什么默认关闭

> 连接复用会导致time_wait的时间变短，从而可能出现一些问题：

1. 可能收到历史报文：time_wait的2MSL时间可以保证当前连接的报文都自然消失，这是由于**序号可能重复**从而无法判断新旧报文

   > 这个问题被**时间戳缓解**，历史报文的时间戳不是当前连接想要的就会拒绝
   >
   > 但是**RST报文一般不带时间戳**，则很大可能收到旧RST报文从而造成连接意外断开

2. 可能造成异常断开：第四次ACK丢失，对方会重传FIN，如果此时没有time_wait，那么就会回复一个RST报文，造成对方认为出错才断开，**不优雅**

#### TLS和TCP可以同时进行握手吗

> 正常情况下不行，只能先TCP握手后TLS握手

特殊情况下（TCP Fast Open+TLS v1.3）：

1. 通信双方开启了TCP Fast Open，此时只要不是第一次通信，后面的三次握手过程就会简化，因为双方协商了一个cookie，类似于一个优先通行证
2. 如果此时使用的TLS版本是1.3，此时就可以同时进行握手过程

#### HTTP keep-alive和TCP keep-alive

> 二者没有关联

1. HTTP keep-alive：开启之后可以保持HTTP长连接，减小开销
2. TCP keep-alive：保活机制，长时间没有数据通信的TCP连接会检测连接的有效性，多长时间触发保活，检测报文发送间隔时长和次数都有参数规定

#### TCP的缺陷

1. 升级困难：TCP协议在**内核**中实现，所以升级需要修改内核，较为困难

2. 建立连接耗时太长：**第一次**需要经历TCP三次握手，TLS四次握手才能建立连接传输数据

   > 可以被TCP Fast Open（使用cookie越过三次握手）和TLS v1.3（会话复用）**缓解**

3. 对头阻塞：由于报文存在**序号**，当一个序号的报文丢失，即使后面的报文到达也无法处理

4. 网络变化需要重新建立连接：由于TCP面向连接，虽然可靠，但是网络变化需要重新建立连接

   > 可以基于UDP实现可靠传输：QUIC协议基于ID实现，不基于IP和端口，所以网络变化影响不大

#### UDP可靠传输（QUIC）

> 可以基于TCP的**缺陷**进行改进，实现可靠传输，UDP本身不可靠，**可靠性是QUIC提供的**

1. 严格递增的数据包ID：
   - 更准确计算RTT，即使重传也知道重传的报文是谁（ID大的），这样就可以根据重传的报文计算RTT，之后判断是否超时
   - 可以**乱序确认**，所以不会有对头阻塞问题，根据StreamID和offset字段来确认当前包是不是之前重传的，这两个字段一致证明两个包一致
2. 解决**对头阻塞**：每一个Stream一个滑动窗口，一个Stream中的数据包对头阻塞，不会影响其他Stream
3. 流量控制：QUIC实现了自己的流量控制
   - Stream级别：针对每一个Stream，协商自己的窗口大小，只要正确接受的数据超过窗口大小的一半
   - Connection级别：限制所有Stream加起来的总字节数
4. 拥塞控制：QUIC将TCP中拥塞控制的方案**搬过来**了
5. 更快的建立连接：QUIC内部包含TLS，建立连接的同时就可以完成秘钥协商，更快
6. 网络迁移：网络地址或者端口变化后，只要**协商的ID和密钥还在**，就可以直接建立连接

#### TCP和UDP使用同一个端口

1. TCP和UDP**可以使用**同一个端口：数据到达网络层，根据IP头部来区分到底是使用了TCP还是UDP，所以可以区分，于是可以使用同一个端口
2. TCP和TCP可以使用同一个端口**吗**：
   - 两个TCP连接的IP**一致**，此时**不能用**
   - 两个TCP连接的IP**不一致**，此时**可以用**
3. 客户端可以使用同一个端口吗：只要源ip端口，目的ip端口**任有一个不同**就可以使用

#### 服务端重启报错Address already in use

1. 服务端重启会断开连接，经过四次挥手
2. 重启正好赶上了time_wait状态，此时连接还未真正断开，所以报错
3. 要么等time_wait状态过了建立连接
4. 要么开启一个选项，time_wait时四元组相同（源ip端口，目的ip端口）的连接还是可以正常建立

#### TCP中序列号和确认号的变化

> 建立连接时随机初始化（时间戳+(源ip端口+目的ip端口)生成的哈希值）

<img src="https://cdn.xiaolincoding.com//mysql/other/ae18cbf6071c47b98014a68d05c37d16.png" alt="在这里插入图片描述" style="zoom: 33%;" />

1. 序列号：上一次发送的序列号+数据长度，如果发送的是SYN或者FIN，此时数据长度为1
2. 确认号：上一次接收的序列号+数据长度，如果收到的是SYN或者FIN，此时数据长度为1
3. 序列号就是当前**自己的编号**，确认号就是自己下一步想要的**数据的编号**

#### ip和mac的区别

1. ip处于网络层，mac处于数据链路层
2. mac地址一般不可变，IP可以变化
3. mac一般是指定下一跳的设备，也就是设备之间是**直连**的
4. ip一般用于网络中通信。设备之间**没有直连**
5. 通信过程中，源和目的mac一直在变化，但是ip不会变化，因为mac一般在数据链路层中使用，数据到达路由器后就由ip控制

#### ip地址

1. 由32位整数组成，采用点分十进制划分
2. 分为A-E五类ip地址，分别以0,10,110,1110,1111开头，主机号所占位数分别为**24,26,8,28,28**，看第几位位0就能看出是几类地址
3. 主机号全为1用于广播，全为0用于指定网络
4. D,E类地址**没有主机号**，D常用于多播，E是预留的

#### CIDR无分类地址

> 不对ip地址划分A,B,C,D,E，而是**直接指定**网络号和主机号的长度

子网掩码：网络号部分全为1，主机号部分全为0，与ip地址**与**就可以**得到ip的网络号**

- 求网络号：判断两个ip地址是不是处于同一个网络中
- 划分子网：将主机号**借**出来一部分做子网划分，借出来的一部分就可以形成不同的子网

#### 公有地址和私有地址

1. 公有地址：整个互联网内唯一的地址，由统一的机构负责分配管理
2. 私有地址：局域网内唯一，全局内可以重复，一般由网络管理员管理
3. 私有地址想要访问需要使用**NAT**网络地址转换服务，将私有地址转换为一个公有地址

#### 路由控制

> 数据到达路由器之后，转发靠的是**网络地址**

1. 路由器中的**路由表**记录了ip地址对应的下一跳应该怎么走
2. 数据到达路由器之后，根据子网掩码计算出网络地址
3. 从路由表中查询到该网络地址下一跳怎么走
4. 不停地跳，最终到达最后一个网络中，此时依靠ip+mac+端口最终传送数据

#### ip分片和重组

> 超过MTU就需要进行分片，但是IP分片**不太好**

1. MTU：网络包的最大长度，超过此长度就会分片，一般为1500字节
2. 针对TCP，引入MSS，尽量在TCP层进行分片，因为IP层分片一旦丢失，整个数据报都需要重传
3. MSS：去掉TCP和IP头部，数据的最大长度
4. 针对UDP，尽量避免发送大于MTU的报文，这样尽量避免IP分片

#### IPV6

1. 长度为128位，缓解IPV4地址耗尽的情况
2. 可以自动配置，没有DHCP服务器也可以分配IP地址
3. 简化头部结构，提高传输的性能
4. 每16为为一组，用`‘:’`分开
5. 分为单播，多播，任播地址

#### IPV4和IPV6头部的区别

> IPV6的头部结构更加简单

1. 取消了首部校验和：因为在数据链路层和传输层都校验，所以IPV6直接去掉
2. 取消分片/组装相关字段：IPV6不允许在中间路由器分片重组，只能在主机端操作
3. 取消选项字段：这样使得头部的长度固定为成40字节

#### DHCP

> 用来分配ip地址
>
> 经历发现，提供，请求，确认报文，全程使用UDP广播

1. 由于客户端此时还没有ip，所以利用UDP广播通信发送DHCP**发现**报文
2. DHCP服务器收到发现报文之后，使用DHCP**提供**报文响应可提供的ip地址，子网掩码，网关，DNS服务器以及租用期限
3. 客户端收到多个DHCP提供报文之后，选择一个DHCP服务器，发送DHCP**请求**报文
4. 服务器最终响应DHCP**确认**报文来确认
5. 租用期限快到达之后，发送DHCP**请求**报文：
   - 服务器同意租用，此时延长租期
   - 服务器不同意租用，此时停止使用

#### DHCP使用UDP广播通信的缺点

> 由于使用的是UDP广播，所以路由器不转发，当DHCP服务器与客户端不在同一个局域网内时就无法通信

1. 使用DHCP**中继代理**
2. 中继代理收到UDP广播通信包之后，将其以单播的形式转发给DHCP服务器
3. 相当于起到了一个中间商的作用

#### NAT地址转换

> 是为了解决IPV4地址耗尽的问题

1. 一个私有地址转换成一个公有地址无意义
2. 网络地址和端口转换**NAPT**：使用私有地址+端口一起转换，此时就只需要一个公有ip
3. 私有地址和公有地址的转换依靠一个**转换表**映射

> **缺点**

1. 外部公网无法与内部的私网地址**主动建立连接**，因为此时转换表中没有转换记录
2. 私网转公网会消耗性能
3. NAT路由器重启，转换表就不在了

> 解决办法：

1. 使用IPV6，公网地址就够用了
2. NAT穿透：私有地址即使没有数据发送，也会主动的建立与公有地址的转换记录到转换表中，这样公网想要主动建立连接也可以通过转换表来建立

#### ICMP互联网控制报文协议

> 用来确认ip包的发送状态，失败原因

1. 确认ip包是否成功送达目标地址
2. 报告发送过程中出现的问题便于后期改善
3. 分为**两类**：
   - 查询报文：用于诊断的查询信息
   - 差错报文：通知出错原因
4. 被封装到IP包里面

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/6.jpg" alt="常见的 ICMP 类型" style="zoom:33%;" />

1. **目标不可达**分为以下几种情况：
   - 网络不可达：路由表中没有目的主机的IP网络号，不知道怎么转发
   - 主机不可达：主机没连接网络
   - 协议不可达：主机找到了，但是主机不支持当前协议
   - 端口不可达：端口找到了，但是应用没监听当前端口
2. 原点抑制：为了减小网络拥堵的情况，网络一旦拥堵，源主机就会收到这个报文
3. 重定向消息：数据包走的不是最优路径，此时会返回重定向消息，包含最优路径
4. 超时消息：当数据包的TTL为0还没传输到目标主机，此时路由器帮忙返回一个超时消息

#### IGMP因特网组管理协议

> 用于**组播**中哪些ip处于同一组，组播地址一般为专门预留的组播地址

1. 路由器周期性的发送IGMP常规查询报文
2. 主机收到查询之后，想要加入组播组的的主机就会发送成员关系报告报文
3. 路由器收到之后，将这些主机加入组播组，后续发送的数据全都是组播
4. 要离开组播组时，发送离组报文
5. 路由器收到离组报文之后，查询这个组内还有没有主机，有的话才转发组播数据

#### ping的工作原理

> 基于ICMP协议工作，也就是判断报文是否到达，没到达出现了什么错误

1. 查询报文：用于诊断的查询消息
2. 差错报文：通知出错原因的错误消息
3. 被封装到IP包里面
4. ping基于ICMP中的回送应答报文和回送请求报文实现，在报文中有几个特殊的字段：
   - 标识符：区分哪个应用程序发的ICMP包，可以用进程ID做标识
   - 序号：从0开始，每次+1，用来判断包是否丢失
   - 选项数据：存放一个发送请求的时间值，判断路程长短

#### traceroute的使用

1. 设置特殊的TTL，追踪数据包沿途经过的路由器
   - 先将TTL设置为1，第一跳路由器返回超时消息
   - 然后TTL设置为2，第二条的路由器返回超时消息
   - 不停的增加TTL，最终拿到所有路由器的地址
   - 设置一个不可能的端口号为目标端口号，当回复端口不可达时说明到达目的地
2. 设置不分片，确定路径的MTU，因为MTU的值不一定全是1500：
   - 发送时IP首部设置为不分片，路由器丢包
   - ICMP通知下一次MTU的大小
   - 每次收到ICMP的响应就减小包的大小

#### 断网之后可以ping通吗

1. localhost可以ping通，也就是127.0.0.1回环地址

   因为回环地址会走本地网卡（假网卡），此时会将消息发送到一个链表中，这个链表所有网卡共享，之后本机从链表中读取数据就可以了

2. localhost是一个域名，最终被解析成127.0.0.1

3. 0.0.0.0代表本机所有的ip地址


#### cookie，session，token

> 这三种是为了解决HTTP无状态的问题

1. cookie:

   - 用户登录之后，生成一个cookie，cookie中可以保存用户的基本信息
   - 后续每次请求都携带这个cookie用来证明自己的登录状态
   - cookie中可能有敏感信息，且可能被修改，不安全
   - 用户如果禁用cookie后，那么cookie就会失效
   - cookie保存在客户端，只能保存ascii格式的数据，有效期较长，但是能存储的大小默认只有4kb
   - cookie只是一种传递数据的手段，只不过内部保存用户信息可以用来验证登录状态，保存sessionId就可以实现更安全的session来验证登录状态

2. session：

   - 用户登录之后，服务端保存用户信息到session中，并返回一个唯一的sessionId给用户
   - 用户每次请求带上这个sessionId即可验证自己的登录状态，不用传递用户的真实信息
   - 相比cookie来说，session存储在服务端，能保存任意类型的数据，有效期较短，存储数据的大小也比cookie大
   - sessionId的传递是通过cookie来实现的
   - 在跨域的情况下，cookie无法进行传递，从而携带不了这个sessionId
   - 并且大量用户访问时，服务器需要保存大量的session，占用大量空间

3. 共享session：

   - 为了实现分布式架构中session的共享，有多种技术
   - 将session存储到别的服务中，例如redis中实现共享
   - 同一个ip固定访问一台服务器，这样就不会出现需要session共享的问题
   - 使用token代替session
   - tomcat的session复制，一个用户登录吗，将当前用户的session复制给所有的服务器，这样需要耗费大量内存

4. token：

   - 分布式架构出现之后，一种服务可能部署到多个服务器上，这样用户在请求时经过**负载均衡**之后不一定路由到哪一台服务器，这台服务器中可能没有保存登录的session信息，也就是session无法共享
   - token就是为了解决session无法共享的问题
   - token分为三部分，头部，载荷和签名
   - 头部指定当前使用的签名算法和token类型
   - 载荷部分就是用户需要加密的信息，比如用户的信息
   - 签名部分就是前两部分加上一个私钥加密之后的结果
   - 由于token中的载荷部分保存了用户的信息，所以解析出这一部分就可以验证用户的登录状态，达到共享的目的
   - token无需保存到客户端或者服务器，只需要在通信的时候传递即可

   
