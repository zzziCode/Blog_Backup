---
title: "网络面经"
description: "网络面经"
keywords: "网络面经"

date: 2024-03-11T08:52:11+08:00
lastmod: 2024-03-11T08:52:11+08:00

categories:
  - 面试
tags:
  - 面经
  - 网络

# 原文作者
# Post's origin author name
author: zzzi
# 开启数学公式渲染，可选值： mathjax, katex
# Support Math Formulas render, options: mathjax, katex
math: mathjax
# 原文链接
# Post's origin link URL
#link:
# 图片链接，用在open graph和twitter卡片上
# Image source link that will use in open graph and twitter card
#imgs:
# 在首页展开内容
# Expand content on the home page
#expand: true
# 外部链接地址，访问时直接跳转
# It's means that will redirecting to external links
#extlink:
# 在当前页面关闭评论功能
# Disabled comment plugins in this post
#comment:
#  enable: false
# 关闭文章目录功能
# Disable table of content
toc: false
# 绝对访问路径
# Absolute link for visit
#url: "网络面经.html"
# 开启文章置顶，数字越小越靠前
# Sticky post set-top in home page and the smaller nubmer will more forward.
#weight: 1

# 开启各种图渲染，如流程图、时序图、类图等
# Enable chart render, such as: flow, sequence, classes etc
#mermaid: true
---

> 🕸 网络面经

本文中介绍了一些计算机网络中常见的面试题，也可以当做平时的学习笔记来使用，知识点参考小林coding的[图解系列](https://xiaolincoding.com/)，文章长期更新

<!--more-->

#### TCP/IP的层数

> 这是对OSI七层网络协议的简化，现在变成了四层

1. 应用层：应用软件在这一层实现，不同应用需要通信时，就把数据交给下一层传输层

2. 传输层：有两个协议TCP,UDP，加上端口号等信息，端口号负责区分消息到达另一台设备时，交给哪个端口对应的应用，可能进行**分段**，之后交给下一层

3. 网络层：将从上层接收到的报文加上IP等信息，ip负责表示将消息交给哪一台主机，可能进行**分片**，交给下一层，ip地址分为网络号（找子网）和主机号（找子网中的主机）

4. 网络接口层：在数据的ip头部加上MAC头部，封装成数据**帧**，这样就可以通过mac地址区分网络上的设备

   <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/%E5%B0%81%E8%A3%85.png" alt="img" style="zoom:35%;" />

#### 输入网址到页面显示的过程

1. 解析url：确定要访问哪个服务器和服务器中哪个文件

2. 根据上述信息生成http请求（请求行，请求头。。）

3. 根据要访问的服务器名在DNS服务器中查询其ip地址，这里涉及到**域名解析**

4. 找到通信的目标ip之后，浏览器通过调用socket库来委托协议栈进行通信

5. 由于http基于tcp进行通信，此时需要三次握手建立连接

6. 建立连接也需要按照这个流程传输数据，是为了确保双方确实可以收发数据

7. 建立连接之后将数据进行封装，加上TCP头部（端口和序列号），进一步交给ip层

8. ip层将数据封装成网络包，加上IP头部（源IP和目标IP），可能进行分片

9. 之后对数据包加上MAC头部，主要加上MAC地址信息，包括发送方和接收方，此时需要用到ARP协议，填入MAC地址就知道数据**先发送**给哪个设备

10. 当客户端和服务器不在同一个子网中时，得到的MAC地址就是发送端所在子网的路由器MAC地址，在同一个子网时，此时MAC地址就是接收方的MAC地址

11. 数据封装好之后，经由发送方的网卡发送出去

12. 发送方网卡发送的消息先到达交换机，判断该消息从交换机哪个端口转发出去，这根据交换机中缓存的mac地址与端口的映射表

13. 找不到端口的映射，就发送给所有的端口（除了来时的端口）

14. 从端口出来到达路由器，路由器判断这个包自己需不需要转发（MAC地址是否一样）

15. 需要转发就去掉数据的MAC头信息，根据内部的IP头信息进行转发

16. 最终消息在网络上传输，这里根据ip地址进行转发，看接收方ip在哪个网段就转发给路由器的哪个端口

17. 都没有匹配的就转发给默认端口

18. 到达最后一跳时加上MAC地址，因为此时路由器的下一跳应该是消息的接收方了

    > 也就是在数据链路层的通信才会需要MAC地址

19. 接收方判断MAC地址是否与自己一样

20. 判断IP地址是不是符合的

21. 判断TCP中的序列号是不是我想要的（我上次ACK什么，就说明这次想要什么）

22. 以上判断都通过，此时根据TCP中记录的端口号进行转发，最终到达HTTP的服务器

23. HTTP的服务器发现对方想要请求网页，于是将网页封装到http响应报文中

24. 经过TCP，IP，MAC的封装，从网卡出去，到达交换机，路由器，最终一步一步到达请求网页的客户端，相当于是逆过程

25. 客户端还是一层一层的进行判断MAC，IP，TCP序列号，然后按照端口转发

26. 浏览器收到HTTP服务器发送过来的页面之后，就可以显示了

27. 最终会发起四次挥手断开连接

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/2.jpg" alt="简单的网络模型" style="zoom: 33%;" />

> 类似于要发送八条消息，三次握手，一条真实消息，四次挥手

#### DNS解析过程

> 为了获取目标主机的ip地址

1. 本地发送一个DNS请求到本地记录的DNS服务器
2. DNS服务器查找缓存，有目标就直接返回
3. 找不到就给客户端一个新的上层DNS服务器地址，客户端继续询问
4. 找到就返回，找不到继续给一个新的DNS服务器地址，这是由要通信的域名决定的
5. 最终得到通信目标的ip地址

#### ARP协议过程

> 为了获取下一跳的设备MAC地址

1. 先查询ARP缓存，缓存中由ip和mac的对应信息直接获取
2. 没有就以广播的形式询问xxx这个ip地址是谁的
3. 每个人判断一下，是自己的话就回答自己的mac地址是多少
4. 如果没有人的ip与之匹配，此时返回的时路由器的MAC地址

#### TCP/IP 网络模型与 OSI 网络模型（四层与七层）

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/OSI%E4%B8%8ETCP.png" alt="img" style="zoom:33%;" />

#### linux接收网络包流程

1. 网卡收到别人传递来的消息

2. 通过DMA技术（硬件机制）将网络包写入到内存地址中

   > DMA技术允许外围组件直接将数据传递给内存或者从内存中读取数据，可以减小无用操作，提高吞吐量

3. 使用NAPI机制（中断+轮询）唤醒数据处理程序，之后来轮询网络包中的内容即可

4. 读取到数据首先会到达网络接口层，去掉帧头帧尾交给网络层

5. 网络层根据ip判断数据的走向，转发还是继续处理

6. 继续处理的话就将IP头去掉，交给传输层

7. 根据传输层的TCP头或者UDP头来决定将数据放到哪个Socket的缓冲区

8. 应用程度调用socket接口读取数据给自己

>**socket**：工作在应用层和传输层之间，采用Unix**一切皆文件**的思想，数据看成文件进行读写操作

#### linux发送网络包流程

1. 应用程序调用Socket接口将数据放到socket缓冲区
2. TCP协议拷贝缓冲区副本进行发送，防止需要重传
3. 对缓冲区数据加上TCP头，**这里使用TCP协议举例**
4. 网络层收到数据之后会选取路由，填充IP头，可能进行数据分片
5. 通过ARP协议获取**下一跳**的MAC地址，可能是目标主机，也可能是路由器
6. 网卡驱动检测到数据之后，会将其保存到缓冲器区中
7. 之后使用DMA机制将缓冲区中的数据读取到内存中准备发送到网络中
8. 发送完成接收到消息的ACK说明不在重传，此时清理缓冲区

#### HTTP协议概念

超文本传输协议：定义了计算机之间通信的规范，主要是针对**两点**之间传输数据的，传输的内容是**超文本**（文字，图片，视频，超链接）

#### HTTP常见状态码

> 1表示中间状态，2表示成功，3表示重定向，4表示客户端错误，5表示服务端错误

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png" alt=" 五大类 HTTP 状态码 " style="zoom:33%;" />

#### HTTP常见字段

> 主要有以下几种，其余的记不住了

1. Host：客户端发送请求时指定服务端的域名
2. Content-Length：标识服务端返回的数据长度，这是为了解决TCP传输时的**粘包问题**
3. Connection：是否保持长连接，以便客户端的其他请求复用这个连接
4. Content-Type：本次响应的数据的格式
5. Accept：客户端用这个字段声明自己可以接受哪些字段
6. Content-Encoding：服务端说明此次数据的压缩格式
7. Accept-Coding：客户端声明自己可以接受哪些压缩方法

#### GET和POST的区别

> 本质上都是TCP链接，但是由于HTTP的规定和浏览器的限制导致有一些细微的差异

1. GET：
   - 指的是从服务端获取指定的资源
   - 参数一般写到请求URL中，所以更不安全，但是这只是规范，并不强制要求，GET也可以向POST一样将参数放到body中
   - 浏览器将请求数据一次性发出去
2. POST：
   - 根据请求报文的body对指定资源做出处理
   - 参数放到body中，只是一个规定，可以不遵守
   - 浏览器将请求数据分为header和data两次发送，Firefox好像就发送一次

#### GET 和 POST 都是安全和幂等的吗？

1. 安全：请求不会破坏服务器上的资源
2. 幂等：多次执行相同的操作，结果是相同的

**GET**方法<u>是</u>安全且幂等的，因为他只是请求资源，相当于只读，所以GET请求的数据可以进行缓存，因为每次请求的数据都是相同的

**POST**方法<u>不是</u>安全和幂等的，因为他会修改服务器的资源

#### HTTP缓存实现方式

<img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240311100505643.png" alt="image-20240311100505643" style="zoom:33%;" />

> 针对幂等（每次请求结果都一样）的请求，我们可以将请求的数据缓存到本地
>
> 强制缓存是只判断数据的过期时间，协商缓存是**每次**都问问服务器缓存还能用吗

1. 强制缓存：只要浏览器说缓存没过期，那么就直接使用缓存的数据

   > 浏览器第一次请求这个数据的时候，服务器给其加上一个过期时间，每次请求时判断当前缓存数据过期没，没过期就直接使用缓存数据

2. 协商缓存：向服务端发送请求，服务端根据请求携带的一些参数判断是否可以使用缓存

   - 基于时间实现：当服务端的数据最后修改时间大于本地缓存的最后修改时间，说明本地缓存失效，直接返回新资源返回200，本地缓存没失效直接返回304访问缓存

   - 基于唯一标识实现：资源一旦变化，唯一标识就会变化，服务端根据客户端传递过来的唯一标识判断缓存是否失效，没失效就可以使用

     > 核心就是判断本地缓存和服务端的数据是否一致

**只有没命中强制缓存时才进行协商缓存**

```java
 Cache-Control  > expires > Etag > Last-Modified
```

#### HTTP1.1的优缺点

1. 简单，灵活，易于扩充：各种请求方法，状态码，头部字段都可以扩充
2. 应用广泛，跨平台：随处可见HTTP的应用，浏览器，APP，新闻，游戏，天然跨平台
3. 无状态：没有额外的信息记录请求的状态信息，减轻了服务器的压力，但是对于登录>加入购物车>下单>结算>支付这种业务来说，每次都需要验证身份，简单解决方法就是**cookie**（标识符）
4. 明文传输：抓包时极其方便，但是信息直接暴露，不安全
5. 不安全：通信使用明文，信息容易泄露，不验证通信方身份，容易登录到假网站，报文无法确保完整或是否被篡改

#### HTTP/1.1的性能

1. 长连接：不用每次请求都建立连接，减小开销，只有主动断开或者超时才会断开连接
2. 管道网络传输（有但是没用过）：在一个TCP连接中可以发出多个请求，按照请求的顺序响应，一旦前面的阻塞，后面的也会持续等待

#### HTTP与HTTPS的区别

> 建立连接时多了TLS握手（生成对话秘钥）的过程，传输数据多了加密的过程

1. HTTP明文传输，HTTPS加入了SSL/TLS协议，使得报文加密传输
2. HTTP进行TCP三次握手之后就可以传输，HTTPS三次握手之后还需要进行SSL/TLS的握手过程才能传输
3. 默认端口不一样，HTTP默认80，HTTPS默认443
4. HTTPS需要申请数字证书，保证身份可信

#### SSL/TLS协议是什么

> 是一个密码通信框架，集成了很多密码学中的内容

1. 客户端向服务端索要公钥

2. 为了防止公钥不被篡改，需要将服务端的公钥放到数字证书(CA)中

3. 双方协商生成一个"对话秘钥"，公私钥加密这个对话秘钥（非对称加密）

   > 上面几步是TLS握手阶段

4. 使用对话秘钥加密通信的报文（对话秘钥使用对称加密，速度很快）

#### HTTPS中的TLS使用RSA的握手过程

1. TCP三次握手之后开始传递请求
2. 第**一**次TLS握手：客户端发起加密通信请求，请求内主要包含一个随机数（用于生成对话秘钥）和支持的加密算法
3. 第**二**次TLS握手：服务端针对加密通信请求作出响应，主要包含一个随机数（用于生成对话秘钥），使用的加密算法(RSA等)以及一个数字证书
4. 客户端**确认**数字证书的真实性之后，从中取出服务器的公钥
5. 第**三**次TLS握手：向服务端再次通信，此次使用公钥加密数据，主要包含一个随机数
6. 双方都根据上面的**三个**随机数计算出一个对话秘钥
7. 之后客户端将之前通信的数据做一个摘要并加密发送，来验证加密通信是否可用以及之前的通信过程中是否有数据被篡改
8. 第**四**次TLS握手：服务端也将之前通信的数据做摘要并加密发送，来验证加密通信的可用性以及之前通信过程中是否有数据被篡改
9. 后期就使用对话秘钥进行对称加密来通信

#### HTTPS中的TLS使用ECDHE握手过程

> ECDHE是一种基于椭圆曲线的密钥交换算法，通信过程中的会话秘钥是计算出来的，不是传递得到的，所以不会被中间人窃取，具有前向安全性

1. TCP三次之后开始传递请求

2. 第一次TLS握手：客户端发起加密通信请求，主要包含一个随机数和支持的加密算法

3. 第二次TLS握手：服务端针对请求进行响应，主要包含一个随机数和使用的加密算法还有数字证书

4. 服务端选择一个椭圆曲线G，然后生成一个随机数a作为服务端椭圆曲线的私钥保存到本地

5. 根据私钥计算出服务端的椭圆曲线公钥（A=aG），然后对公钥进行签名防止第三方篡改，之后发给客户端

   > 这里计算是根据椭圆的点运算，私钥计算出公钥之后，在想利用公钥计算出私钥就很困难，所以具有前向安全性
   >
   > 相当于即使中间人拦截到了公钥也无法破解私钥，也就是知道A，G想反向计算a很困难

6. 第三次TLS握手：客户端验证服务端证书的合法性，之后生成一个随机数b作为客户端椭圆曲线的私钥

7. 然后根据私钥计算出客户端的椭圆曲线公钥（B=bG），将公钥发给服务端

8. 之后双方利用自己的私钥和对方的公钥计算出一个共享密钥，这个是相同的

   > 客户端：自己的私钥*服务端公钥=bxA=bx（aG）=abG
   >
   > 服务端：自己的私钥*客户端公钥=axB=ax（bG）=abG
   >
   > 所以计算出的共享密钥是相同的

9. 共享密钥+之前传递的两个随机数计算出会话秘钥，这个自然也是相同的

   > 上面涉及到[协商密钥的过程](https://wenfh2020.com/2023/10/08/https/)

10. 客户端将之前发送的消息做一个摘要并加密发送，用来验证加密通信是否可用以及之前的通信过程中是否有数据被篡改

11. 第四次TLS握手：服务端执行同样的操作来验证

12. 之后使用会话秘钥来加密通信

#### 对称加密和非对称加密

1. 对称加密：加密数据双方只使用**一个**秘钥，运算速度更快
2. 非对称加密：通信双方使用公私钥**两个**秘钥进行加密

#### 服务端得到数字证书的过程

1. 服务器将自己的公钥注册到CA(数字证书认证机构)
2. CA使用自己的私钥对公钥进行数字签名，主要是将公钥，用途，颁发者，有效时间等信息封装在一起计算哈希
3. CA使用自己的私钥对这个哈希值加密，将其添加到文件证书上(主要包括加密的内容，公钥，用途等信息)，形成数字证书
4. 服务端收到自己的数字证书

#### 客户端检验数字证书的过程

1. 客户端使用相同的哈希算法按照CA计算哈希的步骤自己计算证书文件，得到一个哈希值
2. 使用CA的公钥解密得到另外一个哈希值
3. 两个哈希值相同说明数字证书可信，不相同还需要进行**信任链**的验证操作

#### 信任链验证操作

1. 客户端收到一个证书C，验证发现哈希值不相同，此时进行信任链验证操作
2. 客户端发现证书C由机构B颁发，而机构B的证书由机构A颁发
3. 机构A是根机构，是自签证书，**客户端信任此证书**
4. 此时客户端使用机构A的证书去验证机构B的证书是否可信
5. 可信的话再使用机构B的证书去验证C是否可信
6. 如果还是可信的话，此时客户端就信任证书C

> 可以看出是一个**链传递**的关系，客户端信任A，而A信任B，B信任C，最终客户端也信任C，操作系统中一般会内置一些根证书

#### HTTPS如何保证数据完整性

> 使用TLS**记录协议**保证数据的完整性和来源

1. 数据被分成很多片段，每个片段要进行压缩
2. 压缩的片段会加上消息认证码，保证数据完整性
3. 为了保证消息不会重复发送多次，每个片段还会带上一个编码
4. 使用协商好的会话秘钥进行对称加密
5. 加密好的数据加上传输的必要信息（数据类型，版本号，长度等）就可以传输了

#### HTTPS优化

1. 加快计算密钥的过程：换好CPU
2. 密钥交换算法：将RSA改成ECDHE可以加快TLS的握手过程，并且安全性更高
3. 减小证书大小，这样传递证书时的开销就会更小
4. 服务端定期向CA查询自己的证书状态是否过期，获得一个带时间戳的签名缓存住，客户端请求得到证书之后，只需要根据这个时间戳签名就可以直接判断证书是否过期，不用向CA查询
5. 会话复用：第一次建立连接后缓存会话秘钥，后期直接复用密钥即可减少TLS握手时间：
   1. 使用唯一的SessionID标识这个会话秘钥，后期该客户端再次连接时会携带一个SessionID，该SessionID的会话秘钥还在则直接返回会话秘钥，不需要TLS握手
   2. Session Ticket：第一次建立连接之后，服务端将会话秘钥加密形成Ticket交给客户端，下次连接时传递这个Ticket，服务端解密并验证这个会话秘钥的有效期，有效的话才开始通信
   3. Pre-shared key：将Ticket和请求一起发给服务端，如果解析出来的会话秘钥没过期，此时可以直接响应请求，时间更快

#### 重放攻击

> 要给会话秘钥设置过期时间，防止别人得到了SessionID或者Session Ticket解析出会话秘钥进行重放攻击

中间人恶意截取了客户端通信时的SessionID或者SessionID Ticket和POST报文，之后就可以冒充客户端发送POST请求，而POST可以修改数据库，最终数据被修改，客户端并不知情

#### HTTPS一定可靠吗

> HTTPS**本身是可靠**的，如果你信任了不安全的证书或者电脑被入侵导入了不想信任的证书，此时才会出现不可靠的情况，例如：

1. 客户端向服务器发起请求时，被假基站拦截到了，经过假基站再将请求转发到服务端

2. 此时客户端和服务端之间就会多出一个假基站，假基站通过伪造的证书与客户端进行通信

3. 浏览器是能识别到证书不安全的，但是如果你接受了这个不安全的证书，此时假基站就能获取到客户端请求的明文数据，也能知道服务端响应的明文数据

4. 此时变得不可靠

   > 这种不可靠是因为用户手动信任了不安全的假基站证书导致的，或者电脑被恶意导入了假基站的证书导致的

#### 抓包工具的工作原理

> 承担一个假基站的效果，主要是要让客户端信任抓包工具自己的证书

1. 抓包工具让客户端信任自己的证书，在客户端受信任的证书列表中导入自己的证书
2. 之后客户端正常和抓包工具建立连接
3. 抓包工具得到客户端传递的数据之后，进行解密，实现抓包
4. 之后将解密后的包用自己的秘钥进行加密传递给服务端
5. 由于服务端不校验客户端的身份，所以可以正常通信
6. 服务端将响应数据交给抓包工具，抓包工具解压之后，用与客户端通信的秘钥加密并返回给客户端
7. 客户端与服务端之间都不知道中间存在一个中间人，以为是直接进行通信

#### 如何避免被抓包或者出现假基站

1. 不要信任任何不安全的证书
2. 使用电脑应规范，防止被恶意注入不安全的证书
3. HTTPS**双向认证**，服务端要验证客户端通信的身份，服务端认为不安全的证书就拒绝通信，不像客户端提示不安全的证书可以选择信任

#### HTTP/1.1相比HTTP/1.0的改进

1. 使用长连接减小开销
2. 支持管道，一个请求发送之后，不必等待响应就可以发送下一个请求

#### 如何优化HTTP/1.1

1. 减少重复HTTP请求的发送，将不变的数据缓存（强制缓存+协商缓存）到本地

   > 强制缓存过期（过期不一定更新）之后，会尝试使用协商缓存(时间或者标识符)来确认缓存中的数据是否可以继续使用

2. 合并请求：多个请求共享请求头，减小通信时的开销

   - 将多张图片利用合并的技术合并成一个大图片，这样一次请求就可以获得多个图片
   - 使用webpack技术将js，css等资源打包，请求时一个请求就可以获得这些资源
   - 图片使用二进制编码嵌入HTML文件中，一次请求就可以获得图片和HTML文件

3. 延迟发送请求：请求按需发送，不需要的请求暂时不发送，只有需要的时候才发送请求

4. 减小响应数据的大小：将响应数据进行压缩

#### HTTP/2相比HTTP/1.1的改进

> 主要是引入一个Stream

1. 基于HTTPS，通信更加安全
2. 通信时**头部**数据也可以压缩(HPACK算法)，减小传输开销
3. 通信报文采用二进制的格式，对计算机更加友好，减小转换开销，并且消耗空间更小
4. 可以并发传输，引入了Stream的概念，不同的请求有不同的StreamID，Stream间可以乱序发送，Stream内需要按序发送，此时就可以做到有序组装消息
5. Stream可以设置优先级，从而优先响应某些请求，提高用户体验
6. 服务器主动推送，HTTP/2可以支持服务器主动向客户端推送消息，客户端的StreamID必须是**奇数**，服务端的StreamID必须是**偶数**

#### HPACK算法

1. 静态字典：高频出现在头部的内容建立静态字典，之后就用这些内容对应的编码代替，从而减小头部大小

2. 动态字典：一次连接中动态变化的字符串建立动态字典，然后还是用编码代替变化的内容，依次连接中的请求过多就会导致动态字典变得很大，从而影响服务器性能

   > 当一次连接中的请求过多时就会断开连接，从而**释放**动态表占用的内存

3. 哈夫曼编码：剩下没有被索引的内容还可以使用哈弗曼编码来进一步压缩

> 就这样利用索引+哈弗曼编码来**压缩头部**

#### HTTP/3相比HTTP/2.0的改进

> 底层的TCP改成UDP，所以主要是UDP的优点

1. HTTP2在TCP层面会有**对头阻塞**问题，也就是前面的包没收到，必须等这个包重传好之后后面的包才能处理，HTTP3将TCP协议改成UDP协议，丢包不重传
2. 发生丢包时，只有当前的Stream阻塞，其余的Stream不影响，阻塞的影响变小，丢弃的包也需要重传
3. 没有TCP的三次握手，连接建立更快
4. 连接迁移：当通信双方IP变化时，不会重新建立连接，只要上次建立连接分配的连接ID还在就可以直接通信，因为HTTP/3不是基于IP端口的，而是**基于连接ID**的

#### 有了HTTP为什么还要有RPC

1. 早期HTTP适用于B/S，而RPC适用于C/S，二者适用范围不同，现在没有区分这么大
2. 二者连接方式不一样：HTTP一般向DNS服务器获取目标服务器的ip进行通信，而RPC一般有一个中间服务存储所有服务的ip信息，通过中间服务获取目标服务器的IP
3. RPC会建立一个连接池，可以做到连接复用，用完的连接放回连接池下次还能接着用
4. HTTP请求中冗余的头信息太多，RPC更加关注于要发送的数据本身，所以微服务项目内部一般使用RPC远程调用
5. RPC比HTTP出现的早，很多老项目还是使用的RPC，并且RPC比HTTP/1.1性能要好，灭有过多的冗余头信息，结构化的数据传输起来也更方便

#### 有了HTTP为什么还要有WebSocket

HTTP设计之初是为了浏览网页，只有客户端主动请求，后期需求变多，需要服务端主动推送，此时才出现了WebSocket，比如网页主动弹窗广告，网页游戏主动更新环境变化，所以**应用场景不一样**

1. 浏览网页时使用HTTP协议，网页游戏就是用WebSocket协议，这取决于应用场景是半双工还是全双工
2. WebSocket协议建立连接时需要使用到HTTP，这是因为所有浏览器都支持HTTP协议，所以先使用HTTP尝试建立WebSocket连接进行升级，升级成功就可以进行全双工通信

#### HTTP如何实现服务端主动推送

1. 定时轮询：每个几秒就在后台发送一个请求给服务端，前台看起来就是服务端主动推送，因为用户自己没有主动发出请求
2. 长轮询：在一段时间内只要收到了某个事件服务器就自动推送，例如前端一扫码成功服务器就自动推送登陆成功后的页面，RabbitMQ就是这种机制，队列中一旦有消息，消费者就开始处理
3. 将HTTP改成WebSocket：由于HTTP是半双工的，导致服务端不能主动推送，而WebSocket是全双工的，可以直接推送消息，并且WebSocket是利用HTTP来进行升级的
