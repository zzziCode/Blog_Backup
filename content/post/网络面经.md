---
title: "网络面经"
description: "网络面经"
keywords: "网络面经"

date: 2024-03-11T08:52:11+08:00
lastmod: 2024-03-11T08:52:11+08:00

categories:
  - 面试
tags:
  - 面经
  - 网络

# 原文作者
# Post's origin author name
author: zzzi
# 开启数学公式渲染，可选值： mathjax, katex
# Support Math Formulas render, options: mathjax, katex
math: mathjax
# 原文链接
# Post's origin link URL
#link:
# 图片链接，用在open graph和twitter卡片上
# Image source link that will use in open graph and twitter card
#imgs:
# 在首页展开内容
# Expand content on the home page
#expand: true
# 外部链接地址，访问时直接跳转
# It's means that will redirecting to external links
#extlink:
# 在当前页面关闭评论功能
# Disabled comment plugins in this post
#comment:
#  enable: false
# 关闭文章目录功能
# Disable table of content
toc: false
# 绝对访问路径
# Absolute link for visit
#url: "网络面经.html"
# 开启文章置顶，数字越小越靠前
# Sticky post set-top in home page and the smaller nubmer will more forward.
#weight: 1

# 开启各种图渲染，如流程图、时序图、类图等
# Enable chart render, such as: flow, sequence, classes etc
#mermaid: true
---

> 🕸 网络面经

本文中介绍了一些计算机网络中常见的面试题，也可以当做平时的学习笔记来使用，知识点参考小林coding的[图解系列](https://xiaolincoding.com/)，文章长期更新

<!--more-->

#### TCP/IP的层数

> 这是对OSI七层网络协议的简化，现在变成了四层

1. 应用层：应用软件在这一层实现，不同应用需要通信时，就把数据交给下一层传输层

2. 传输层：有两个协议TCP,UDP，加上端口号等信息，端口号负责区分消息到达另一台设备时，交给哪个端口对应的应用，可能进行**分段**，之后交给下一层

3. 网络层：将从上层接收到的报文加上IP等信息，ip负责表示将消息交给哪一台主机，可能进行**分片**，交给下一层，ip地址分为网络号（找子网）和主机号（找子网中的主机）

4. 网络接口层：在数据的ip头部加上MAC头部，封装成数据**帧**，这样就可以通过mac地址区分网络上的设备

   <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/%E5%B0%81%E8%A3%85.png" alt="img" style="zoom:35%;" />

#### 输入网址到页面显示的过程

1. 解析url：确定要访问哪个服务器和服务器中哪个文件

2. 根据上述信息生成http请求（请求行，请求头。。）

3. 根据要访问的服务器名在DNS服务器中查询其ip地址，这里涉及到**域名解析**

4. 找到通信的目标ip之后，浏览器通过调用socket库来委托协议栈进行通信

5. 由于http基于tcp进行通信，此时需要三次握手建立连接

6. 建立连接也需要按照这个流程传输数据，是为了确保双方确实可以收发数据

7. 建立连接之后将数据进行封装，加上TCP头部（端口和序列号），进一步交给ip层

8. ip层将数据封装成网络包，加上IP头部（源IP和目标IP），可能进行分片

9. 之后对数据包加上MAC头部，主要加上MAC地址信息，包括发送方和接收方，此时需要用到ARP协议，填入MAC地址就知道数据**先发送**给哪个设备

10. 当客户端和服务器不在同一个子网中时，得到的MAC地址就是发送端所在子网的路由器MAC地址，在同一个子网时，此时MAC地址就是接收方的MAC地址

11. 数据封装好之后，经由发送方的网卡发送出去

12. 发送方网卡发送的消息先到达交换机，判断该消息从交换机哪个端口转发出去，这根据交换机中缓存的mac地址与端口的映射表

13. 找不到端口的映射，就发送给所有的端口（除了来时的端口）

14. 从端口出来到达路由器，路由器判断这个包自己需不需要转发（MAC地址是否一样）

15. 需要转发就去掉数据的MAC头信息，根据内部的IP头信息进行转发

16. 最终消息在网络上传输，这里根据ip地址进行转发，看接收方ip在哪个网段就转发给路由器的哪个端口

17. 都没有匹配的就转发给默认端口

18. 到达最后一跳时加上MAC地址，因为此时路由器的下一跳应该是消息的接收方了

    > 也就是在数据链路层的通信才会需要MAC地址

19. 接收方判断MAC地址是否与自己一样

20. 判断IP地址是不是符合的

21. 判断TCP中的序列号是不是我想要的（我上次ACK什么，就说明这次想要什么）

22. 以上判断都通过，此时根据TCP中记录的端口号进行转发，最终到达HTTP的服务器

23. HTTP的服务器发现对方想要请求网页，于是将网页封装到http响应报文中

24. 经过TCP，IP，MAC的封装，从网卡出去，到达交换机，路由器，最终一步一步到达请求网页的客户端，相当于是逆过程

25. 客户端还是一层一层的进行判断MAC，IP，TCP序列号，然后按照端口转发

26. 浏览器收到HTTP服务器发送过来的页面之后，就可以显示了

27. 最终会发起四次挥手断开连接

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/%E9%94%AE%E5%85%A5%E7%BD%91%E5%9D%80%E8%BF%87%E7%A8%8B/2.jpg" alt="简单的网络模型" style="zoom: 33%;" />

> 类似于要发送八条消息，三次握手，一条真实消息，四次挥手

#### DNS解析过程

> 为了获取目标主机的ip地址

1. 本地发送一个DNS请求到本地记录的DNS服务器
2. DNS服务器查找缓存，有目标就直接返回
3. 找不到就给客户端一个新的上层DNS服务器地址，客户端继续询问
4. 找到就返回，找不到继续给一个新的DNS服务器地址，这是由要通信的域名决定的
5. 最终得到通信目标的ip地址

#### ARP协议过程

> 为了获取下一跳的设备MAC地址

1. 先查询ARP缓存，缓存中由ip和mac的对应信息直接获取
2. 没有就以广播的形式询问xxx这个ip地址是谁的
3. 每个人判断一下，是自己的话就回答自己的mac地址是多少
4. 如果没有人的ip与之匹配，此时返回的时路由器的MAC地址

#### TCP/IP 网络模型与 OSI 网络模型（四层与七层）

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%B5%AE%E7%82%B9/OSI%E4%B8%8ETCP.png" alt="img" style="zoom:33%;" />

#### linux接收网络包流程

1. 网卡收到别人传递来的消息

2. 通过DMA技术（硬件机制）将网络包写入到内存地址中

   > DMA技术允许外围组件直接将数据传递给内存或者从内存中读取数据，可以减小无用操作，提高吞吐量

3. 使用NAPI机制（中断+轮询）唤醒数据处理程序，之后来轮询网络包中的内容即可

4. 读取到数据首先会到达网络接口层，去掉帧头帧尾交给网络层

5. 网络层根据ip判断数据的走向，转发还是继续处理

6. 继续处理的话就将IP头去掉，交给传输层

7. 根据传输层的TCP头或者UDP头来决定将数据放到哪个Socket的缓冲区

8. 应用程度调用socket接口读取数据给自己

>**socket**：工作在应用层和传输层之间，采用Unix**一切皆文件**的思想，数据看成文件进行读写操作

#### linux发送网络包流程

1. 应用程序调用Socket接口将数据放到socket缓冲区
2. TCP协议拷贝缓冲区副本进行发送，防止需要重传
3. 对缓冲区数据加上TCP头，**这里使用TCP协议举例**
4. 网络层收到数据之后会选取路由，填充IP头，可能进行数据分片
5. 通过ARP协议获取**下一跳**的MAC地址，可能是目标主机，也可能是路由器
6. 网卡驱动检测到数据之后，会将其保存到缓冲器区中
7. 之后使用DMA机制将缓冲区中的数据读取到内存中准备发送到网络中
8. 发送完成接收到消息的ACK说明不在重传，此时清理缓冲区

#### HTTP协议概念

超文本传输协议：定义了计算机之间通信的规范，主要是针对**两点**之间传输数据的，传输的内容是**超文本**（文字，图片，视频，超链接）

#### HTTP常见状态码

> 1表示中间状态，2表示成功，3表示重定向，4表示客户端错误，5表示服务端错误

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png" alt=" 五大类 HTTP 状态码 " style="zoom:33%;" />

#### HTTP常见字段

> 主要有以下几种，其余的记不住了

1. Host：客户端发送请求时指定服务端的域名
2. Content-Length：标识服务端返回的数据长度，这是为了解决TCP传输时的**粘包问题**
3. Connection：是否保持长连接，以便客户端的其他请求复用这个连接
4. Content-Type：本次响应的数据的格式
5. Accept：客户端用这个字段声明自己可以接受哪些字段
6. Content-Encoding：服务端说明此次数据的压缩格式
7. Accept-Coding：客户端声明自己可以接受哪些压缩方法

#### GET和POST的区别

> 本质上都是TCP链接，但是由于HTTP的规定和浏览器的限制导致有一些细微的差异

1. GET：
   - 指的是从服务端获取指定的资源
   - 参数一般写到请求URL中，所以更不安全，但是这只是规范，并不强制要求，GET也可以向POST一样将参数放到body中
   - 浏览器将请求数据一次性发出去
2. POST：
   - 根据请求报文的body对指定资源做出处理
   - 参数放到body中，只是一个规定，可以不遵守
   - 浏览器将请求数据分为header和data两次发送，Firefox好像就发送一次

#### GET 和 POST 都是安全和幂等的吗？

1. 安全：请求不会破坏服务器上的资源
2. 幂等：多次执行相同的操作，结果是相同的

**GET**方法<u>是</u>安全且幂等的，因为他只是请求资源，相当于只读，所以GET请求的数据可以进行缓存，因为每次请求的数据都是相同的

**POST**方法<u>不是</u>安全和幂等的，因为他会修改服务器的资源

#### HTTP缓存实现方式

<img src="C:/Users/zzzi/AppData/Roaming/Typora/typora-user-images/image-20240311100505643.png" alt="image-20240311100505643" style="zoom:33%;" />

> 针对幂等（每次请求结果都一样）的请求，我们可以将请求的数据缓存到本地
>
> 强制缓存是只判断数据的过期时间，协商缓存是**每次**都问问服务器缓存还能用吗

1. 强制缓存：只要浏览器说缓存没过期，那么就直接使用缓存的数据

   > 浏览器第一次请求这个数据的时候，服务器给其加上一个过期时间，每次请求时判断当前缓存数据过期没，没过期就直接使用缓存数据

2. 协商缓存：向服务端发送请求，服务端根据请求携带的一些参数判断是否可以使用缓存

   - 基于时间实现：当服务端的数据最后修改时间大于本地缓存的最后修改时间，说明本地缓存失效，直接返回新资源返回200，本地缓存没失效直接返回304访问缓存

   - 基于唯一标识实现：资源一旦变化，唯一标识就会变化，服务端根据客户端传递过来的唯一标识判断缓存是否失效，没失效就可以使用

     > 核心就是判断本地缓存和服务端的数据是否一致

只有没命中强制缓存时才进行协商缓存

```java
 Cache-Control  > expires > Etag > Last-Modified
```

#### HTTP1.1的优缺点

1. 简单，灵活，易于扩充：各种请求方法，状态码，头部字段都可以扩充
2. 应用广泛，跨平台：随处可见HTTP的应用，浏览器，APP，新闻，游戏，天然跨平台
3. 无状态：没有额外的信息记录请求的状态信息，减轻了服务器的压力，但是对于登录>加入购物车>下单>结算>支付这种业务来说，每次都需要验证身份，简单解决方法就是**cookie**（标识符）
4. 明文传输：抓包时极其方便，但是信息直接暴露，不安全
5. 不安全：通信使用明文，信息容易泄露，不验证通信方身份，容易登录到假网站，报文无法确保完整或是否被篡改

#### HTTP/1.1的性能

1. 长连接：不用每次请求都建立连接，减小开销，只有主动断开或者超时才会断开连接
2. 管道网络传输（有但是没用过）：在一个TCP连接中可以发出多个请求，按照请求的顺序响应，一旦前面的阻塞，后面的也会持续等待

#### HTTP与HTTPS的区别

> 建立连接时多了TLS握手（生成对话秘钥）的过程，传输数据多了加密的过程

1. HTTP明文传输，HTTPS加入了SSL/TLS协议，使得报文加密传输
2. HTTP进行TCP三次握手之后就可以传输，HTTPS三次握手之后还需要进行SSL/TLS的握手过程才能传输
3. 默认端口不一样，HTTP默认80，HTTPS默认443
4. HTTPS需要申请数字证书，保证身份可信

#### SSL/TLS协议是什么

> 是一个密码通信框架，集成了很多密码学中的内容

1. 客户端向服务端索要公钥

2. 为了防止公钥不被篡改，需要将服务端的公钥放到数字证书(CA)中

3. 双方协商生成一个"对话秘钥"，公私钥加密这个对话秘钥（非对称加密）

   > 上面几步是TLS握手阶段

4. 使用对话秘钥加密通信的报文（对话秘钥使用对称加密，速度很快）

#### HTTPS建立连接的过程

1. 客户端发起加密通信请求，请求内主要包含一个随机数（用于生成对话秘钥）和支持的加密算法
2. 服务端针对加密通信请求作出响应，主要包含一个随机数（用于生成对话秘钥），使用的加密算法以及一个数字证书
3. 客户端确认数字证书的真实性之后，从中取出服务器的公钥
4. 向服务端再次通信，此次使用公钥加密数据，主要包含一个随机数
5. 服务端根据上面的三个随机数计算出一个对话秘钥
6. 有了对话秘钥之后，后期就使用对话秘钥进行对称加密来通信

#### 服务端得到数字证书的过程

1. 服务器将自己的公钥注册到CA(数字证书认证机构)
2. CA使用自己的私钥对公钥进行数字签名，主要是将公钥，用途，颁发者，有效时间等信息封装在一起计算哈希
3. CA使用自己的私钥对这个哈希值加密，将其添加到文件证书上，形成数字证书
4. 服务端收到自己的数字证书

#### 客户端检验数字证书的过程

1. 客户端使用相同的哈希算法按照CA计算哈希的步骤自己计算出来一个哈希值
2. 使用CA的公钥解密得到另外一个哈希值
3. 两个哈希值相同说明数字证书可信，不相同还需要进行**信任链**的验证操作

#### 信任链验证操作

1. 客户端收到一个证书C，验证发现哈希值不相同，此时进行信任链验证操作
2. 客户端发现证书C由机构B颁发，而机构B的证书由机构A颁发
3. 机构A是根机构，是自签证书，**客户端信任此证书**
4. 此时客户端使用机构A的证书去验证机构B的证书是否可信
5. 可信的话再使用机构B的证书去验证C是否可信
6. 如果还是可信的话，此时客户端就信任证书C

> 可以看出是一个**链传递**的关系，客户端信任A，而A信任B，B信任C，最终客户端也信任C，操作系统中一般会内置一些根证书

#### HTTPS如何保证数据完整性

> 使用TLS**记录协议**保证数据的完整性和来源

1. 数据被分成很多片段，每个片段要进行压缩
2. 压缩的片段会加上消息认证码，保证数据完整性
3. 为了保证消息不会重复发送多次，每个片段还会带上一个编码
4. 使用协商好的会话秘钥进行对称加密
5. 加密好的数据加上传输的必要信息（数据类型，版本号，长度等）就可以传输了

#### HTTPS一定可靠吗

> HTTPS**本身是可靠**的，如果你信任了不安全的证书或者电脑被入侵导入了不想信任的证书，此时才会出现不可靠的情况，例如：

1. 客户端向服务器发起请求时，被假基站拦截到了，经过假基站再将请求转发到服务端

2. 此时客户端和服务端之间就会多出一个假基站，假基站通过伪造的证书与客户端进行通信

3. 浏览器是能识别到证书不安全的，但是如果你接受了这个不安全的证书，此时假基站就能获取到客户端请求的明文数据，也能知道服务端响应的明文数据

4. 此时变得不可靠

   > 这种不可靠是因为用户手动信任了不安全的假基站证书导致的，或者电脑被恶意导入了假基站的证书导致的

#### 抓包工具的工作原理

> 承担一个假基站的效果，主要是要让客户端信任抓包工具自己的证书

1. 抓包工具让客户端信任自己的证书，在客户端受信任的证书列表中导入自己的证书
2. 之后客户端正常和抓包工具建立连接
3. 抓包工具得到客户端传递的数据之后，进行解密，实现抓包
4. 之后将解密后的包用自己的秘钥进行加密传递给服务端
5. 由于服务端不校验客户端的身份，所以可以正常通信
6. 服务端将响应数据交给抓包工具，抓包工具解压之后，用与客户端通信的秘钥加密并返回给客户端
7. 客户端与服务端之间都不知道中间存在一个中间人，以为是直接进行通信

#### 如何避免被抓包或者出现假基站

1. 不要信任任何不安全的证书
2. 使用电脑应规范，防止被恶意注入不安全的证书
3. HTTPS**双向认证**，服务端要验证客户端通信的身份，服务端认为不安全的证书就拒绝通信，不像客户端提示不安全的证书可以选择信任

#### HTTP/1.1相比HTTP/1.0的改进

1. 使用长连接减小开销
2. 支持管道，一个请求发送之后，不必等待响应就可以发送下一个请求

#### HTTP/2相比HTTP/1.1的改进

> 主要是引入一个Stream

1. 基于HTTPS，通信更加安全
2. 通信时头部数据也可以压缩，减小传输开销
3. 通信报文采用二进制的格式，对计算机更加友好，减小转换开销
4. 可以并发传输，引入了Stream的概念，不同的请求有不同的StreamID，所以可以有序地组装消息
5. 服务器主动推送，HTTP/2可以支持服务器主动向客户端推送消息，客户端的StreamID必须是**奇数**，服务端的StreamID必须是**偶数**

#### HTTP/3相比HTTP/2.0的改进

> 底层的TCP改成UDP，所以主要是UDP的优点

1. HTTP2在TCP层面会有对头阻塞问题，也就是前面的包没收到，必须等这个包重传好之后后面的包才能处理，HTTP3将TCP协议改成UDP协议，丢包不重传
2. 发生丢包时，只有当前的Stream阻塞，其余的Stream不影响
3. 没有TCP的三次握手，连接建立更快
4. 当通信双方IP变化时，不会重新建立连接，因为UDP不是面向连接的

#### 

